帆软软件招聘
Hadoop
9k以上 /无锡 / 经验不限 / 本科及以上 / 全职
08:50  发布于拉勾网职位诱惑：
技术大牛多，产品牛
职位描述：


职位描述： 

1、与产品经理，UX设计师一起工作来分析、评估和细化功能需求
2、与软件开发团队一起再快速迭代中不断发布新功能
3、作为软件产品模块的代码负责人，保持代码质量、完整性、效率和可用性
4、与软件测试工程师交流设计信息并提供测试建议


我们对您的期望： 
1、本科毕业生，重点院校计算机等相关理工科专业背景。 
2、对软件开发有浓厚的兴趣，有开发出完美的软件产品的热情，喜欢钻研。 
3、极强的逻辑思维能力和问题解决能力，数学基础优秀。 
4、熟练java，熟练掌握Hadoop、spark平台，做基本的分析处理。
5、有开源项目经验加分。


公司介绍：
1、在数据产品领域有15年行业经验，一直被模仿，从未被超越。
2、合作客户超过 4500 家;中国 500 强中 285 家合作过；中国软件 100 强中, 62 家是合作伙伴,中国 244 家一级系统集成商,137 家牵手了帆软。
3、2005年，帆软公司人数200人，行业内规模最大；销售额破亿，业内遥遥领先。
4、公司成员90%来自全国重点985、211院校，牛人到处都是，我们招聘的每一个你，都期待能够在未来有能力独当一面。
5、关于工作回报，我们除了提供有竞争力的薪酬，更有能够参与公司利润分配的股权激励，我们坚持，不让某一个人创始人暴富，与优秀的人一起共赢才是王道。

工作地址
无锡 - 南长区 - 清扬路 - 清扬路118号世金中心11楼
查看地图
职位发布者:
hr
职位发布者
聊天意愿
弱
回复率17%  用时38分钟
简历处理
超快
处理率100%  用时1天
活跃时段
下午
下午5点最活跃
-------------------------------------------------
极光研发部-数据组招聘
Hadoop工程师
15k-25k /深圳 / 经验3-5年 / 本科及以上 / 全职
15:08  发布于拉勾网职位诱惑：
五险一金、14薪/年、下午茶、工作餐等等
职位描述：
工作职责：
1.负责公司Hadoop系统的底层搭建，构建公司统一的离线和实时计算平台。 
2.负责公司日志系统及ETL系统的设计和实现。 
3.负责公司数据体系的架构设计和规划，充分发挥公司的数据价值。 
4.跟踪Hadoop生态环境的最新进展。 

任职资格：
1、本科以上学历，熟悉Hadoop生态环境，对Hadoop, Hbase, Hive, Storm等至少一个项目有着深入的了解。 
2.扎实的Java基础，对至少一门动态语言有过使用经验。 
3.熟悉Linux系统常用操作。 
4.对数据有着强烈兴趣，有部署大规模Hadoop集群的经验者优先。 
5.良好的学习能力，保持对新技术的敏感性。
工作地址
深圳 - 南山区 - 翻身路 - 关口二路智恒战略性新兴产业园
查看地图
职位发布者:
Maggie
HRBP
聊天意愿
暂无
回复率--  用时--
简历处理
超快
处理率100%  用时1天
活跃时段
下午
下午2点最活跃
-------------------------------------------------
紫川软件招聘
Hadoop工程师
9k-18k /深圳 / 经验1-3年 / 大专及以上 / 全职
数据挖掘
08:24  发布于拉勾网职位诱惑：
员工旅游 周末双休 五险一金
职位描述：
熟悉SPARK或者SCALA,三年以上大数据经验
工作地点：大剧院平安银行
工作地址
深圳 - 福田区 - 深南中路新闻大厦
查看地图
职位发布者:
谭
谭生
职位发布者
聊天意愿
很弱
回复率--  用时56分钟
简历处理
超快
处理率100%  用时1天
活跃时段
早上
早7点最活跃
-------------------------------------------------
广州棒谷科技股份有限公司大数据人工智能研发中心招聘
hadoop工程师
10k-20k /广州 / 经验1-3年 / 本科及以上 / 全职
高级
数据分析
数据开发
数据挖掘
深度学习
电商
13:37  发布于拉勾网职位诱惑：
海量数据,人工智能
职位描述：
岗位职责：
1.负责Hadoop平台MapReduce、Hive、HBase、Impala、ETL等应用开发；
2.构建数据仓库，全方位支撑公司产品和业务迭代扩张；
3.负责大数据平台数据抽取.清洗.转换和建模的开发；
4.构建数据的监测与分析体系，帮助业务运营人员快速、及时了解业务动态；
任职要求：
1.了解数据仓库开发流程，熟悉数据仓库(DW)/商业智能(BI)的数据框架；    
2.2年以上大数据工作经验，熟练掌握Python/Java至少一种编程语言，熟悉java者优先； 
3.熟悉Mysql/Oracle等至少一种关系型数据库，熟悉SQL开发；
4.熟悉HDFS、HBase、Hive、MapReduce、Impala、Oozie、Sqoop、Kettle等相关技术/工具，具备大数据分析项目经验；
5.熟悉Linux系统，能实际编写Shell脚本；
6.两年以上Java/Python开发相关工作经验；
7.有数据仓库开发、海量数据处理经验者优先考虑；
8.有电商数据分析、网站分析经验者优先；
工作地址
广州 - 白云区 - 白云大道 - 景泰街机场东门路01号豪泉大厦2楼大厅
查看地图
职位发布者:
aiko
大数据人工智能HRBP
聊天意愿
一般
回复率45%  用时1小时
简历处理
快
处理率36%  用时1天
活跃时段
全天
早9点最活跃
-------------------------------------------------
浙江执御信息技术有限公司数据部门招聘
Hadoop
15k-30k /杭州 / 经验3-5年 / 本科及以上 / 全职
09:40  发布于拉勾网职位诱惑：
旅游活动,调薪制度,年终奖金,扁平化管理
职位描述：
hadoop开发工程师
职位描述：
1、负责网站/APP端海量点击流日志的分析及处理；
2、负责全球分布式高性能计算平台的设计与实现；
3、参与个性化推荐系统算法开发。
职位要求：
1、本科以上学历，3年以上Hadoop开发经验，熟悉Map/Reduce编程框架及接口，并有实际项目经验；
2、有一定的数学基础，对常用数据分析算法有一定研究并有实战经验；掌握Shell及Javascript者更佳；
3、有网站日志处理及数据仓库相关经验者更佳；
4、熟悉任意一种开源日志系统，如：Hive、Scribe、Chukwa、Kafka、Flume更佳。
工作地址
杭州市 - 拱墅区 - 三墩 - 祥茂路2号影天印业园区1幢3楼
查看地图
职位发布者:
王充
招聘
聊天意愿
很弱
回复率--  用时43分钟
简历处理
超快
处理率92%  用时1天
活跃时段
早上
早9点最活跃
-------------------------------------------------
星环科技研发部招聘
Hadoop发行版开发工程师
20k-40k /上海 / 经验不限 / 本科及以上 / 全职
高级
linux
hadoop
SQL
大数据
Java
11:06  发布于拉勾网职位诱惑：
商业保险 补充公积金 技术牛人多 公司氛围
职位描述：
职位描述：
hadoop的研发，用于fix Hadoop 的bug, 维护和升级hadoop及社区版  
职位要求：
1、本科及以上学历，计算机/软件工程专业                           2、熟练掌握Java语言、SQL语言                                     3、熟悉Linux平台                                                 
4、有良好的操作系统、数据结构和算法功底                      
5、具有良好的沟通能力和良好的团队合作精神                       6、工作积极主动，自我驱动能力强，负责认真，主动思考         
7、熟悉spark、hadoop、hive、hbase者优先   
工作地址
上海 - 徐汇区 - 田林 - 虹漕路88号
查看地图
职位发布者:
HR
招聘专员
聊天意愿
暂无
回复率--  用时--
简历处理
超快
处理率96%  用时1天
活跃时段
早上
早10点最活跃
-------------------------------------------------
远传技术创新业务事业部招聘
Hadoop开发工程师
10k-20k /杭州 / 经验1-3年 / 本科及以上 / 全职
数据分析
hadoop
大数据
Java
17:06  发布于拉勾网职位诱惑：
五险一金,餐补,年底双薪,定期体检
职位描述：
工作职责：
1、参与大数据平台的设计与开发，解决海量数据面临的挑战；
2、管理、优化并维护Hadoop、Spark等集群，保证集群规模持续、稳定；
3、负责HDFS/hive/HBase的功能、性能和扩展，解决并实现业务需求；
4、 协助建模工程师建立数据模型，对数据进行挖掘、优化及统计。

任职资格：
1、本科生及以上学历，2年及以上互联网系统或者其他企业应用系统开发相关经验；；
2、熟悉Hadoop/HBase/Spark/Storm/Hive，熟悉数据挖掘策略与算法；
3、具备Java开发经验，Java编程基础扎实，熟练使用struts2、spring、ibatis或hibernate等框架；
4、数据控，善于发现问题、解决问题,具备良好的分析和解决问题的能力，具备一定的钻研精神和持续学习的意愿，强烈的责任感和团队感，对负有挑战性的工作充满热情
工作地址
杭州 - 下城区 - 东新路 - 白石路318号省浙江人力资源服务产业园北楼5楼
查看地图
职位发布者:
H
huangyiyun
HR
聊天意愿
暂无
回复率--  用时--
简历处理
超快
处理率100%  用时1天
活跃时段
早上
早10点最活跃
-------------------------------------------------
江苏亿科达研发部招聘
（急招）大数库hadoop开发工...
15k-20k /深圳 / 经验3-5年 / 本科及以上 / 全职
中级
数据分析
spark
hadoop
数据挖掘
大数据
1天前  发布于拉勾网职位诱惑：
晋升机会大,氛围好,领导好,环境高大尚
职位描述：
1、本科以上学历、3年以上大数据开发或管理经验；  
2、精通oracle数据库、具备优秀的sql编写和调优能力；
3、熟悉 Hadoop、yran、hive 或 Spark 等分布式系统的工作原理，具备较强的架构、性能优化能力； 
4、有主导完成优秀应用或大型大数据项目开发经验者优先；
5、熟悉java等开发语言，熟悉常用的分布式系统；
6、有良好的团队协作与沟通能力。
工作地址
深圳 - 福田区 - 新洲 - 购物公园
查看地图
职位发布者:
W
weihy@h...
hr
聊天意愿
弱
回复率15%  用时7分钟
简历处理
超快
处理率100%  用时1天
活跃时段
全天
早9点最活跃
-------------------------------------------------
方付通大数据开发工程师招聘
Hadoop
15k-30k /上海 / 经验3-5年 / 本科及以上 / 全职
python
大数据
09:25  发布于拉勾网职位诱惑：
薪资优待 福利完善
职位描述：
岗位职责： 
1、基于大规模CDH Hadoop集群部署、管理和日常运维； 
2、负责数据采集、清洗、实时分析、离线分析、报表、数据可视化。
3、基于JAVA+大数据相关技术的组合开发模式。

任职要求： 
1、2年以上工作经验，本科计算机及相关专业学历； 
2、JAVA基础扎实，熟悉数据结构和算法, 熟悉Linux操作系统；  
3、熟悉hadoop、spark、hive、flume 、kafka、 hbase 、zookeeper 、ETL 有esper、druid数据分析工具经验更佳
4、熟悉spring框架,mybaits等框架，有jetty，netty使用经验加分
5、熟悉python、scala其中一种脚本更佳。
6、最好有CDH hadoop集群、zk集群、kafka集群安装经验，具备独立分析和解决问题的能力； 
7、能够承担一定工作压力，具备创新思维、具备团队协作精神。

备注：相关技术仅仅处于学习或了解阶段的，请勿写熟悉，以免误解。 
工作地址
上海 - 浦东新区 - 世纪公园 - 民生路1286号汇商大厦11、14、17楼
查看地图
职位发布者:
江小姐
招聘主管
聊天意愿
一般
回复率35%  用时22分钟
简历处理
超快
处理率100%  用时1天
活跃时段
下午
下午3点最活跃
-------------------------------------------------
晶赞科技Zamplus招聘
Hadoop研发工程师
15k以上 /上海 / 经验1-3年 / 本科及以上 / 全职
大数据
09:21  发布于拉勾网职位诱惑：
弹性工作制、国外旅游、免费早餐、下午茶等
职位描述：
岗位描述：
1、Hadoop 数据平台建设、开发、测试、部署和优化
2、基于Hadoop的存储平台架构设计与性能优化
3、设计和开发海量数据的管理系统
岗位要求：
1、计算机或相关专业本科以上学历，具有扎实的算法和数据结构基础
2、1年以上Hadoop/Hbase/Hive/storm开发经验，或者有相关的分布式平台开发经验者
3、精通Java，熟悉Java开发工具
4、对Hadoop源代码有研究和有贡献者优先
5、有海量数据挖掘算法开发者优先
6、较好的沟通理解能力，有修的团队合作品质，乐观向上，踏实上进
7、熟悉linux系统，包括shell/python等语言开发
工作地址
上海 - 闸北区 - 汶水路 - 灵石路695号珠江创业园区3号楼11楼
查看地图
职位发布者:
Zamplus...
HR
聊天意愿
暂无
回复率--  用时--
简历处理
快
处理率22%  用时1天
活跃时段
早上
早10点最活跃
-------------------------------------------------
徐工信息软件研发部招聘
Hadoop
10k-20k /徐州 / 经验3-5年 / 本科及以上 / 全职
大数据
hadoop
数据分析
数据挖掘
09:17  发布于拉勾网职位诱惑：
五险一金,带薪假期,扁平化管理,晋升空间大
职位描述：
岗位职责：
1、基于hadoop生态的大数据存储平台搭建和部署; 
2、承担数据抽取、清洗、转化等数据处理程序开发； 
3、商用平台指标数据挖掘。
4、数据仓库的设计，开发，维护
5、完成日常数据分析查询需求
任职要求：
1.三年以上工作经验，一年以上大数据项目开发/维护经验，精通Hadoop技术体系，熟练掌握以下至少两项技能（多者加分）：
.MapReduce、Hbase/Cassandra 、HIVE、Zookeeper、Pig、Sqoop、Flume、Ambari；
2.熟练掌握至少一门主流语言，包括但不限于JAVA、C#；
3.熟练掌握至少一门脚本语言，包括但不限于Python、Perl、Linux/Unix Shell。
岗位福利：
1、五险一金，有竞争力的薪资；
2、各种带薪假期；
3、假期福利、生日福利；
4、员工宿舍、员工食堂、免费班车；
5、出差补助。
工作地址
徐州 - 鼓楼区 - 经济开发区科技路6号
查看地图
职位发布者:
郭女士
HR
聊天意愿
很弱
回复率--  用时4小时
简历处理
快
处理率100%  用时3天
活跃时段
早上
早10点最活跃
-------------------------------------------------
允升科技技术产品部招聘
Hadoop
12k-20k /重庆 / 经验1-3年 / 本科及以上 / 全职
hadoop
大数据
16:30  发布于拉勾网职位诱惑：
福利好，平台大，技术氛围好，环境高大上
职位描述：
岗位职责：
1、参与公司Hadoop/Hive/Spark等大数据基础设施的研发与运维，提升运行效率、稳定性和可用性；
2、参与大数据集群部署和管理平台的研发和改进；
3、参与公司搜索平台的研发和改进。

任职资格：
1、熟悉并行计算或者分布式计算，熟悉hadoop/Spark框架,熟练掌握MR/RDD编程；
2、熟悉ZooKeeper/kafka/Hadoop/HBase/Flume等平台者优先；
3、有深厚的操作系统，数据结构和算法基础；
4、熟练掌握Java或Scala语言；
5、有搜索平台开发经验者优先；
6、做事严谨踏实，责任心强，条理清楚，善于学习总结，有良好的团队合作精神和沟通协调能力。
工作地址
重庆 - 大渡口区 - 八桥 - 思源路32号云谷总部基地4号楼
查看地图
职位发布者:
唐
唐小姐
HR
聊天意愿
暂无
回复率--  用时--
简历处理
超快
处理率100%  用时1天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
竞技世界TSC招聘
Hadoop
20k-30k /北京 / 经验3-5年 / 本科及以上 / 全职
大数据
1天前  发布于拉勾网职位诱惑：
过节费，旅游，年终奖金，各种福利等着你！
职位描述：
岗位职责：
1、负责大数据平台的数据体系以及数据仓库的规划与设计。  
2、业务数据产品的开发。与分析人员一起，面向业务目标进行数据分析与模型定义，并完成支撑业务BI的数据产品的开发。 
3、基础数据服务建设。对各种数据分析场景和模型进行抽象，建设一个通用的可配置的基础数据服务平台。
4、大数据计算分析以及数据可视化相关领域的新技术、新框架的调研。
 
任职要求：
1、本科以上学历，3年及以上相关开发经验。 
  （硕士以上可适当放宽相关经验年限） 
2、熟悉算法与数据结构。 
3、精通Java 语言。 
4、熟悉Unix/Linux 系统工作环境。 
5、精通HDFS，HBase/Hadoop，MapReduce，spark，Hive…… 等相关技术。 
6、有良好的技术文档功底，有较强的抽象，提炼能力，有一定的分析、设计、架构能力。 
7、有较强的探索精神，积极主动、责任心强，具有良好的沟通能力和团队合作精神。 
8、有海量数据开发经验者优先。 
9、精通Python、R其中一种语言的优先。
10、有相关数据可视化经验者优先 

我们为您提供：    1、工资奖金 ——薪资在业内极有竞争力，一年13-15个月工资，且年度有2次调薪机会；    2、五险一金 —— 按工资基数全额缴纳五险一金；    3、多种福利——交通补助、餐补、每年5000元左右过节费、春节报销回家路费、春节开门红奖金等等；   4、多种激励 —— 月度个人或项目评优、丰厚的人才推荐奖、高效团队合作奖等各种奖励；    5、员工旅游 —— 春游、夏游、秋游、大型年会，当年被评为金牌员工可以享受出国游，让您旅游玩到high；    6、健身中心——宽敞明亮随用随有的免费健身房，羽毛球、乒乓球、台球、跑步机等各种健身设施应有尽有，更有各种俱乐部，篮球、跆拳道等各种部落群让您找到志同道合的玩友！    7、健康体检——每年一度的健康体检让您的身体定期做个检查；    8、工作居住证——为符合北京市规定的员工办理北京市工作居住证；优秀的应届毕业生更有机会解决北京市户口；   9、上班时间——每天弹性工作制，错峰上下班；   10、培训分享 —— 新员工培训、沙龙、托展培训、外部培训等等，在JJ我们一起成长！
工作地址
- 上地创业路17号竞技世界大厦
查看地图
职位发布者:
Kelley
HR
聊天意愿
暂无
回复率--  用时--
简历处理
快
处理率87%  用时3天
活跃时段
早上
早10点最活跃
-------------------------------------------------
利通科技软件研发部招聘
Hadoop开发工程师
8k-16k /广州 / 经验3-5年 / 本科及以上 / 全职
中级
hadoop
信息安全
11:37  发布于拉勾网职位诱惑：
六险一金,带薪年假,内部培训,优秀团队
职位描述：
职责描述：
1、负责Hadoop平台搭建，运维，管理，故障处理；
2、负责保障大数据平台的高效运转、稳定、安全；
3、负责MapRedure程序的开发、Hive脚本编写；
4、能对平台的Hadoop，Hbase，Kafka，Hive进行优化；
5、建立Hadoop集群管理规范、维护，包括版本管理和变更记录等。

岗位要求:
1、有3年以上的hadoop相关使用和开发经验；
2、精通Hadoop/MapReduce/hive/HBase/Zookeeper/Spark/Flume等分布式计算框架 ,并能搭建&维护集群环境；
3、熟悉java/MS SQL/mysql，有相关开发经验；
4、有一定的java开发经验和linux shell开发经验；
5、熟悉常用数据结构和算法；
6、有较好的逻辑思维能力，较强的抽象、概括、总结能力；
7、具备责任心和良好的团队协作精神，且具备良好的执行力者优先；
工作地址
广州 - 萝岗区 - 广州萝岗区科学大道99号科汇金谷三街5号新粤大厦（6-11层）
查看地图
职位发布者:
Mr. Liu
招聘负责人
聊天意愿
暂无
回复率--  用时--
简历处理
超快
处理率100%  用时1天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
AdMaster研发部招聘
Hadoop开发工程师
20k-35k /上海 / 经验3-5年 / 本科及以上 / 全职
hadoop
Scala
spark
hive
大数据
Java
11:25  发布于拉勾网职位诱惑：
优秀团队,大有可为,技术领先,行业领先
职位描述：
岗位职责：
1、构建分布式大数据服务平台，参与海量数据存储、实时计算、实时查询，系统运维等工作
2、服务各种业务需求
任职要求：
1、计算机或相关专业（3年以上工作经验）
2、精通Java/Scala程序开发，熟悉Linux开发环境
3、熟练掌握Spring，Spring Boot, MyBatis等Web框架及常用组件
4、熟悉常用开源分布式系统，精通Hadoop/Hive/Spark/Kafka/Flink/HBase之一源代码者优先
5、熟练掌握常用的数据结构和算法
6、具有良好的沟通协作能力和分享精神
7、对Greenplum、Kylin、Impala、ElasticSearch等系统有深入研究者加分
工作地址
上海 - 普陀区 - 金沙江路 - 金沙江路1038号华大科创楼
查看地图
职位发布者:
E
Emily
招聘经理
聊天意愿
强
回复率67%  用时9分钟
简历处理
超快
处理率96%  用时1天
活跃时段
全天
晚上8点最活跃
-------------------------------------------------
极光数据部招聘
Hadoop工程师
10k-15k /深圳 / 经验不限 / 本科及以上 / 全职
数据
大数据
15:08  发布于拉勾网职位诱惑：
14薪、弹性工作、扁平管理、工作餐、下午茶
职位描述：
工作职责
1、负责Hadoop集群的部署，运维和二次开发
2、负责周边系统的开发，如调度系统，监控告警系统等
3、负责基础数据等清洗，处理等
职位要求
1、本科以上学历，计算机相关专业
2、二年以上 Java/Python 开发经验
3、熟悉 Hadoop/HBase/Zookeeper/Spark 等的运行机制和工作原理
4、熟悉Linux/Unix平台，熟悉bash
5、善于学习新知识，有较强的逻辑分析和解决问题的能力
6、有较强的责任心和沟通能力
工作地址
- 南头湖滨中路智恒战略性新兴产业园7栋5楼
查看地图
职位发布者:
Maggie
HRBP
聊天意愿
暂无
回复率--  用时--
简历处理
超快
处理率100%  用时1天
活跃时段
下午
下午2点最活跃
-------------------------------------------------
江苏亿科达大数据开发部招聘
hadoop开发工程师
15k-20k /深圳 / 经验3-5年 / 本科及以上 / 全职
高级
中级
spark
hadoop
数据挖掘
大数据
1天前  发布于拉勾网职位诱惑：
晋升机会多,氛围好,领导好,环境佳
职位描述：
1、本科以上学历、3年以上大数据开发或管理经验；  
2、精通oracle数据库、具备优秀的sql编写和调优能力；
3、熟悉 Hadoop、yran、hive 或 Spark 等分布式系统的工作原理，具备较强的架构、性能优化能力； 
4、有主导完成优秀应用或大型大数据项目开发经验者优先；
5、熟悉java等开发语言，熟悉常用的分布式系统；
6、有良好的团队协作与沟通能力。
工作地址
深圳 - 福田区 - 新洲 - 购物公园
查看地图
职位发布者:
W
weihy@h...
hr
聊天意愿
弱
回复率15%  用时7分钟
简历处理
超快
处理率100%  用时1天
活跃时段
全天
早9点最活跃
-------------------------------------------------
徐工信息软件研发部招聘
Hadoop
12k-24k /南京 / 经验3-5年 / 本科及以上 / 全职
大数据
hadoop
数据分析
数据挖掘
09:17  发布于拉勾网职位诱惑：
五险一金,周末双休,带薪假期,扁平化管理
职位描述：
岗位职责：
1、基于hadoop生态的大数据存储平台搭建和部署; 
2、承担数据抽取、清洗、转化等数据处理程序开发； 
3、商用平台指标数据挖掘。
4、数据仓库的设计，开发，维护
5、完成日常数据分析查询需求
任职要求：
1.三年以上工作经验，一年以上大数据项目开发/维护经验，精通Hadoop技术体系，熟练掌握以下至少两项技能（多者加分）：
.MapReduce、Hbase/Cassandra 、HIVE、Zookeeper、Pig、Sqoop、Flume、Ambari；
2.熟练掌握至少一门主流语言，包括但不限于JAVA、C#；
3.熟练掌握至少一门脚本语言，包括但不限于Python、Perl、Linux/Unix Shell。
岗位福利：
1、五险一金，有竞争力的薪资；
2、各种带薪假期；
3、假期福利、生日福利；
4、员工宿舍、员工食堂、免费班车；
5、出差补助。
工作地址
南京 - 雨花台区 - 新街口 - 软件大道180号
查看地图
职位发布者:
郭女士
HR
聊天意愿
很弱
回复率--  用时4小时
简历处理
快
处理率100%  用时3天
活跃时段
早上
早10点最活跃
-------------------------------------------------
美团点评零售事业部招聘
Hadoop开发
25k-50k /北京 / 经验3-5年 / 本科及以上 / 全职
资深
spark
数据开发
hadoop
大数据
hive
08:43  发布于拉勾网职位诱惑：
技术大牛,技术氛围,免费班车
职位描述：
工作职责
1、参与打造数据中内容的规划、设计、开发和优化工作，实现高质量数据的互通与共享；
2、参与数据模型体系构建及数据主题设计和开发，搭建离线、实时数据公共层；
3、参与数据产品与应用的数据研发，发掘数据商业价值，打造极致体验的数据产品； 
4、深入理解数据产品的使用场景，为业务方在可用性、成本上做更好的设计做参考。 
任职要求
1、熟悉数据仓库建模理论，3年以上相关领域实践经验；
2、熟悉Hadoop、Hive、Spark等大数据技术；
3、熟练使用Python/Java或其他语言进行复杂业务逻辑的数据处理工作，具备海量数据处理以及性能优化的能力；
4、对MySQL、Redis、HBase等数据库有一定的了解和使用经验；
5、对olap，多维分析及kylin熟悉的更好；
6、思路清晰，具备良好的沟通能力和理解能力，较强的学习能力以及快速解决问题的能力；
7、对新技术，新事物有很好的探索和求知欲。
工作地址
北京 - 朝阳区 - 望京 - 望京恒电大厦
查看地图
职位发布者:
欧阳
HR
聊天意愿
一般
回复率47%  用时4分钟
简历处理
快
处理率25%  用时1天
活跃时段
全天
早7点最活跃
-------------------------------------------------
蜂投网技术部招聘
hadoop工程师/大数据开发...
10k-15k /长沙 / 经验1-3年 / 学历不限 / 全职
中级
数据分析
算法
数据挖掘
深度学习
大数据
11:08  发布于拉勾网职位诱惑：
五险一金,朝九晚五,免费中餐晚,带薪年假
职位描述：
大数据开发岗位
1、熟悉MySQL/MongoDB/Redis/HDFS等常用数据库，掌握SQL开发技术；
4、熟悉Hadoop/HBase/Hive/MapReduce/Spark等相关技术，并有实际的开发经验
5、熟悉java和shell，可以熟练的使用linux系统，了解Linux群集技术者优先
6、掌握MapReduce处理问题思想，熟悉分布式计算模型或有高效索引技术经验者优先;
7、擅长数据分析，对数据具有足够的敏感性，熟悉常规的数据统计、挖掘知识、统计方法；

任职要求：
1、计算机算法分析、数据挖掘、机器学习、大数据分析等专业
2、对数据挖掘、智能推荐、机器学习、领域语言或自然语言分析在互联网行业的应用有深入了解，熟悉相关领域当前热点和前沿技术，对BI有完整的、系统的认识；熟练掌握JAVA编程语言；
3、有相关数据分析和数据挖掘相关学术研究或工作经验。有成功的项目经验优先
工作地址
长沙 - 天心区 - 芙蓉南路中信凯旋蓝岸16栋2-3层
查看地图
职位发布者:
hr
职位发布者
聊天意愿
一般
回复率56%  用时5分钟
简历处理
超快
处理率100%  用时1天
活跃时段
下午
下午2点最活跃
-------------------------------------------------
雁联计算事业部招聘
Hadoop
10k-18k /深圳 / 经验1-3年 / 本科及以上 / 全职
金融
hadoop
p2p
大数据
13:32  发布于拉勾网职位诱惑：
国企背景，薪资待遇完善，发展前景好
职位描述：
1、有数据仓库开发经验，掌握hive优化，精通Oracle、SQL优化优先。
2、Hadoop开发工作经验一年以上，统招本科以上学历优先；
3、有互联网、金融等大型企业开发工作经验者优先。
工作地址
深圳 - 福田区 - 岗厦 - 深南大道国际创新中心C座13楼
查看地图
职位发布者:
周小姐
HR
聊天意愿
一般
回复率50%  用时57分钟
简历处理
超快
处理率100%  用时1天
活跃时段
全天
下午2点最活跃
-------------------------------------------------
数美研发部招聘
Hadoop研发工程师
25k-50k /北京 / 经验1-3年 / 本科及以上 / 全职
hadoop
大数据
数据挖掘
12:20  发布于拉勾网职位诱惑：
源码研发,大牛如云,技术氛围,大佬领投
职位描述：
360、小米、百度等顶级互联网公司联合投资，顶级大数据公司

岗位职责
1. 主导数美大数据平台的设计与开发，解决海量数据面临的挑战；
2. 管理、优化并维护Hadoop、Spark等集群，保证集群规模持续、稳定；
3. 负责HDFS/hive/HBase的功能、性能和扩展，解决并实现业务需求；
4. 协助建立数据模型，对数据进行挖掘、优化及统计。

任职要求
1、硕士及以上学历，1年及以上相关经验；
2、熟悉Hadoop/HBase/Spark/Storm/Hive，熟悉数据挖掘策略与算法；
3、熟悉分布式系统设计范型，有大规模系统设计和工程实现的经验 ；
4、数据控，善于发现问题、解决问题；


公司福利待遇
有竞争力的薪酬
期权奖励
五险一金+商业保险
午餐+晚餐补助
交通+通讯+电脑补贴
结婚+生育+丧葬+住院礼金
伯乐奖金
年假8天起+带薪病假
年度体检、零食畅享、团队建设、生日会、弹性办公


【关于数美】www.ishumei.com
 数美（全称北京数美时代科技有限公司）成立于2015年6月，是一家专业的大数据科技公司。数美依托先进的核心AI技术和海量的数据基础，致力于解决多场景欺诈问题，为客户提供专业、可信赖的服务。团队均来自百度、阿里、腾讯、360、小米等顶尖互联网公司，在大数据、人工智能、机器学习、金融风控等领域有着丰富的实践经验。目前，业务已覆盖金融、支付、直播、社交、电商、O2O等为代表的多个行业领域，其中包括中信银行、用钱宝、人人贷、51信用卡、360、小米、58同城、爱奇艺、熊猫直播、花椒、唱吧等知名企业，截止到2017年6月，服务客户突破1000家。作为大数据反欺诈专业品牌，数美将持续挖掘数据价值，为金融机构、互联网企业提供智能、创新的一站式反欺诈综合解决方案
…………………………………………………………………………
了解更多
数美公司介绍
https://www.ishumei.com/aboutUs/introduction.html
数美团队介绍
https://www.ishumei.com/aboutUs/team.html
数美产品介绍
https://www.ishumei.com/product/creditFengkong.html
数美解决方案介绍
https://www.ishumei.com/solution/finance.html

工作地址
北京 - 朝阳区 - 望京 - 望京诚盈中心
查看地图
职位发布者:
raoying
HR
聊天意愿
很弱
回复率--  用时1分钟
简历处理
超快
处理率100%  用时1天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
重庆易宠科技有限公司技术研发中心招聘
Hadoop工程师
8k-15k /重庆 / 经验3-5年 / 本科及以上 / 全职
Java
spark
hadoop
大数据
1天前  发布于拉勾网职位诱惑：
五险一金,周末双休,福利多,氛围好
职位描述：
工作描述：
 1、负责Hadoop、HBase、Hive、Spark等大数据平台 规划、部署、监控、系统优化等；
2、负责公司大数据平台的运维管理工作，集群容量规划、扩容及性能优化；
3、处理公司大数据平台各类异常和故障，确保系统平台的稳定运行；
4、设计实现大规模分布式集群的运维、监控和管理平台；
5、深入研究大数据业务相关运维技术，持续优化集群服务架构，探索新的大数据运维技及发展方向；
 任职要求:
1、3年以上工作经验，精通Hadoop、Hbase、Hive、Spark，具有完整项目实战经验，熟悉分布式计算实施过程中的各种问题。
2、熟悉Hadoop大数据生态圈，包括但不限于Sqoop、Kafka、Flume等
3、有开发经验，精通JAVA及一门以上脚本语言(shell/perl/python等),熟练掌握linux常规命令与工具;
加分项：
1、熟悉Apache Kylin或者其他OLAP系统
2、有数据仓库实施及管理或数据挖掘经验者
3、对数据仓库和数据挖掘理论感兴趣且有一定深度的研究。
4、熟悉阿里云的大数据方案
工作地址
重庆 - 渝北区 - 庆两江新区金开大道西段互联网产业园18号楼
查看地图
职位发布者:
张女士
招聘官
聊天意愿
弱
回复率17%  用时44分钟
简历处理
快
处理率28%  用时1天
活跃时段
下午
下午5点最活跃
-------------------------------------------------
海雕网络科技技术部招聘
hadoop工程师
10k-15k /上海 / 经验3-5年 / 大专及以上 / 全职
高级
中级
初级
hadoop
大数据
Java
2天前  发布于拉勾网职位诱惑：
午餐补贴,扁平管理,带薪年假,五险一金
职位描述：
职位描述：
1.负责公司大数据平台产品的技术工作，包括存储、处理、分析、挖掘、架构设计、研发工作；
2.负责设计、构建和优化基于hadoop/Hbase的存储平台架构；
3.负责整体提升hadoop/Hbase/Spark集群的高可用性、高性能、高扩展特性；
4.根据业务需求，提出最优的技术解决方案；
任职要求
1.相关工作2~5年经验
2.扎实的Java、Scala语言基础，对JVM运行机制有深入了解
3.熟悉hadoop & Spark & flume系统，熟悉HDFS、HIVE、HBase等子系统架构
4.熟悉Kafka、LogStash、Redis等数据中间件
5.良好的SQL语句功底，熟悉MySQL、PostgreSQL、Oracle数据库中的一种
6.具备Hadoop/Hbase/Hive/Zookeeper等大规模集群的开发、运维经验者优先
7.对文本分词有实战经验，熟悉Solr／Lucene开发优先。
8.具有良好的沟通协作能力和分享精神
工作地址
上海 - 闵行区 - 七宝 - 新龙路1333弄69号510室
查看地图
职位发布者:
H
hr
职位发布者
-------------------------------------------------
广州智干电子商务科技有限公司技术部招聘
hadoop开发工程师
10k-20k /广州 / 经验1-3年 / 本科及以上 / 全职
初级
hadoop
大数据
数据挖掘
20:02  发布于拉勾网职位诱惑：
五险一金,定期体检,法定假期,员工旅游
职位描述：
由于岗位称谓每个公司不尽相同，所以发布职位时同一职位我们会以不同标题发布多条。
请仔细阅读职位说明且认真投递简历，勿重复投递（重复投递不会增加面试几率）。

【岗位职责】
1、参与建设公司数据仓库，根据业务逻辑整合优化平台数据流程；
2、对接数据采集系统，负责数据仓库的数据集成和处理程序开发与优化；
3、协助运维大数据平台软件环境；
4、对接数据分析小组完成数据各种转换和提取操作；
5、完成公司安排的其他数据相关工作和任务；
【我们对您期望】
1、计算机或相关专业，全日制本科以上学历，2年以上大数据开发经验；
2、精通java后台程序开发，熟悉并发编程，熟练使用mysql、mongodb等数据库；
3、熟悉hadoop体系相关技术,有hive程序的实战开发经验；
4、熟悉Hadoop运行监控及调优技术；
5、熟悉linux开发环境，熟悉python、shell中的一种；
6、对数据结构、算法有深刻理解，有hadoop等系统的源代码阅读经验者优先。
【优先条件】
1、对数据结构、算法有深刻理解；
2、有hadoop等系统的源代码阅读经验者优先。
工作地址
广州 - 海珠区 - 赤岗 - 琶洲大道83号宝地广场16层
查看地图
职位发布者:
智干电商
职位发布者
聊天意愿
很弱
回复率--  用时50分钟
简历处理
超快
处理率100%  用时2天
活跃时段
下午
下午5点最活跃
-------------------------------------------------
HelloTalk招聘
Hadoop工程师
20k-25k /深圳 / 经验3-5年 / 本科及以上 / 全职
hadoop
spark
算法
大数据
Java
09:23  发布于拉勾网职位诱惑：
公司氛围好，老板nice，零食下午茶
职位描述：
Hadoop工程师
HelloTalk是全球最大的跨文化交流社区，有来自全球200个国家近900万用户。      
HelloTalk的使命是促进文化交流，增加世界上不同文化和国家的人，彼此间的了解。
我们的愿景是成为全世界各国人连接的桥梁。透过互助学习、跨文化社区、语言学习服务等，HelloTalk打破语言和文化的障碍。
让我们一起，让语言学习变得有趣、自然和生动，让全世界没有难学的语言！

工作职责：
1、负责公司的大数据处理框架的研发工作，设计与开发分布式存储、数据处理与分析架构；
2、负责基于Hadoop技术的海量数据处理，构建基于Hadoop生态（如Sqoop、Kafka、Hive、Spark等）下的准实时多维分析系统和深度挖掘系统

任职资格：
1、本科以上学历，3年以上相关工作经验 
2. 有Hadoop集群搭建和管理经验者优先考虑，有海量数据挖掘算法开发经验者优先考虑，兼有Oracle，MySQL，NoSQL开发经验者优先考虑，具备丰富的大中型开发项目的总体规划、方案设计经验者优先考虑； 
3.具备以下技能，精通者优先考虑： 
（1）了解大数据分析处理（Hadoop，HDFS, MapReduce，Hbase，Pig，Hive）等技术内部机制； 
（2）扎实的Java语言基础，熟悉Java开发工具和调试工具的使用； 
（3）熟悉Linux系统，熟练使用shell/perl/python脚本处理问题； 
（4）熟悉主流数据挖掘算法开发。
工作地址
深圳 - 南山区 - 科技园 - 赋安大厦B座903
查看地图
职位发布者:
HelloTalk
HelloTalk
聊天意愿
很弱
回复率--  用时10分钟
简历处理
超快
处理率100%  用时2天
活跃时段
下午
下午6点最活跃
-------------------------------------------------
武汉佰钧成技术有限公司ISBG-BU2招聘
HADOOP
17k-30k /深圳 / 经验5-10年 / 大专及以上 / 全职
Python
spark
hadoop
2天前  发布于拉勾网职位诱惑：
项目稳定
职位描述：
大数据相关工作3年以上；2. Java、Python中至少一门语言的5年以上的开发经验；3. 熟悉运用MapReduce、HDFS、Hive、Hbase、Sqoop、storm、kafka、mongoDB、redis、elasticSearch中至少4种组件，并基于这4种以上组件的开发经验；4. 熟练使用关系型数据库；5.  大数据组件性能、存储优化经验丰富；6.  3年以上shell编程经验
工作地址
深圳市 - 龙华新区 - 观澜 - 龙华新区清湖街道宝能科技园9栋C座7-9楼
查看地图
职位发布者:
魏小姐
HR
聊天意愿
强
回复率75%  用时38分钟
简历处理
暂无
处理率--  用时--天
活跃时段
早上
早9点最活跃
-------------------------------------------------
新蛋信息技术（中国）有限公司MIS招聘
Hadoop开发
15k-22k /上海 / 经验3-5年 / 本科及以上 / 全职
hadoop
Java架构
大数据
hbase
Java
电商
1天前  发布于拉勾网职位诱惑：
美国电商,大数据平台,技术氛围好
职位描述：
岗位职责：
1、基于大数据技术实现业务Service的重构；
2、从事大数据平台化的开发，提升海量数据的处理性能；
3、电子商务数据平台的维护优化和重构；
4、集群运维，解决各种疑难杂症，对系统进行性能调优; 
任职要求：
1、计算机相关专业本科及以上学历；
2、一年以上java开发经验，两年以上大数据开发经验；
3、熟悉JavaScript、html、css等web前端常用开发技术；
4、精通Spring、Hibernate、iBatis开发，对虚拟机及Linux下的开发环境有较深厚的开发经验；
5、熟悉网络编程，具有设计和开发对外API接口经验和能力。
6、熟悉Hadoop、Redis、Spark、HBase、Storm、Kafka、Flume等类框架技术者优先；
7、有开源代码或项目经验优先。
工作地址
上海市 - 长宁区 - 镇宁路 - 延安西路726号8楼
查看地图
职位发布者:
新蛋集团
软件技术研发
聊天意愿
暂无
回复率--  用时--
简历处理
超快
处理率82%  用时1天
活跃时段
早上
早10点最活跃
-------------------------------------------------
东方国信联通事业部-大数据中心招聘
Hadoop开发工程师
8k-16k /上海 / 经验1-3年 / 本科及以上 / 全职
hadoop
10:32  发布于拉勾网职位诱惑：
职位好、薪资高
职位描述：
职位描述：
1、Hive HQL脚本创建、自定义UDF函数编写；
2、Hive优化，包括HQL优化、自定义UDF调优等；
3、Hive开发文档的编写；
4、负责数据的提取、统计分析、Hive数据导入、导出等；
5、熟练使用linux操作系统，具备shell编写能力；
6、至少熟练掌握Hadoop、Hive、Hbase、Zookeeper、Storm中的3项技术；
7、具备Hadoop、Hive、Hbase、Zookeeper、Storm的日常监控和故障排查能力；
8、负责建立数据质量标准与流程，提高数据的质量和完整性；
9、兼具数据挖掘、数据模型设计能力者优先考虑。
职位要求：
1、211、985院校大学本科以上学位，计算机或相关专业本科以上学历
2、.熟悉Hadoop、Hive、Hbase、Zookeeper、Storm等主流大数据技术
3、具备JAVA报错信息的判读能力和解决能力
工作地址
上海 - 徐汇区 - 漕河泾 - 钦江路333号 37号楼 4楼
查看地图
职位发布者:
H
hr-icrm
职位发布者
聊天意愿
很弱
回复率--  用时1分钟
简历处理
快
处理率76%  用时1天
活跃时段
早上
早10点最活跃
-------------------------------------------------
电魂网络运维部招聘
Hadoop工程师
15k-25k /杭州 / 经验3-5年 / 本科及以上 / 全职
hadoop
09:52  发布于拉勾网职位诱惑：
六险一金 部门团建 带薪年假 绩效奖金等
职位描述：
工作职责：
1. 负责公司大数据平台基础架构的研发
2. 日常数据系统开发
3. 海量数据分析和专项的数据挖掘
4.负责调优数据平台性能，保证数据平台高可用性

任职要求：
1. 具有搭建维护维护 hadoop 相关环境, troubleshooting, turning的经验
2. 熟悉jvm 运行机制，有 java 开发经验优先
3. 熟练的 java、shell、python 开发能力
4. 有海量数据开发经验优先
工作地址
杭州 - 滨江区 - 西兴 - 滨安路435号电魂大厦
查看地图
职位发布者:
电魂HR
招聘
聊天意愿
弱
回复率14%  用时10分钟
简历处理
超快
处理率100%  用时2天
活跃时段
全天
早9点最活跃
-------------------------------------------------
极光研发中心招聘
高级Hadoop开发工程师
20k-30k /深圳 / 经验3-5年 / 本科及以上 / 全职
资深
高级
hadoop
Hadoop集群
大数据
15:08  发布于拉勾网职位诱惑：
五险一金、14薪/年、下午茶、工作餐等等
职位描述：
【工作职责】：
1.负责公司Hadoop系统的底层搭建，构建公司统一的离线和实时计算平台。 
2.负责公司日志系统及ETL系统的设计和实现。 
3.负责公司数据体系的架构设计和规划，充分发挥公司的数据价值。 
4.跟踪Hadoop生态环境的最新进展。 
【岗位要求】： 
1、本科以上学历，熟悉Hadoop生态环境，对Hadoop, Hbase, Hive, Storm等至少一个项目有着深入的了解。 
2.扎实的Java基础，对至少一门动态语言有过使用经验。 
3.熟悉Linux系统常用操作。 
4.对数据有着强烈兴趣，有部署大规模Hadoop集群的经验者优先。 
5.良好的学习能力，保持对新技术的敏感性。
工作地址
深圳 - 南山区 - 翻身路 - 关口二路智恒战略性新兴产业园7栋5楼
查看地图
职位发布者:
Maggie
HRBP
聊天意愿
暂无
回复率--  用时--
简历处理
超快
处理率100%  用时1天
活跃时段
下午
下午2点最活跃
-------------------------------------------------
良品铺子电商技术中心招聘
hadoop 开发工程师
8k-15k /武汉 / 经验3-5年 / 本科及以上 / 全职
中级
MySQL
大数据
Java
架构
10:11  发布于拉勾网职位诱惑：
成长空间,职位晋升
职位描述：
工作职责：
1、负责数据应用的架构设计与性能优化；
2、负责日常BI应用报表的开发；
3、软件核心模块代码的开发、接口工具开发；

任职资格：
1、2年以上大数据（基于HadoopSpark）相关开发经验；
2、精通Java编程，精通JavaEE、SOA等软件架构；
3、熟悉hadoopsparkhivesqoop框架, 熟悉hdfs，对其源码有一定了解；
4、熟悉Linux操作系统，具备一定Shell编程能力；
5、精通Spring、Struts、Ibatis等框架；
工作地址
武汉 - 江汉区 - 常青 - 发展大道164号武汉科技大厦606室
查看地图
职位发布者:
X
xiaoying
招聘助理
聊天意愿
弱
回复率17%  用时31分钟
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午5点最活跃
-------------------------------------------------
武汉佰钧成技术有限公司BU2招聘
Hadoop工程师
15k-25k /广州 / 经验5-10年 / 大专及以上 / 全职
大数据
python
14:28  发布于拉勾网职位诱惑：
薪资丰厚,前沿技术,福利齐全
职位描述：
任职要求：
1、5年以上Linux 经验，1年以上Hadoop（HDFS & MapReduce）相关经验，全日制大专以上学历；
2、深入理解Hadoop设计原理，集群连通性，安全和影响大规模系统性能的因素，深刻理解自动化工具（Puppet, chef, ansible)，熟练至少一种技术：Python，Perl，ruby或Bash；
3、有远程监控和用Nagios，ELK处理问题的经验，能够用Chef, Puppet, Ansible or a shell创建自动化；
4、良好的合作和沟通能力，能跨团队合作。
工作地址
广州 - 天河区 - 天河城 - 太古汇
查看地图
职位发布者:
李青
HR
聊天意愿
强
回复率67%  用时9分钟
简历处理
暂无
处理率--  用时--天
活跃时段
早上
早10点最活跃
-------------------------------------------------
二维火招聘
Hadoop/spark开发工程师
20k-30k /杭州 / 经验1-3年 / 本科及以上 / 全职
hadoop
spark
hive
大数据
Java
旅游
11:20  发布于拉勾网职位诱惑：
五险及高比例公积金 绩效 年终
职位描述：
职位描述：

岗位职责：
1. 负责公司大数据平台基础架构的研发
2. 日常数据系统开发
3. 负责调优数据平台性能，保证数据平台高可用性
任职要求：
1. 具有搭建维护维护 hadoop 相关环境, troubleshooting, turning的经验
2. 熟悉jvm 运行机制，有 java 开发经验优先
3. 熟练的 java、shell、python 开发能力
4. 有海量数据开发经验优先


加分项：
• 在GitHub或其他平台上有过开源项目 
• 有个人技术博客，公开发布过技术文章、论文等
• 喜爱运动
• DOTA & LOL
我们将能提供： 
• 宽松的办公环境
• 五险一金是必须的
• 极具潜力的期权数
• 灵活的考勤方式
• 足够多的水果和零食
• 免费的咖啡和茶
• 每年不少于一次旅游
• 充分的学习机会（培训与分享）
• 餐补+年休假
• 报销所有职业书籍
你要能扛得住： 
• 做为创业公司，加班是必然的，但是会有调休
• 边做业务边改进架构的压力
• 业务快速增长下，能力也要快速提升
工作地址
杭州 - 拱墅区 - 小河 - 二维火科技大厦
查看地图
职位发布者:
易微
HR
聊天意愿
一般
回复率42%  用时15分钟
简历处理
快
处理率11%  用时1天
活跃时段
全天
晚上8点最活跃
-------------------------------------------------
明略数据技术部招聘
Hadoop工程师
8k-15k /苏州 / 经验3-5年 / 本科及以上 / 全职
中级
spark
hadoop
大数据
数据挖掘
1天前  发布于拉勾网职位诱惑：
六险一金,团建旅游,定期体检
职位描述：
工作职责：

1、负责大数据应用相关解决方案的设计，进行技术方案材料的撰写；

2、负责大数据应用相关产品的整体架构设计，进行大数据平台上数据挖掘产品的规划及研发；

3、完成各种面向业务目标的数据分析模型的定义和应用开发；

4、开发具有数据分析、数据挖掘能力的创新型产品； 

岗位要求：

1、计算机相关专业，本科及以上学历，2~3年以上Hadoop相关开发经验；

2、熟悉主流的云计算、大数据产品（hadoop、spark、flume等）和数据分析技术（机器学习)并具有相关项目经验；

3、精通算法设计/数据结构，精通JAVA或C/C++语言编程；

4、熟悉Linux/Unix平台上的开发环境；

5、思路敏捷清晰，良好的表达和理解能力，良好的学习能力，强烈的创新意识；
工作地址
苏州市市市 - 相城区 - 元和 - 苏州市公安局
查看地图
职位发布者:
明略数据HR汪丽
大数据,数据挖掘
聊天意愿
很弱
回复率--  用时3分钟
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
网宿科技信息系统部招聘
Hadoop开发工程师
25k-35k /北京 / 经验3-5年 / 本科及以上 / 全职
hadoop
MySQL
大数据
Java
架构
09:15  发布于拉勾网职位诱惑：
六险一金,补充医疗,上市公司,地铁周边
职位描述：
工作职责：
1.负责公司BI/Bigdata平台的搭建和开发，负责产品主要部分代码编写；
2.带领团队做BI/Bigdata业务需求分析、架构设计，负责BI/Bigdata详细设计，开发；
3.负责BI/Bigdata数据收集、数据模型设计、报表开发，仪表盘开发，系统集成；
4.支持运营，根据业务需求，测试问题，持续修改完善产品,提升性能；
5.服从领导安排，积极做好领导交代的其他工作。
任职要求：
1.计算机或数学专业本科以上学历,5年以上工作经验；
2.熟悉Java语言；精通Hadoop；
3.熟练掌握SSH等主流开发技术,精通JavaScript, HTML/CSS，精通jquery/bootstrap 等流行框架；
4.熟悉Jetty/Tomcat等WEB服务器；熟悉Mysql/Oracle等流行数据库,熟悉SQL,熟悉NoSQL；
5.熟悉Linux，熟悉Maven, 熟悉Git/SVN,熟悉自动化部署；
6.熟悉大数据开发；
7.有激情，有责任，执行力强，能够承受较大工作压力，有团队协作精神；
8.热爱开源，有全栈开发经验优先；
9.有团队管理经验优先;
工作地址
北京 - 海淀区 - 北航 - 学院路39号唯实大厦6层
查看地图
职位发布者:
网宿科技HR
网宿科技股份有限公司
聊天意愿
暂无
回复率--  用时--
简历处理
超快
处理率100%  用时1天
活跃时段
全天
早9点最活跃
-------------------------------------------------
58到家招聘
Hadoop高级研发工程师
12k-20k /长沙 / 经验3-5年 / 本科及以上 / 全职
数据分析
数据开发
ETL
数据挖掘
大数据
数据仓库
12:04  发布于拉勾网职位诱惑：
独角兽公司，背靠58同城、腾讯、阿里
职位描述：
岗位职责： 
1. 负责数据仓库应用产品设计和开发；
2. 负责数据仓库建模、数据预处理子系统的设计和开发；
3. 负责数据仓库ETL流程的优化及解决ETL相关技术问题。
  岗位要求：
1. 熟练数据仓库的ETL的开发和数据建模，2年以上数据仓库实施经验； 
2. 熟悉分布式数据库平台开发（hadoop，spark等），熟悉分布式平台工作原理；
3. 至少熟练使用shell、python等脚本语言之一； 
4. 有DBA经验或分布式计算平台经验者优先； 
5. 有在网站公司或海量数据处理工作经验，数据分析和挖掘经验者优先。
工作地址
长沙 - 岳麓区 - 麓谷 - 中电软件园17栋
查看地图
职位发布者:
58daojia91
HR
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
暂无
--点最活跃
-------------------------------------------------
PPTV聚力招聘
Hadoop开发工程师
14k-22k /上海 / 经验1年以下 / 本科及以上 / 全职
高级
spark
hadoop
大数据
Java
11:53  发布于拉勾网职位诱惑：
公司平台大前景好 有餐补交补
职位描述：
职位描述：
  1. 大数据平台开发，包括部署、实施；
2. 大数据平台运行性能、可用性、扩展性等监控与优化调控；
3. 负责基于Hadoop/Spark生态系统的研发；
4. 负责基于Spark的计算和挖掘研发；
    岗位要求：
  1、扎实的Java、Scala语言基础，对JVM运行机制有深入了解；
2、熟悉Hadoop、Spark并有丰富的开发经验；
3、熟练使用java语言，并掌握spring、mybatis等开源J2EE框架。使用java、scala、python等开发语言中的一种，有python和scala实际使用经验更佳；
4、有hadoop和spark实际开发经验。了解大数据组件的使用限制和应用场景，如hdfs,yarn,hbase,hive,flume,kafka,zk,impala,kylin,kudu,ES,Storm、MongoDB等。读过spark源码更佳；
5、熟悉mysql、ElasticSearch、Redis等关系型或NoSQL数据库，了解应用场景和使用限制。有实际调优经验者更佳。
6、熟悉linux常用命令，有实际CDH或HDP或apache版本的hadoop部署经验者优先；
7、熟悉并行计算或者分布式计算，熟悉Spark框架,熟练掌握RDD，SQL, Streaming, MLLIB，SparkR编程；
8、英文文档阅读无障碍、熟练掌握常用设计模式、熟练使用maven、git；
9、有深入研究过Hadoop/Spark源码者优先；
10、深入理解MapReduce工作原理，HDFS分布式文件系统架构；熟练掌握Hadoop/Hive/HBASE的运维和调优方法；
11、掌握或使用过Storm、Spark、flume、kafka等工具；
12、1年以上大数据相关工作经验，最好参与并成功部署过1个日均TB级的集群项目。
  工作地址
上海 - 浦东新区 - 花木 - 陆家嘴软件园
查看地图
职位发布者:
bole
HR
聊天意愿
暂无
回复率--  用时4分钟
简历处理
暂无
处理率--  用时--天
活跃时段
全天
早10点最活跃
-------------------------------------------------
个推数据部招聘
hadoop开发工程师（诚聘）
10k-15k /杭州 / 经验1-3年 / 本科及以上 / 全职
hadoop
数据挖掘
大数据
09:27  发布于拉勾网职位诱惑：
16-18薪 带薪年假 五险一金 生日Party 餐补
职位描述：
职位描述：
岗位职责： 
研究并开发基于Hadoop, hive, hbase, spark的海量（百TB级）数据处理分析程序，使用java，python等开发数据服务接口等

任职要求： 
1、 掌握java开发，面向对象的设计方法，语言、框架不限，对jvm 内存管理熟悉最佳
2、 掌握 hadoop/hive/spark/hbase, 如果对于相关开源框架有所研究最佳 
3、 熟悉mysql数据库，并具有一定的SQL功底； 
4、 熟悉python，scala等语言更佳。
5、 对数据建模、存取、处理、可视化等相关技术有很强的学习热情
工作地址
杭州 - 西湖区 - 古墩路 - 西斗门路福地创业园
查看地图
职位发布者:
江婷婷
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
全天
早10点最活跃
-------------------------------------------------
东方国信招聘
Hadoop开发工程师
6k-10k /西安 / 经验不限 / 大专及以上 / 全职
银行
spark
hadoop
软件开发
大数据
2018-01-05  发布于拉勾网职位诱惑：
年终奖金、五险一金、餐补、定期体检等
职位描述：
岗位职责：
1、参与 Hadoop项目的数据模型设计和应用的研发；    
2、负责公司银行Hadoop平台项目运维和优化工作；    
3、不断提升公司BI及大数据产品的质量和响应速度。    
任职要求：
1、大专以上学历，计算机及相关专业，具有2年以上J2EE系统应用开发经验，对分布式计算有深刻理解，熟悉 Linux 系统环境，致力于大数据项目的研发；    
2、熟悉Hadoop平台及HBase子项目，有过Hadoop及Hbase平台的搭建与开发经验；    
3、熟悉HDFS的原理、特性和常用配置，了解MapReduce程序的开发过程； 4、熟悉Hadoop、hbase、hive、scribe、flume、storm等分布式相关技术者优先。
工作地址
西安 - 高新技术产业开发区 - 沣惠南路 - 未来国际
查看地图
职位发布者:
yitongz...
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
一般
处理率47%  用时3天
活跃时段
早上
早9点最活跃
-------------------------------------------------
Hellobike哈罗单车技术部招聘
hadoop开发
20k-40k /上海 / 经验5-10年 / 大专及以上 / 全职
资深
高级
大数据
数据分析
1天前  发布于拉勾网职位诱惑：
年底双薪,年假多,晋升快
职位描述：
【岗位职责】
1、负责数据统计与分析的研发与维护；
2、根据产品经理和运营团队等的统计需求，进行开发实现；
3、负责对用户行为数据的深度挖掘，以数据指导产品改善；

【任职要求】
1、全日制本科及以上学历，3年以上工作经验；
2、Java基础扎实，熟悉Netty、IBatis等开源框架，懂JVM调优更佳；
3、熟悉HBase、Spark/Storm、MapReduce等数据框架；
4、熟悉Kafka、LogStash、Redis等数据中间件；
5、良好的SQL语句功底，熟悉MySQL、PostgreSQL、Oracle数据库中的一种；
6、有日志收集相关经验或者数据仓库建设和BI经验优先；
7、逻辑清晰，快速的学习能力及良好的沟通能力。
工作地址
上海 - 闵行区 - 莘庄 - 秀文路898号西子国际1栋5楼
查看地图
职位发布者:
F
Frank
HR
聊天意愿
很弱
回复率--  用时13分钟
简历处理
快
处理率100%  用时3天
活跃时段
全天
早11点最活跃
-------------------------------------------------
上海宏鹿信息技术服务有限公司技术研发中心招聘
Hadoop开发工程师
15k-30k /上海 / 经验3-5年 / 本科及以上 / 全职
硬件制造
hadoop
数据分析
spark
大数据
2018-01-17  发布于拉勾网职位诱惑：
弹性工作,带薪年假,员工旅游,年终奖
职位描述：
1、Hadoop集群设计包括软硬件架构、节点配置、网络、存储和容量规划；
2、大数据平台运行性能、可用性、扩展性等监控与优化调控；
3、负责基于Hadoop/Spark生态系统的研发；
4、责基于Spark的计算和挖掘研发
5、基于Hadoop各种开发工具和框架实施数据采集、分析和报表。


任职资格：
1、熟练掌握Java或Scala语言；
2、熟悉Java、Python、Shell语言，较强的独立开发能力，具备良好的代码风格；
3、具备以下1种或多种工具的开发和实施经验：Java-Mapreduce, Hive, PIG, Sqoop, Flume, HBASE, Cassandra, MangoDB, CouchDB, Spark, Shark；
4、有良好的Hadoop上分布式研发的经验，熟悉MR编程；
5、具有HBase、Hive、Storm、Spark相关的实际开发经验；
6、有独立分析和解决问题的能力；
7、能够承担一定工作压力，具备创新思维、具备团队协作精神。
  工作地址
上海 - 浦东新区 - 张江 - 盛夏路666号D栋6楼
查看地图
职位发布者:
宗
宗勤红
职位发布者
聊天意愿
弱
回复率11%  用时2小时
简历处理
暂无
处理率10%  用时--天
活跃时段
下午
下午6点最活跃
-------------------------------------------------
云学堂技术和研发招聘
Hadoop运维开发工程师
15k-20k /苏州 / 经验3-5年 / 本科及以上 / 全职
运维
hadoop
大数据
信息安全
15:08  发布于拉勾网职位诱惑：
运维
职位描述：
岗位要求：
1. 负责公司大数据集群的运维工作,保证其可用和稳定性 
2. 负责离线及实时集群规划、安装、运维监控以及集群性能优化 
3. 负责离线及实时日志的收集清洗等 
4. 搭建企业数据仓库(kylin), 实现低延时的报表服务 
5. 深入研究大数据业务相关运维技术，持续优化集群服务，跟踪Hadoop生态平台的新组件及技术的应用 
任职资格： 
1.1年以上集群环境Hadoop/Impala/Hive/Spark集群相关运维经验。 
2.对各种HDFS/Yarn/Hive/Impala/Spark/Hbase等相关参数调优, 性能优化等有实际经验。 
3.了解熟悉企业数据仓库的建设; 
4.熟悉Kerberos安全认证系统，实施过集群权限管理, 资源隔离方面的方案规划或二次开发工作。
工作地址
苏州 - 高新区 - 苏州高新区竹园路209号2号楼20层
查看地图
职位发布者:
songp
招聘总监
聊天意愿
很弱
回复率--  用时3分钟
简历处理
快
处理率6%  用时1天
活跃时段
下午
下午3点最活跃
-------------------------------------------------
君南圣达大数据事业部招聘
hadoop工程师
15k-30k /北京 / 经验5-10年 / 本科及以上 / 全职
分布式
hadoop
spark
大数据
16:16  发布于拉勾网职位诱惑：
弹性工作制,发展空间大
职位描述：
岗位要求：
1.负责构建和优化基于hadoop/hive/Hbase的存储计算平台；
2.负责整体提升hadoop/Hbase/Storm/Spark集群的高可用性、高性能、高扩展特性；
3.根据业务需求，提出最优的技术解决方案；
4.负责基于hadoop平台mapreduce和hive hql计算任务开发；
任职资格：
1.熟悉Java/shell/python等开发，至少3年以上Hadoop和hive ql相关开发经验；
2.具备数据库系统基本理论知识，至少掌握一种主流商业数据库产品如MySQL的管理和应用，精通SQL语言；
3.对hadoop的Map/Reduce原理有深入研究，有相关项目的实际开发经验；
4.熟悉Hadoop、Hive、spark、hbase、storm等开源项目；
5.对基于hadoop的大数据处理体系有深入认识，具备相关产品（hadoop/spark/storm/hive/hbase）项目应用研发经验；
6.熟悉分布式系统、分布式计算系统的工作机制，能熟练掌握相关核心技术的工作机理。
7.有很强的沟通和理解能力，有良好的团队协作精神、环境适应能力和执行力，在较大压力下保持工作激情；
8、熟悉电信行业者优先。
工作地址
北京 - 西城区 - 西单 - 西单君太百货9楼
查看地图
职位发布者:
P
publicmail
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率100%  用时--天
活跃时段
早上
早10点最活跃
-------------------------------------------------
哔哩哔哩数据平台招聘
技术开发经理/（资深Hadoop...
40k-50k /上海 / 经验5-10年 / 本科及以上 / 全职
资深
hadoop
hive
10:38  发布于拉勾网职位诱惑：
年终奖,六险一金,互联网
职位描述：

工作职责：
1、hadoop大规模集群优化；
2、各种分布式存储方案构建；
3、集群数据安全相关体系建设；
1.、 4.hbase集群整体优化和功能开发；
2.、 5.hive集群性能优化；
3.、 6.Spark／Storm等相关应用，平台开发；
  职位要求
1.、 本科及以上学历，计算机及相关专业；
2.、 具有至少3年以上Java开发经验，熟悉python/shell等脚本语言，熟悉tcp/ip网络协议，熟悉基本存储原理；
3.、 熟悉hadoop相关各种开源项目，Hive/Hbase等有实际应用开发经验，具有一定独立解决问题的能力；
4.、 掌握MapReduce处理问题思想，熟悉分布式计算模型或有高效索引技术经验者优先；
5.、 熟悉多进程、多线程、数据库、IO、内存管理等方面编程者优先；
6.、 相关具体技术方向1年以上项目经验；
7.、 熟悉软件开发过程、相关规范和开发工具，能独立完成软件模块的详细设计；
逻辑思维清晰，沟通能力良好，大型互联网公司相关从业经验优先。
工作地址
上海 - 杨浦区 - 复旦大学 - 国正中心
查看地图
职位发布者:
zhaopin
招聘
聊天意愿
暂无
回复率--  用时4分钟
简历处理
超快
处理率100%  用时1天
活跃时段
下午
下午3点最活跃
-------------------------------------------------
明略数据技术部招聘
Hadoop工程师
10k-20k /南京 / 经验不限 / 本科及以上 / 全职
中级
hadoop
大数据
1天前  发布于拉勾网职位诱惑：
成长快,福利好
职位描述：
工作职责：
1、负责大数据应用相关解决方案的设计，进行技术方案材料的撰写；
2、负责大数据应用相关产品的整体架构设计，进行大数据平台上数据挖掘产品的规划及研发；
3、完成各种面向业务目标的数据分析模型的定义和应用开发；
4、开发具有数据分析、数据挖掘能力的创新型产品； 
岗位要求：
1、计算机相关专业，本科及以上学历，2~3年以上Hadoop相关开发经验；
2、熟悉主流的云计算、大数据产品（hadoop、spark、flume等）和数据分析技术（机器学习)并具有相关项目经验；
3、精通算法设计/数据结构，精通JAVA或C/C++语言编程；
4、熟悉Linux/Unix平台上的开发环境；
5、思路敏捷清晰，良好的表达和理解能力，良好的学习能力，强烈的创新意识；
6、适应出差
工作地址
南京市市市 - 鼓楼区 - 南师大 - 虎踞关21号金盾饭店3号楼7楼
查看地图
职位发布者:
明略数据HR汪丽
大数据,数据挖掘
聊天意愿
很弱
回复率--  用时3分钟
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
个推BI招聘
Hadoop开发工程师
12k-15k /杭州 / 经验1-3年 / 本科及以上 / 全职
hadoop
大数据
20:35  发布于拉勾网职位诱惑：
16-18薪 带薪年假 五险一金 生日Party 餐补
职位描述：
岗位职责： 
研究并开发基于Hadoop, hive, hbase, spark的海量（百TB级）数据处理分析程序，使用java，python等开发数据服务接口等

任职要求： 
1、 掌握java开发，面向对象的设计方法，语言、框架不限，对jvm 内存管理熟悉最佳
2、 掌握 hadoop/hive/spark/hbase, 如果对于相关开源框架有所研究最佳 
3、 熟悉mysql数据库，并具有一定的SQL功底； 
4、 熟悉python，scala等语言更佳。
5、 对数据建模、存取、处理、可视化等相关技术有很强的学习热情
工作地址
杭州 - 西湖区 - 古墩路 - 西斗门路福地创业园
查看地图
职位发布者:
江婷婷
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
全天
早10点最活跃
-------------------------------------------------
还呗-智能信贷领先者研发部招聘
Spark/Hadoop开发工程师
15k-25k /上海 / 经验3-5年 / 本科及以上 / 全职
架构师
数据分析
算法
spark
大数据
Java
09:07  发布于拉勾网职位诱惑：
前沿,有挑战,系统稳定,业务成熟
职位描述：
岗位职责：
为海量数据的处理和分析提供高效解决方案；
研究Hadoop/Spark/Hbase/Hive等开源项目，对线上任务进行调优，并开发通用组件；
基于Hadoop平台、数仓、图库开发离线、实时数据流应用。

任职要求：
扎实的计算机系统和算法基础知识；良好的英文阅读能力；
扎实的Java、Scala语言基础，对JVM运行机制有深入了解；
熟悉Hadoop、Spark并有丰富的开发经验；
对常见开源框架代码有研究；
熟悉SQL和noSQL的设计和开发；
熟悉企业应用设计模式、面向对象的分析和设计技术，包括设计模式、UML建模等；
善于思考，能独立分析和解决问题，热衷于互联网技术的研究和创新；
责任心强，沟通能力好，具备良好的团队合作精神；
有深入研究过Hadoop/Spark源码者优先。

工作地址
上海 - 浦东新区 - 张江 - 上海市浦东新区金科路2889弄A座2层01室
查看地图
职位发布者:
徐方典
行政服务
聊天意愿
弱
回复率11%  用时35分钟
简历处理
超快
处理率100%  用时1天
活跃时段
下午
下午6点最活跃
-------------------------------------------------
慕课网大数据招聘
hadoop工程师/讲师
15K-25K /北京 / 经验1-3年 / 学历不限 / 兼职
算法
数据分析
数据挖掘
09:26  发布于拉勾网职位诱惑：
时间自由,分成收益,持续分成
职位描述：
互联网电商行业背景，有推荐系统经验优先，2年以上大数据从业经验，精通hive+hbase数据分析模式，具有一定算法应用能力
工作地址
北京 - 海淀区 - 魏公村 - 北京理工大学国防科技园2号楼十层
查看地图
职位发布者:
丁语霏
BD经理
聊天意愿
很强
回复率100%  用时1分钟
简历处理
快
处理率100%  用时3天
活跃时段
下午
下午2点最活跃
-------------------------------------------------
达摩网络研发部招聘
JAVA-Hadoop工程师
15k-25k /杭州 / 经验3-5年 / 本科及以上 / 全职
中级
spark
hadoop
大数据
10:15  发布于拉勾网职位诱惑：
老板好,活动多,氛围好,五险一金
职位描述：
职位描述：
1、负责数据仓库和大数据处理模块的架构设计和开发；
2、 负责海量数据的处理、分析、统计、挖掘工作；
3、数据仓库的设计，开发，维护；
4、根据需求使用海量数据处理框架进行数据处理、查询、统计等工作。
  职位要求：
1、两年以上大数据开发工作经验，计算机、数学或相关专业本科及以上学历；
2、熟悉Hadoop、Spark等大数据框架，有大型分布式计算开发、部署等相关经验；
3、有扎实的Java开发基础，熟悉JAVA平台多种常用框架；
4、熟悉Linux操作系统和开发环境；
5、优秀的编程能力及良好的开发习惯。具备独立沟通需求，设计，架构，开发的能力；
6、熟悉主流的数据存储产品，有开发经验者优先。如：HBase，Hive，Redis，MongoDB，MySQL等；
7、具备海量数据处理相关框架及产品的使用经验者优先。如：Storm，Spark，Esper，Hadoop等；
8、有良好的业务及产品感觉，可以站在使用者角度设计技术产品。可以主动并乐于了解日常业务，具备从日常业务中发现问题并解决问题的能力；
工作地址
杭州 - 西湖区 - 高新文教区 - 文二路188号浙江团校内青创楼402-2
查看地图
职位发布者:
达摩网络
HR
聊天意愿
一般
回复率41%  用时24分钟
简历处理
超快
处理率100%  用时1天
活跃时段
早上
早9点最活跃
-------------------------------------------------
信雅达影像流程条线招聘
Hadoop开发工程师
10k-20k /北京 / 经验3-5年 / 本科及以上 / 全职
hadoop
金融
大数据
ABAP
Java
系统开发
08:45  发布于拉勾网职位诱惑：
五险一金,餐补,带薪年假,节假日福利
职位描述：
工作职责：
1、参与Hadoop相关项目开发；
2、用Map/Reduce实现业务部门的数据需求；
3、熟悉etl开发过程；
任职要求：
1、本科以上学历，计算机相关专业，3年以上工作经验；
2、1年以上Hadoop或HBase的Java开发经验；
2、熟悉Hadoop、HBase、Hive、Spark等组件，Map/Reduce编程；
3、熟悉Lucene，ElastiSearch开发者优先；
4、有shell、python开发经验优先；
5、有金融行业项目经验优先；
6、学习能力强
工作地址
北京市 - 朝阳区 - 朝外 - 朝阳门北大街9号 中信银行
查看地图
职位发布者:
J
jing.jin1
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
超快
处理率100%  用时1天
活跃时段
下午
下午5点最活跃
-------------------------------------------------
百米生活数据开发组招聘
Hadoop工程师
10k-15k /深圳 / 经验3-5年 / 本科及以上 / 全职
算法
spark
hadoop
大数据
Java
1天前  发布于拉勾网职位诱惑：
项目前景好,团队氛围好,办公环境好,完善福利
职位描述：
岗位职责：
1.负责公司的大数据处理框架的研发工作，设计与开发分布式存储、数据处理与分析架构； 
2.负责开源大数据平台与产品和相关技术的追踪及研究； 
3.跟据公司战略需求组织团队研发与管理，并进行相关技术培训。

任职资格：
1. 计算机相关专业，本科以上学历，博士优先考虑； 
2.具备研究或研发项目经历，相关工作经验丰富者优先考虑； 
3.有Hadoop集群搭建和管理经验者优先考虑，有海量数据挖掘算法开发经验者优先考虑，兼有Oracle，MySQL，NoSQL开发经验者优先考虑，具备丰富的大中型开发项目的总体规划、方案设计经验者优先考虑； 
4.具备以下技能，精通者优先考虑： 
（1）了解大数据分析处理（Hadoop，HDFS, MapReduce，Hbase，Pig，Hive）等技术内部机制； 
（2）扎实的Java语言基础，熟悉Java开发工具和调试工具的使用； 
（3）熟悉Linux系统，熟练使用shell/perl/python脚本处理问题； 
（4）熟悉主流数据挖掘算法开发。
工作地址
深圳 - 福田区 - 车公庙 - 深南大道6025号英龙展业大厦26
查看地图
职位发布者:
百米生活HR
招聘负责人
聊天意愿
弱
回复率12%  用时1小时
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午5点最活跃
-------------------------------------------------
上海宏鹿信息技术服务有限公司大数据部招聘
Hadoop工程师
15k-25k /上海 / 经验3-5年 / 本科及以上 / 全职
分布式
大数据
spark
hadoop
2018-01-19  发布于拉勾网职位诱惑：
五险一金,带薪年假,员工旅游,年终奖
职位描述：
1、大数据平台开发，包括部署、实施
2、大数据平台运行性能、可用性、扩展性等监控与优化调控
3、负责基于Hadoop/Spark生态系统的研发；
4、责基于Spark的计算和挖掘研发

任职资格：
1、熟练掌握Java或Scala语言；
2、JAVA技术知识扎实，熟悉IO，多线程，异步处理，集合类等基础框架和常用中间件产品，熟悉缓存，消息，搜索等机制；
3、有良好的Hadoop上分布式研发的经验，熟悉MR编程；
4、具有HBase、Hive、Storm、Spark相关的实际开发经验；
工作地址
上海 - 浦东新区 - 张江 - 申江路5005弄星创科技大厦1号楼9层
查看地图
职位发布者:
宗
宗勤红
职位发布者
聊天意愿
弱
回复率11%  用时2小时
简历处理
暂无
处理率10%  用时--天
活跃时段
下午
下午6点最活跃
-------------------------------------------------
美丽联合集团研发部-数据平台招聘
Hadoop高级开发工程师
15k-30k /杭州 / 经验3-5年 / 本科及以上 / 全职
后端开发
09:38  发布于拉勾网职位诱惑：
全员MAC、成长快、福利好
职位描述：
1.hadoop大规模集群优化；
2.负责各种分布式存储方案构建；
3.集群数据安全相关体系建设；
4.hbase集群整体优化和功能开发；
5.hive集群性能优化；

职位要求：
1.本科及以上学历，计算机及相关专业；
2.具有3年以上Java开发经验，熟悉python/shell等脚本语言，熟悉tcp/ip网络协议，熟悉基本存储原理；
3.熟悉hadoop相关各种开源项目，Hive/Hbase等有实际应用开发经验，具有一定独立解决问题的能力；
4.掌握MapReduce处理问题思想，熟悉分布式计算模型或有高效索引技术经验者优先；
5.熟悉多进程、多线程、数据库、IO、内存管理等方面编程者优先；
6.熟悉软件开发过程、相关规范和开发工具，能独立完成软件模块的详细设计；
7.逻辑思维清晰，沟通能力良好。
工作地址
杭州 - 西湖区 - 古墩路 - 古墩路99号浙商财富中心1号楼3楼
查看地图
职位发布者:
HR
招聘经理
聊天意愿
一般
回复率33%  用时23分钟
简历处理
超快
处理率100%  用时1天
活跃时段
晚上
晚上9点最活跃
-------------------------------------------------
汽车之家大数据部招聘
Hadoop 工程师
15k-25k /北京 / 经验5-10年 / 本科及以上 / 全职
hadoop
大数据
Java
1天前  发布于拉勾网职位诱惑：
大平台,薪资待遇好,团队氛围好
职位描述：
岗位职责：
1、研究开源大数据组件，改进性能、功能，提出创新性点，反馈给社区。成为领域专家。
2、解决各种客户hadoop、spark等疑难杂症
3、建设万台Hadoop集群
任职资格：
1、计算机或相关专业本科以上学历（5年以上工作经验）
2、精通Java/Scala程序开发(至少一种)，熟悉Linux/Unix开发环境
3、熟悉常用开源分布式系统，精通Hadoop/Spark/Hive之一源代码尤佳
4、具有良好的沟通协作能力，具有较强的分享意愿
5、高抗压能力，随时应对线上故障
工作地址
北京 - 海淀区 - 中关村 - 丹棱街三号中国电子大厦B座10层
查看地图
职位发布者:
Z
zhaoxin
招聘组
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
全天
早9点最活跃
-------------------------------------------------
一下科技总裁办招聘
Hadoop开发工程师
15k-30k /北京 / 经验1-3年 / 本科及以上 / 全职
高级
数据开发
hadoop
大数据
数据挖掘
09:03  发布于拉勾网职位诱惑：
短视频第一矩阵，全新技术驱动化团队
职位描述：
工作职责
1、基于Hadoop/Hive的数据仓库模型设计和ETL开发。
2、支持运营的各类数据需求。

任职资格
1、计算机相关专业，本科及以上学历。
2、熟练掌握hadoop、hive、spark、kafka等大数据平台的原理、使用和调优。
3、掌握python、java、scala等任意一门程序语言。
4、熟悉常用的shell命令。
5、具备较强的业务理解能力、解决问题的能力，和团队协作能力。

工作地址
北京 - 朝阳区 - 望京 - 浦项中心A座31层
查看地图
职位发布者:
陶冶
招聘经理
聊天意愿
暂无
回复率--  用时--
简历处理
超快
处理率100%  用时1天
活跃时段
暂无
--点最活跃
-------------------------------------------------
百联全渠道电商大数据部招聘
Hadoop开发
15k-25k /上海 / 经验3-5年 / 本科及以上 / 全职
hadoop
spark
大数据
Java
09:37  发布于拉勾网职位诱惑：
氛围,突破
职位描述：
岗位职责：
1、基于Hadoop进行MapReduce、Hive和HBase的应用开发；
2、维护和管理大规模Hadoop集群，解决不断增长的海量数据带来的存储和计算挑战；
3、大数据平台数据清洗、转换和建模的开发。

任职资格：
1、大专以上学历，3年及以上工作经验；
2、熟悉Hadoop/HBase生态环境体系的搭建和管理，掌握Hadoop、HBase、MapReduce、HDFS、Hive、Pig、Zookeeper等开源项目的原理和使用方法，具有实际集群搭建和调优经验；
3、精通Java开发，有大平台架构开发经验；
4、掌握至少一种NoSQL数据库，具有真正项目使用经验；
5、良好团队协作和沟通能力
工作地址
上海 - 黄浦区 - 外滩 - 四川南路26号
查看地图
职位发布者:
B
BLHR
HRBP
聊天意愿
很弱
回复率--  用时2分钟
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午3点最活跃
-------------------------------------------------
京东金融招聘
Hadoop开发工程师
20k-35k /北京 / 经验5-10年 / 本科及以上 / 全职
高级
spark
hadoop
软件开发
大数据
1天前  发布于拉勾网职位诱惑：
餐补+年终奖+良好的晋升空间
职位描述：
岗位职责：
负责大数据平台的研制和维护性开发，提供数据应用项目技术支持，参与数据应用类项目
1、负责大数据平台的架构设计、核心代码开发等任务；根据项目要求编写相关技术文档；
2、负责大数据平台的架构评审，代码评审，上线评审；参与数据应用需求、设计、审核和评审；
3、负责核心模块研发，负责大数据平台的搭建，完成系统调试、集成与实施；
4、负责建立和维护大数据平台技术标准规范，指导开发人员编写代码；
5、配合产品经理与项目经理规划设计与实施大数据应用。

任职要求：
1、本科及以上计算机、数学相关专业毕业；具有5年以上相关工作经验；
2、精通离线和实时数据处理流程，掌握离线数据处理框架hive、impala、spark-sql等，掌握实时数据处理常用技术工具，包括Storm、SparkStreaming等；
3、熟悉大数据技术生态圈，精通大数据技术架构，有大数据平台构建经验；
4、掌握常见数据流接入工具，包括Flume、kafka等；
5、熟练掌握基本的Linux操作系统和某种脚本语言编程（如Shell等）；
6、掌握一种或以上实时处理语言，如JAVA、SCALA、PYTHON等；
7、有3年以上实际大规模数据（TB级以上）处理经验；
8、熟悉大容量、高性能的数据库系统，如HBASE、REDIS等；
9、有调度系统设计开发经验者优先。
工作地址
北京市 - 大兴区 - 亦庄 - 亦庄经海路京东总部
查看地图
职位发布者:
W
wylianrui
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
慢
处理率31%  用时4天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
悠易技术部招聘
Hadoop
20k-30k /北京 / 经验3-5年 / 本科及以上 / 全职
大数据
10:19  发布于拉勾网职位诱惑：
全员期权 花样福利 团队氛围好
职位描述：
  岗位描述：
     参与基于hadoop的数据计算平台建设，支持精准广告投放所需的大规模数据计算需求
     大数据应用相关解决方案的设计，以及相关软件应用技术疑难问题的研究工作
工作地点：北京
岗位要求
     计算机相关专业，本科及以上学历，3年以上Hadoop相关开发/维护经验：
     熟悉Hadoop/HBase/Spark相关系统的搭建和管理，掌握原理和使用方法
     善于发现系统的性能瓶颈、设计缺陷，提出改进方案并进行实施；
     思路敏捷清晰，良好的表达和理解能力，良好的学习能力，强烈的创新意识；
工作地址
北京 - 朝阳区 - CBD - 东三环中路1号北京环球金融中心东塔5层511
查看地图
职位发布者:
悠
悠易互通HR
高级人力资源经理
聊天意愿
很弱
回复率--  用时2小时
简历处理
很慢
处理率14%  用时6天
活跃时段
下午
下午3点最活跃
-------------------------------------------------
Hypers技术部招聘
Hadoop开发工程师
8k-15k /上海 / 经验不限 / 本科及以上 / 全职
hadoop
大数据
10:29  发布于拉勾网职位诱惑：
福利待遇好，发展空间巨大
职位描述：
岗位职责：                                 

1.负责基于Hadoop（CDH、HDP）平台架构的规划、设计和搭建；
2.独立或者带领团队完成各种面向业务目标的数据分析模型定义和应用开发；
3.针对海量的数据开发具有数据收集、统计、分析和挖掘能力的创新型产品；
4.基于MapReduce、Spark、Flume等的大数据开发；
5.学习和研究大数据技术最新动向以满足产品、项目的需求。

要求：
1.计算机相关专业本科及以上；
2.软件基础理论知识扎实，具有良好的数据结构、算法功底；
3.精通Hadoop等分布式开发，如：MapReduce、Spark，具有扎实的Java／Scala等开发语言功底；
4.熟悉Hadoop相关各种开源项目，如：Flume、Hive、Hbase等，并有实际应用者优先；
5.熟悉Solr／Lucene开发，熟悉NoSQL数据库者优先；
6.对新技术敏感，有一定独立分析，技术研究能力；
7.熟练使用Linux环境下开发者优先；熟悉至少一种版本控制工具，如：Git、SVN、Mercurial；
8.有个人开源项目或参与开源项目者优先；
9.有代码洁癖和自发组织Code Review的开发者优先。
工作地址
- 溧阳路735号1号楼2层
查看地图
职位发布者:
HR
职位发布者
聊天意愿
一般
回复率26%  用时15分钟
简历处理
超快
处理率100%  用时2天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
明略数据项目部招聘
Hadoop工程师（上海）
15k-25k /上海 / 经验3-5年 / 本科及以上 / 全职
大数据
1天前  发布于拉勾网职位诱惑：
福利好,牛人多
职位描述：
1.本科以上学历
2.3年＋大数据开发经验。
3.熟悉Java语言，熟练使用SQL，熟练使用Linux，能熟练写Shell脚本，懂scala语言佳
4.熟悉Hadoop生态圈中的组件之一或者多种（flume, kafka, Hive, HBase, Spark, impala，storm，ES）【备注 Hive和Spark经验优先】
6.有志往大数据领域发展，学习欲强，学习能力强，主动性强，抗压能力强，团队协作意识强
工作地址
上海 - 浦东新区 - 张江 - 郭守敬路498号(浦东软件园郭守敬园)3号楼3302
查看地图
职位发布者:
明略数据HR汪丽
大数据,数据挖掘
聊天意愿
很弱
回复率--  用时3分钟
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
京东金融技术研发部招聘
Hadoop开发工程师
20k-35k /北京 / 经验5-10年 / 本科及以上 / 全职
spark
大数据
docker
Java
1天前  发布于拉勾网职位诱惑：
带薪年假，年底双薪，年终奖
职位描述：
岗位职责：
负责Hadoop系统的资源管理和日常维护；
负责Hive/HBase/Spark/Impala等组件的优化和二次开发。
任职资格：
   1.熟悉Hadoop、Hbase、Hive，5年以上Hadoop开发经验；
   2.理解MapReduce计算框架的思想，熟悉分布式计算模型或有高效索引  技术经验者优先；
  3.精通JAVA语言，熟悉J2EE相关技术；
  4.至少熟练使用Shell、Python、Perl等脚本语言之一；
  5.热爱技术，工作认真、严谨，有团队精神。

工作地址
北京市 - 大兴区 - 亦庄 - 亦庄经海路京东总部
查看地图
职位发布者:
W
wylianrui
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
慢
处理率31%  用时4天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
爱奇艺技术产品中心招聘
Hadoop资深工程师
25k-45k /北京 / 经验5-10年 / 本科及以上 / 全职
资深
spark
hadoop
大数据
视频
10:09  发布于拉勾网职位诱惑：
成熟平台 成长型团队
职位描述：
岗位职责
1、负责爱奇艺各垂直业务大数据处理
2、负责视频播放相关数据计算
3、关注开源技术动态，推动平台技术架构持续更新。
  任职要求
1、计算机相关专业或数理统计相关专业，3年以上大数据开发项目经验
2、熟悉Linux/Unix开发环境
3、精通hadoop各模块，了解HDFS数据存储机制；熟练使用hive数据处理
4、对HBase、Redis、Spark有深入了解
5、熟练使用shell命令，熟悉python/perl等脚本语言
6、思维敏捷，有较强的钻研学习能力；较好的沟通能力、团队合作
工作地址
北京 - 海淀区 - 中关村 - 海淀北一街2号 爱奇艺创新大厦
查看地图
职位发布者:
A
Alicia
HR
聊天意愿
暂无
回复率--  用时--
简历处理
快
处理率16%  用时1天
活跃时段
全天
早9点最活跃
-------------------------------------------------
京东商城大数据-平台研发部招聘
hadoop工程师
30k-60k /北京 / 经验3-5年 / 本科及以上 / 全职
资深
后端开发
Java
spark
hadoop
大数据
2018-01-16  发布于拉勾网职位诱惑：
技术导向
职位描述：
构建全京东hadoop集群，3万规模。并深入参与Hadoop社区。深入Hadoop源码改进优化，解决源码问题。

研发Hadoop组件，而非使用组件。

岗位要求:

1、计算机或相关专业统招本科以上学历(最高学历毕业后3年以上工作经验)
2、精通Java开发语言和面向对象思想，熟悉Linux开发环境，熟悉java高并发原理，熟悉操作系统
3、熟悉Hadoop源代码，有贡献过Hadoop社区者优先
4、良好的沟通协作能力，敢于挑战技术难点


1、研究开源Hadoop大数据组件，改进性能、功能，提出创新性点，反馈给社区。
推进京东最大Hadoop集群的发展。
2、解决Hadoop各种疑难问题,在内部分享大数据技术。

注：
1. 满足2-5原则，即平均在一家公司工作2年以上或在一家连续工作过5年以上
2. 统招本科以上
工作地址
北京 - 朝阳区 - 亚运村 - 北辰西路8号北辰世纪中心A座
查看地图
职位发布者:
张逸
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
快
处理率2%  用时1天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
搜狗招聘
基础运维平台-高级hadoop...
25k-40k /北京 / 经验5-10年 / 本科及以上 / 全职
后端开发
大数据
运维
09:57  发布于拉勾网职位诱惑：
公司重点项目，团队气氛佳
职位描述：
【项目介绍】
为搜狗各项业务提供了坚实的服务保障。  在这里， 你将亲手优化系统架构和内部逻辑，精确管理和处理每个任务的执行，打造出强大的自动化管理平台；  你将亲手优化服务部署结构和性能，提升服务器硬件能力，打造出万级数据中心；  你将亲手优化网络存储架构，使海量数据的传输、存储与访问也变得轻而易举；  你将亲手设计高性能数据库集群，让每条记录都能快速、准确的记录与索引；  你将亲手设计和实施企业安全体系，与顶尖的白帽子们一起打造安全的互联网环境； 你将亲手规划分布式与虚拟化应用，为计算效率、运营效率的不断提高做出贡献；  你将亲手维护数亿量级用户的产品，以及千亿条量级的数据，并为网民提供99.99%以上稳定性的业务。

【职位诱惑】
负责大数据运营平台规划、建设、运维、管理相关工作

【特别提示】 搜狗欢迎专情的你，所以提醒你只能选择两个项目，请慎重投递。

【岗位职责】
1. 负责数据平台的规划与建设；
2. 负责数据平台的运维体系建设；
3. 数据平台的审计开发；

任职条件
1. 精通hadoop原理，有一定hadoop管理使用经验；
2. 熟悉hive、spark、mapreduce编写者优先；
3. 有权限审计项目工作经验者优先；  
4. 诚信正直，工作责任心强；
5. 具备良好的沟通能力及团队合作精神，能承受一定的工作压力。
工作地址
北京 - 海淀区 - 五道口 - 中关村东路一号院清华科技园搜狐网络大厦
查看地图
职位发布者:
sogou
HR
聊天意愿
很弱
回复率--  用时25分钟
简历处理
超快
处理率100%  用时1天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
烽火众智项目产出线招聘
Hadoop工程师（项目）
10k-20k /武汉 / 经验不限 / 本科及以上 / 全职
spark
hadoop
软件开发
大数据
18:19  发布于拉勾网职位诱惑：
数据量大
职位描述：
工作职责：
1、大数据相关技术研究、架构设计，平台优化。
2. 流式计算平台开发结合业务的应用，处理实时数据，实时应用场景的开发；
3.大数据环境下的软件开发，数据分析；保证大数据平台数据与各源系统数据准确性； 
4. 大数据平台数据清洗、转换、建模的开发工作；
要求：
1、计算机相关专业毕业，大学本科及以上学历；熟悉大数据背景和趋势，有两年以上工作经验，有智慧城市行业经验者优先；
2、熟悉大数据技术方案的编写，具备良好的文档编制习惯；
3、精通Hadoop、Hbase、Hive、spark、Flume、Zookeeper中的一种或几种； 
4、熟悉Java面向对象编程语言，熟悉数据库系统知识。
工作地址
武汉 - 洪山区 - 光谷 - 邮科院路88号
查看地图
职位发布者:
zhaopin
人力资源部
聊天意愿
暂无
回复率--  用时--
简历处理
很慢
处理率3%  用时6天
活跃时段
下午
下午5点最活跃
-------------------------------------------------
首汽约车技术部招聘
Hadoop工程师
20k-30k /北京 / 经验3-5年 / 本科及以上 / 全职
大数据
Java
1天前  发布于拉勾网职位诱惑：
平台好,团队佳,薪资高,福利多
职位描述：
岗位职责：
        1、负责Hadoop集群的开发、调优和运维；
        2、负责大数据平台的基础工具设计、开发；
        3、大数据技术难点攻关及新技术调研；
        4、参与小组的产品设计讨论，共同讨论和设计产品。
任职资格：
       1、精通Java，熟练使用shell命令；
       2、精通Hadoop生态技术，包括HDFS、Yarn、Hive、HBase等；
       3、熟悉hadoop以及mapreduce编程模型，对数据结构、算法有深刻理解；
       4、熟悉hadoop、hbase、spark的源码的优先；
       5、学习能力强，认真负责、有良好的沟通和学习能力，具备独立解决问题的能力；
       6、计算机相关专业或通信相关专业，两年以上大数据开发经验。
工作地址
北京市 - 东城区 - 朝阳门 - 朝阳门银河SOHO D座 5-120 SOHO3Q
查看地图
职位发布者:
hr
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率2%  用时--天
活跃时段
全天
中午12点最活跃
-------------------------------------------------
景通科信平台研发部招聘
Hadoop开发工程师
10k-15k /北京 / 经验3-5年 / 本科及以上 / 全职
zookeeper
hadoop
软件开发
spark HBase
HDFS Kafka
中级
18:23  发布于拉勾网职位诱惑：
五险一金,绩效奖金,员工旅游,专业培训
职位描述：
任职要求：
工作技能
1、精通Java，熟悉Java开发环境和工具；
2、熟练掌握SQL，熟悉Mysql、Oracle等数据库；
3、熟悉Linux/Unix系统，熟悉Shell/Python/Perl等脚本语言中至少一种；
4、熟悉Hadoop、Hive、HBase、Spark、Zookeeper等相关开源项目，或者从事过分布式相关系统的设计、开发工作优先；
5、熟悉Hadoop集群的部署、维护和性能调优；
工作地址
北京 - 海淀区 - 小营东路15号
查看地图
职位发布者:
Nica
招聘经理
聊天意愿
一般
回复率50%  用时12分钟
简历处理
超快
处理率100%  用时1天
活跃时段
早上
早9点最活跃
-------------------------------------------------
瓜子二手车直卖网技术部招聘
Hadoop开发高级工程师-01
30k-45k /北京 / 经验3-5年 / 本科及以上 / 全职
架构师
爬虫
python
算法
大数据
数据挖掘
14:22  发布于拉勾网职位诱惑：
我们拥有一支超强悍的团队 我们来自硅谷
职位描述：
我们拥有一支超强悍的团队：他们曾是Hulu团队算法大拿，是微软，百度、阿里、腾讯的技术专家，是清华、北大、中科院等名校超级学霸。在过去的时间里我们完成A轮2.5亿美金的融资。我在瓜子二手车，期待优秀的你的加入！

职位描述：
1.负责Hadoop平台上的数据处理；
2.使用Spark、Mapreduce进行数据处理

职位要求：
1.熟悉Hadoop、HBase、Hive、Spark、Mapreduce
2.对数据结构、算法有深刻理解
3.精通Java、Python
4.熟悉linux开发环境
5.熟悉hadoop、hbase、spark的源码的优先
6.对新技术充满激情，认真负责、有良好的沟通和学习能力
7.计算机或数学相关专业本科及以上学历

工作地址
北京 - 昌平区 - 回龙观 - 金域国际B座
查看地图
职位发布者:
gz_liyang
HR
聊天意愿
暂无
回复率--  用时--
简历处理
快
处理率59%  用时2天
活跃时段
早上
早5点最活跃
-------------------------------------------------
美菜网数据研发部招聘
Hadoop
15k-30k /北京 / 经验3-5年 / 本科及以上 / 全职
云计算
hadoop
10:53  发布于拉勾网职位诱惑：
五险一金 弹性工作制
职位描述：
岗位职责：

1、参与公司Hadoop/Hive/Storm/Spark等大数据基础设施的研发与运维，提升运行效率、稳定性和可用性；

2、参与大数据集群部署和管理平台的研发和改进。

任职要求：

1、计算机相关专业本科及以上学历； 

2、熟练掌握操作系统、网络原理、数据结构与算法；

3、精通Java/Python至少一种； 

4、熟悉常见的开源分布式计算/存储相关技术，精通Hadoop/MapReduce/Hive/Spark等； 

5、有Hadoop等分布式系统运维开发，并有运维和调优经验者优先；

6、在开源社群活跃并有积极贡献者优先。
工作地址
北京 - 朝阳区 - 安贞 - 北京市朝阳区安贞路安贞西里五区一号楼新华金融大厦4层
查看地图
职位发布者:
H
hr
招聘渠道经理
聊天意愿
很弱
回复率--  用时1小时
简历处理
超快
处理率100%  用时2天
活跃时段
全天
晚上9点最活跃
-------------------------------------------------
智游研发部招聘
HADOOP开发
10k-16k /郑州 / 经验3-5年 / 本科及以上 / 全职
教育
大数据
2天前  发布于拉勾网职位诱惑：
五险一金、带薪年假、弹性工作、提供住宿
职位描述：
岗位职责：
1、负责大数据方向教研体系，设计、规划课程和任务体系；
2、通过面授方式进行学员答疑、任务讲解；
3、按照规范和课程体系规划制作专业的大数据相关教学课程；
4、管理并协调全职助教、兼职老师进行作业批改、问题解答、助教培养；
5、负责设计作业和作业批改的范本；
6、研究最新的大数据技术、人才市场发展趋势，确保教研体系的专业性和时效性。
任职要求：
1、精通Java语言，具备实际的开发经验；
2、熟练掌握大数据相关的技术，如：Hadoop、HDFS、MapReduce、Spark、Impala、Hbase、Hive、Mahout、Storm等；
3、熟悉掌握互联网项目的架构与设计，对分布式、集群、缓存技术等有深入的理解，有商业大数据系统构建经验者优先；
4、有技术步道，就业培训班经验者优先；
5、普通话标准，逻辑思路清晰，流畅的语言表达能力；
6、热爱教育行业，有责任心，有强烈的自我学习和成长欲望；
工作地址
郑州 - 经开区 - 东开发区 - 航海路经开第五大街经北三路河南通信产业园6楼
查看地图
职位发布者:
杨
杨淑芳
人力主管
聊天意愿
暂无
回复率--  用时--
简历处理
超快
处理率100%  用时1天
活跃时段
早上
早10点最活跃
-------------------------------------------------
小米云平台招聘
Hadoop存储开发工程师
25k-50k /北京 / 经验3-5年 / 本科及以上 / 全职
高级
数据挖掘
机器学习
信息安全
Java
系统开发
2018-01-17  发布于拉勾网职位诱惑：
年终奖,股票期权,没有考勤,年终奖
职位描述：
工作职责:
1. 负责开发及维护小米HDFS/HBase存储系统, 包括Bug修复及满足业务需求的各种新功能
2. 负责改进HDFS/HBase存储系统的可扩展性、易用性、数据安全并降低数据存储成本
3. 和各个业务线一起规划和管理数据的生命周期

岗位要求:
1. 本科及以上学历, 计算机软件、系统机构或相关专业
2. 熟练掌握Java/C++/C至少一种开发语言
3. 熟悉分布式文件系统或分布式数据库系统的原理和技术细节
4. 熟悉HDFS/HBase源代码者优先考虑
工作地址
北京 - 海淀区 - 清河 - 安宁庄东路72号科利源大厦
查看地图
职位发布者:
L
lipengc...
职位发布者
聊天意愿
很弱
回复率--  用时44分钟
简历处理
快
处理率77%  用时2天
活跃时段
全天
早9点最活跃
-------------------------------------------------
FreeWheel大数据招聘
Hadoop
30k-40k /北京 / 经验3-5年 / 本科及以上 / 全职
高级
hadoop
python
spark
Java
架构
2天前  发布于拉勾网职位诱惑：
美资互联网,长期激励,补充养老金,技术导向
职位描述：
FreeWheel 为Comcast旗下机构，拥有业界最完整的广告管理解决方案。专注服务于全新电视生态系统，我们帮助客户管理并变现高端视频内容，使之在品牌安全的条件下充分发挥商业价值。凭借领先技术和独树一帜的咨询服务，我们助力众多全球顶级媒体和娱乐公司开展广告业务。FreeWheel总部位于美国加州圣马特奥，在纽约、伦敦、巴黎、北京等全球各地设有分支机构。目前90%美国主流电视媒体和运营商使用我们的广告平台。

Sr. Engineer in Data Infrastructure Team 

*  负责FreeWheel数据基础架构系统或组件的调研、开发和维护工作，及时高质量地交付任务
*  对所负责的组件或特性进行持续的优化及改进，建立高效可扩展的数据基础架构
*  指导初级工程师，跨团队沟通协作
    要求
 - 3年及以上工作经验，本科以上学历，计算机相关专业
 - 扎实的编程能力，良好的开发习惯，熟悉Java、C++，熟悉Go更佳
 - 自我驱动，有很强的解决问题能力，能够快速掌握新的技术
 - 对流行的大数据处理平台如Hadoop有深入的了解，并有实际的项目经验，熟悉HBase、Presto、Spark更佳
 - 有消息队列，分布式缓存，RPC框架，AWS开发，以及分布式同步等方面的实际的项目经验更佳
 - 对Linux内核，包括线程调度，内存管理，磁盘缓存等有一定了解
 - 良好的沟通能力与团队合作精神，能顺利进行英语口语交流
    Sr. Engineer in Backend Team

*  独立负责数据后端处理中重要组件的开发、运维，确保产品质量以及相关功能
*  为代码重构、优化架构、技术决策提供建设性意见，及时高质量地交付任务
*  指导初级工程师，跨团队沟通协作
    要求
 - 3年及以上工作经验，本科以上学历，计算机相关专业
 - 扎实的编程基础，良好的开发习惯，追求优雅、高抽象、可复用代码模块的热情；如有C++, Python, Go， 以及AWS开发经验更佳
 - 精通关系型数据库如MySQL, 有NoSQL、Redis使用经验更佳
 - 熟练使用Linux操作系统，对Linux内核，包括线程调度，内存管理，磁盘缓存等有一定了解，熟悉Linux下开发环境（GDB, VIM等）
 - 自我驱动，工作积极主动，认真负责
 - 有快速学习掌握新技术并运用解决产品问题的能力
 - 良好的沟通能力与团队合作精神，能流利进行英语口语交流

大数据部门提供多种服务：
基于流处理（Spark Streaming)的实时数据服务。
基于SQL-on-Hadoop (Presto)的数据查询服务。
基于商业智能工具（Looker）的数据分析服务。 
工作地址
北京 - 朝阳区 - 三元桥 - 亮马桥润世中心
查看地图
职位发布者:
Y
yaqi wang
招聘
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率100%  用时--天
活跃时段
下午
下午5点最活跃
-------------------------------------------------
Hypers招聘
资深hadoop工程师
15k-30k /上海 / 经验3-5年 / 本科及以上 / 全职
资深
hadoop
大数据
10:29  发布于拉勾网职位诱惑：
大牛团队，零食管够
职位描述：
岗位职责：
负责基于Hadoop（CDH、HDP）平台架构的规划、设计和搭建；
独立或者带领团队完成各种面向业务目标的数据分析模型定义和应用开发；
针对海量的数据开发具有数据收集、统计、分析和挖掘能力的创新型产品；
基于MapReduce、Spark、Flume等的大数据开发；
学习和研究大数据技术最新动向以满足产品、项目的需求。

要求：
计算机相关专业本科及以上，3年及以上相关工作经验；
软件基础理论知识扎实，具有良好的数据结构、算法功底；
精通Hadoop等分布式开发，如：MapReduce、Spark，具有扎实的Java／Scala等开发语言功底；
熟悉Hadoop相关各种开源项目，如：Flume、Hive、Hbase等，并有实际应用者优先；
熟悉Solr／Lucene开发，熟悉NoSQL数据库者优先；
对新技术敏感，有一定独立分析，技术研究能力；
熟练使用Linux环境下开发者优先；熟悉至少一种版本控制工具，如：Git、SVN、Mercurial；
有个人开源项目或参与开源项目者优先；
有代码洁癖和自发组织Code Review的开发者优先。

工作地址
上海 - 虹口区 - 四川北路 - 溧阳路735号1号楼2层
查看地图
职位发布者:
HR
职位发布者
聊天意愿
一般
回复率26%  用时15分钟
简历处理
超快
处理率100%  用时2天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
青岛微智慧大数据招聘
hadoop开发工程师
4k-6k /青岛 / 经验不限 / 本科及以上 / 全职
数据分析
spark
hadoop
大数据
部署运维
Java
2018-01-08  发布于拉勾网职位诱惑：
大数据开发
职位描述：
1.理解大数据平台体系架构，设计和规划Hadoop集群，提升集群高可用性、高性能和高扩展特性；
2.熟悉Hadoop 安装配置，熟悉Hive，Hbase，Sqoop，yarn框架；熟练掌握hadoop分布式集群的部署运维监控等内容。
3.掌握Java语言编程开发；
4.熟悉spark，掌握scala语言开发的优先考虑。
工作地址
青岛 - 市南区 - 徐州路79号好奇工厂2层
查看地图
职位发布者:
先生
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
暂无
--点最活跃
-------------------------------------------------
明略数据技术部招聘
Hadoop工程师--大连
10k-20k /大连 / 经验1-3年 / 本科及以上 / 全职
中级
后端开发
hadoop
大数据
1天前  发布于拉勾网职位诱惑：
大数据,技术牛
职位描述：
工作职责：
1、负责大数据应用相关解决方案的设计，进行技术方案材料的撰写；
2、负责大数据应用相关产品的整体架构设计，进行大数据平台上数据挖掘产品的规划及研发；
3、完成各种面向业务目标的数据分析模型的定义和应用开发；
4、开发具有数据分析、数据挖掘能力的创新型产品； 
岗位要求：
1、计算机相关专业，本科及以上学历，3~4年以上Hadoop相关开发经验；
2、熟悉主流的云计算、大数据产品（hadoop、spark、flume等）和数据分析技术（机器学习)并具有相关项目经验；
3、精通算法设计/数据结构，精通JAVA或C/C++语言编程；
4、熟悉Linux/Unix平台上的开发环境；
5、思路敏捷清晰，良好的表达和理解能力，良好的学习能力，强烈的创新意识；
工作地址
大连 - 西岗区 - 黄河路 - 大连市公安局大数据平台办
查看地图
职位发布者:
明略数据HR汪丽
大数据,数据挖掘
聊天意愿
很弱
回复率--  用时3分钟
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
FreeWheel大数据开发招聘
Hadoop
35k-50k /北京 / 经验5-10年 / 本科及以上 / 全职
高级
分布式
spark
hadoop
Java
架构
2018-01-11  发布于拉勾网职位诱惑：
大牛聚集,美国轮岗,超长年假,全员持股
职位描述：
Data infrastructure
职责
负责FreeWheel数据基础架构系统或组件的调研、开发和维护工作，及时高质量地交付任务
对所负责的组件或特性进行持续的优化及改进，建立高效可扩展的数据基础架构
指导初级工程师，跨团队沟通协作
要求
扎实的编程能力，良好的开发习惯，熟悉Java、C++，熟悉Go更佳
自我驱动，有很强的解决问题能力，能够快速掌握新的技术
对流行的大数据处理平台如Hadoop有深入的了解，并有实际的项目经验，熟悉HBase、Presto、Spark更佳
有消息队列，分布式缓存，RPC框架，AWS开发，以及分布式同步等方面的实际的项目经验更佳
对Linux内核，包括线程调度，内存管理，磁盘缓存等有一定了解
良好的沟通能力与团队合作精神，能顺利进行英语口语交流
工作地址
北京 - 朝阳区 - 燕莎 - 润世中心
查看地图
职位发布者:
Cassie Guo
Recruiter
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
下午
中午1点最活跃
-------------------------------------------------
易宝支付技术中心招聘
Java/ Hadoop研发工程师
15k-25k /北京 / 经验3-5年 / 本科及以上 / 全职
Java
hadoop
数据分析
数据开发
大数据
1天前  发布于拉勾网职位诱惑：
领导超棒，充满激情的团队等你来！
职位描述：
岗位职责：
1、负责数据仓库架构设计与研发；
2、负责大数据产品的数据研发；
3、助力数据化运营业务，与算法同学配合构建丰富多样的BI应用。

任职要求：
1、有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关开发经验，有Spark/Flink的开发经验尤佳；
2、较为丰富的数据仓库及数据平台的架构经验，精通数据仓库建模及ETL设计开发；有较为系统的海量数据性能处理经验；在大数据资产管理与治理有一定成功产品化经验；
3、具备一定的JAVA、Python语言的开发能力，具备机器学习算法能力尤佳；
4、 良好的思维逻辑性、语言表达能力；有较好英语口语能力，将安排海外岗位。
工作地址
北京 - 朝阳区 - 朝外大街甲6号万通中心D座7层
查看地图
职位发布者:
rui.liu
HRBP
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
下午
中午1点最活跃
-------------------------------------------------
健康之路信息技术有限公司健康信息服务平台事业部招聘
hadoop工程师
4k-7k /厦门 / 经验1-3年 / 本科及以上 / 全职
2天前  发布于拉勾网职位诱惑：
周末双休 五险一金
职位描述：
职责：
1、负责大数据平台的日常维护及优化；
2、负责大数据平台的建设、部署实施；
3、负责分布式大数据平台开源新技术的研究，为应用的架构设计提供技术支持。
  要求：
1、熟悉Java，熟悉jvm调优、熟悉程序Debug；；
2、熟悉Hadoop、Hive和hbase、spark、storm等开源产品；
3、熟悉Linux系统；
4、对新技术敏感，有新技术分析、研究能力；
5、具有良好的服务意识和团队合作精神。
6、了解数据仓库技术者优先

工作地址
厦门软件园二期
查看完整地图
职位发布者:
健康之路
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午6点最活跃
-------------------------------------------------
知乎招聘
Hadoop 高级开发工程师
18k-35k /北京 / 经验3-5年 / 本科及以上 / 全职
资深
高级
python
hadoop
大数据
Java
11:43  发布于拉勾网职位诱惑：
平台大 三餐 健身房
职位描述：
Hadoop 高级开发工程师
  职责：
1、Hadoop 平台日常维护
2、Hadoop 组件二次开发和优化
3、新技术调研及生产环境落地
  任职条件：
1、工作责任心强，热爱技术，对 Hadoop 相关源码有深入研究者优先
2、熟悉 Java/Scala 语言和 Jvm 机制
3、熟悉高并发编程模型
4、熟悉 Linux 系统下软件性能优化，具备一定的数据平台调优、排障能力
5、熟悉下列之一技术领域：
    分布式存储，如 Hdfs，Hbase，Kudu 等
    资源调度， 如 Yarn，Kubernetes，Mesos 等
    计算框架，如 Spark，Mr，Hive，Impala 等
工作地址
北京 - 海淀区 - 五道口 - 学院路甲 5 号 768 创意园 A 座西区 1-002
查看地图
职位发布者:
萧萧
HRBP & 人才招聘
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
暂无
--点最活跃
-------------------------------------------------
搜狗搜索事业部招聘
大数据基础平台-Hadoop高...
20k-40k /北京 / 经验3-5年 / 本科及以上 / 全职
数据分析
hadoop
大数据
智能硬件
09:57  发布于拉勾网职位诱惑：
技术氛围浓厚，海量数据支撑
职位描述：
【项目介绍】
基于网页搜索每日增长百TB数据，建设搜狗大数据海量数据离线和实时分析系统和计算平台，在这里有深厚的技术积淀，有浓郁的技术氛围，我们可以让数据变得更有价值。同时，我们也拥有很多创新的机会，为用户提供高质量一站式的服务。
【职位诱惑】
技术氛围浓厚，海量数据支撑，docker等相关的基础平台技术在业内处于领先地位
【岗位职责】
1. 负责搜狗网页搜索大数据存储和计算平台
2.提供稳定高效的数据分析系统和提供数据处理服务
3.开发和维护数据服务后台，对网页搜索业务进行数据支持
4.深入了解PC端产品、移动端产品、智能硬件、商业化产品，从数据层面发现业务的系统问题，并支持解决
5.提升集群处理能力/高可用性/高扩展性的各种解决方案进行跟踪和落地，推进开源技术的发展
【特别提示】
搜狗欢迎专情的你，所以提醒你只能选择两个项目，请慎重投递。
【任职条件】
1. 三年以上的hadoop开发经验和大数据处理平台工具的使用和开发
2. 熟悉Linux/Unix系统，熟悉Shell/PHP/Python/Java/Scala编程
3. 熟悉Hadoop、Hive、Flink、Spark等开源框架
4. 善于分析问题、能将复杂的业务问题转化为数据/数学模型，对大数据处理和分析工作有热情
5. 能够主动获取新知识，具有较强领悟力，有系统性思考解决问题能力，性格乐观，态度踏实
工作地址
北京 - 海淀区 - 五道口 - 中关村东路一号院清华科技园搜狐网络大厦
查看地图
职位发布者:
sogou
HR
聊天意愿
很弱
回复率--  用时25分钟
简历处理
超快
处理率100%  用时1天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
平安科技招聘
资深Hadoop开发工程师（上海）
15k-30k /上海 / 经验3-5年 / 本科及以上 / 全职
高级
中级
数据分析
搜索
数据挖掘
推荐
2天前  发布于拉勾网职位诱惑：
世界500强，丰厚奖金
职位描述：
岗位职责：
1、 基于HADOOP数据平台，参与数据清洗、转换、整合及各类数据模型建设工作；
2、 基于HADOOP数据平台，参与生态圈内工具创新及研发工作；
3、 参与人工智能及数据挖掘等研发项目，结合大数据平台探索机器学习应用场景并参与实施
任职资格：
1、 本科以上学历，计算机相关专业，3年以上IT开发工作经验，熟悉金融保险业务
2、 1年以上数据挖掘或人工智能建模工作经验
3、 精通Sql编程及性能调优
4、 熟练使用Hadoop/Spark生态圈技术，如：Hive、Hbase、MapReduce、Spark、Oozie、Kafka、Flume等等
5、 熟悉Linux系统及shell编程
6、 具备较高的程序开发及调试能力；具备一定的系统设计能力
7、 良好的沟通技巧和团队合作意识
工作地址
上海 - 浦东新区 - 东外滩 - 崂山路316号
查看地图
职位发布者:
it-hr
职位发布者
聊天意愿
暂无
回复率--  用时1分钟
简历处理
超快
处理率100%  用时2天
活跃时段
下午
下午5点最活跃
-------------------------------------------------
一点资讯大数据平台招聘
hadoop高级工程师
25k-50k /北京 / 经验3-5年 / 本科及以上 / 全职
后端开发
2天前  发布于拉勾网职位诱惑：
岗位晋升 弹性工作
职位描述：
岗位职责:
1、Hadoop 技术栈的开发和管理，解决实际业务挑战，e.g. YARN, HDFS, MapReduce, Spark, Hbase etc；
2、与开源社区保持交流，发现对业务场景有帮助的特性并引入生产环境，或将经内部验证的特性贡献到社区；
3、承担千台规模 Hadoop YARN 集群的管理工作，与业务一起解决性能优化、容量规划、预算审计等问题，保障集群高效稳定经济运行。
任职资格:
1、思维活跃，熟悉 Hadoop Stack 及相关基础设施；
2、优秀的设计和编码能力：针对具体的业务场景问题，快速设计和实现解决方案；对工程质量有很高的自我要求；
工作地址
北京 - 朝阳区 - 北京市朝阳区启阳路中轻大厦A座19层
查看地图
职位发布者:
H
hr
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
快
处理率7%  用时2天
活跃时段
下午
下午3点最活跃
-------------------------------------------------
秒针系统招聘
Hadoop平台开发工程师
20k-30k /北京 / 经验3-5年 / 本科及以上 / 全职
高级
平台/后台
linux
大数据
Java
架构
10:29  发布于拉勾网职位诱惑：
六险一金；带薪年假；餐补房补；弹性工作
职位描述：
职位描述

负责Hadoop平台组件的设计与开发；
负责海量实时日志采集，聚合，传输系统的设计与开发；
负责资源调度系统的设计与开发；
优化平台架构，提高稳定性，可靠性和运维效率；

职位要求

熟练掌握Java系统编程，熟悉JVM机制及其内存管理；熟悉使用Shell脚本；
熟悉操作系统和网络知识，有良好的数据结构和算法基础；
熟悉Hadoop生态系统框架Hbase, HDFS, Spark, Hive等，清楚原理和机制；
阅读过开源代码，活跃于开源社区者优先；
有Hadoop平台运维及监控开发者优先；
工作地址
北京 - 朝阳区 - 望京 - 望京soho T3B座10层
查看地图
职位发布者:
MiaozhenHR
招聘主管
聊天意愿
很弱
回复率--  用时3分钟
简历处理
快
处理率54%  用时2天
活跃时段
早上
早11点最活跃
-------------------------------------------------
美团点评基础数据部招聘
Hadoop开发（实时计算方向）
15k-30k /北京 / 经验3-5年 / 本科及以上 / 全职
算法
hadoop
10:48  发布于拉勾网职位诱惑：
发展空间大
职位描述：
工作职责：
1. 负责构建美团点评的实时计算平台，包括性能和架构改进，不断解决规模增长带来的技术和业务问题；
2. 探索面向不同场景的实时解决方案，包括离线实时融合场景、Exactly Once场景、线上应用场景等；

任职资格：
1. 本科及以上学历，扎实的计算机专业基本功；
2. 2年以上 Java 开发经验，精通 Java 及面向对象设计开发；
3. 有较强的逻辑思维能力，善于分析和解决问题；有较强的主动性和自驱力，能够发现问题，并推动系统演进至完美状态；
4. 有大数据分布式计算系统设计和开发经验，熟悉flume、 kafka、storm、spark streaming、flink等开源软件的优先考虑；
5. 有技术团队管理经验者优先；
工作地址
北京 - 朝阳区 - 望京 - 望京东路4号恒电大厦C座
查看地图
职位发布者:
杨慧
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午5点最活跃
-------------------------------------------------
百度基础架构部招聘
Hadoop资深研发工程师
15k-30k /北京 / 经验3-5年 / 本科及以上 / 全职
Java
分布式
hadoop
算法
系统架构
3天前  发布于拉勾网职位诱惑：
500强,弹性工作
职位描述：
工作职责:
-设计、开发、优化大规模分布式计算或文件存储系统
-为百度相关产品线提供分布式计算技术解决方案
职责要求:
-精通Java或C++，精通网络编程和多线程编程技术
-精通数据结构和算法，有极强的算法分析和工程实现能力
-熟悉分布式系统设计范型，有大规模系统设计和工程实现的经验
-良好的团队合作，较强的沟通能力，对解决具有挑战性问题充满激情
-能够指导普通工程师的工作和技术成长
具有以下条件者优先：
-2年+hadoop系统研发经验，有大型互联网服务的设计和开发经验
-MapReduce及其他并行计算的实践经验，或者HDFS等分布式文件系统的实践经验
工作地址
北京 - 海淀区 - 上地 - 百度大厦
查看地图
职位发布者:
C
chengtao02
职位发布者
聊天意愿
弱
回复率18%  用时2小时
简历处理
暂无
处理率--  用时--天
活跃时段
全天
下午3点最活跃
-------------------------------------------------
爱奇艺技术产品中心招聘
高级Hadoop开发工程师
18k-35k /北京 / 经验3-5年 / 本科及以上 / 全职
高级
hadoop
大数据
10:10  发布于拉勾网职位诱惑：
成熟平台 成长型团队
职位描述：
岗位职责
1、负责爱奇艺各垂直业务大数据处理
2、负责视频播放相关数据计算
3、关注开源技术动态，推动平台技术架构持续更新。
  任职要求
1、计算机相关专业或数理统计相关专业
2、熟悉Linux/Unix开发环境
3、精通hadoop各模块，了解HDFS数据存储机制；熟练使用hive数据处理
4、对HBase、Redis、Spark有深入了解
5、熟练使用shell命令，熟悉python/perl等脚本语言
6、思维敏捷，有较强的钻研学习能力；较好的沟通能力、团队合作
  工作地址
北京 - 海淀区 - 中关村 - 海淀北一街2号 爱奇艺创新大厦
查看地图
职位发布者:
A
Alicia
HR
聊天意愿
暂无
回复率--  用时--
简历处理
快
处理率16%  用时1天
活跃时段
全天
早9点最活跃
-------------------------------------------------
广州棒谷科技股份有限公司运维中心招聘
Hadoop运维工程师
10k-20k /广州 / 经验1-3年 / 大专及以上 / 全职
hadoop
Nginx
大数据
运维
2天前  发布于拉勾网职位诱惑：
跨境电商,晋升空间大,工作氛围好,团队牛人多
职位描述：
1.负责Hadoop相关项目日常运行维护、故障排查工作；
2.负责Hadoop集群的监控和配置调优工作；
3.负责Hadoop平台的用户管理、权限分配、资源分配；
4.负责集群服务器软件的安装、维护、部署、更新。
工作地址
广州 - 白云区 - 白云大道 - 景泰街机场东门路01号豪泉大厦2楼大厅
查看地图
职位发布者:
kongdel...
职位发布者
聊天意愿
弱
回复率15%  用时1分钟
简历处理
暂无
处理率--  用时--天
活跃时段
早上
早8点最活跃
-------------------------------------------------
PPTV聚力招聘
Hadoop工程师（龙珠直播）
15k-30k /上海 / 经验3-5年 / 本科及以上 / 全职
直播
linux
hadoop
大数据
运维
Java
11:53  发布于拉勾网职位诱惑：
五险一金；弹性工作；免费体检
职位描述：
岗位职责：
1、负责Hadoop集群相关的开发、调优、监控等工作；
2、负责Hbase、Storm、Spark项目开发、维护和实施工作；
3、负责数据平台的系统性能分析及优化；
  职位要求：
1、深刻理解Hadoop、Hive、Hbase、Spark等开源软件的工作原理；
2、熟练掌握Java，Scala开发，有开源软件源码阅读和fix经验者优先；
3、有大规模Hadoop集群运维经验者优先；
4、具有快速解决问题的能力和较强的学习能力；
5、附上github地址或blog地址有加分。

*（科班出身经验可放宽）
工作地址
上海 - 浦东新区 - 花木 - 陆家嘴软件园
查看地图
职位发布者:
bole
HR
聊天意愿
暂无
回复率--  用时4分钟
简历处理
暂无
处理率--  用时--天
活跃时段
全天
早10点最活跃
-------------------------------------------------
小年糕研发招聘
Spark/Hadoop/Storm 高级...
25k-45k /北京 / 经验5-10年 / 本科及以上 / 全职
移动互联网
spark
hadoop
大数据
Java
2天前  发布于拉勾网职位诱惑：
前景好,发展快,顶级VC,扁平管理
职位描述：
1. 研究业界最新的大数据技术，负责大数据系统的设计与开发
2. 组建及领导团队的机会
3. 为公司提供大数据存储、分析、计算支持

职位要求：
1、本科及以上学历，计算机相关专业；
2、熟练Java语言，有两年以上java开发经验，对分布式有深刻理解。
3、熟悉Hadoop/Storm/Spark/HIVE/Hbase等分布式开源项目及其工作原理，并有实际开发经验。
4、熟悉常用脚本语言shell,python等。
5、良好的trouble shooting能力
6、有互联网或移动互联网公司背景优先
工作地址
北京 - 海淀区 - 学院路 - 高德大厦
查看地图
职位发布者:
小年糕HR
职位发布者
聊天意愿
很弱
回复率--  用时12分钟
简历处理
快
处理率64%  用时1天
活跃时段
全天
早10点最活跃
-------------------------------------------------
FreeWheel大数据平台招聘
大数据平台开发工程师-Hadoop
30k-40k /北京 / 经验3-5年 / 本科及以上 / 全职
hadoop
Scala
ETL
可视化
spark
hive
2018-01-11  发布于拉勾网职位诱惑：
硅谷文化,美国轮岗,超长年假,全员持股
职位描述：
职责
负责FreeWheel数据基础架构系统或组件的调研、开发和维护工作，及时高质量地交付任务
对所负责的组件或特性进行持续的优化及改进，建立高效可扩展的数据基础架构
指导初级工程师，跨团队沟通协作
要求
扎实的编程能力，良好的开发习惯，熟悉Java、C++，熟悉Go更佳
自我驱动，有很强的解决问题能力，能够快速掌握新的技术
对流行的大数据处理平台如Hadoop有深入的了解，并有实际的项目经验，熟悉HBase、Presto、Spark更佳
有消息队列，分布式缓存，RPC框架，AWS开发，以及分布式同步等方面的实际的项目经验更佳
对Linux内核，包括线程调度，内存管理，磁盘缓存等有一定了解
良好的沟通能力与团队合作精神，能顺利进行英语口语交流
工作地址
北京 - 朝阳区 - 燕莎 - 润世中心
查看地图
职位发布者:
Cassie Guo
Recruiter
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
下午
中午1点最活跃
-------------------------------------------------
平安科技招聘
资深Hadoop开发工程师（深圳）
15k-30k /深圳 / 经验3-5年 / 本科及以上 / 全职
资深
高级
数据分析
spark
hadoop
数据挖掘
2天前  发布于拉勾网职位诱惑：
世界500强，丰厚奖金
职位描述：
岗位职责：
1、优化、设计和规划Hadoop/Spark集群，提升集群的性能、可用性、可扩展性等；
2、负责分大数据分析平台系统研发，提升大数据计算效率；
3、负责数据仓库建设，数据ETL；
4、实现大数据分析计算需求，支持海量数据挖掘。
任职资格：
1、 3年以上软件开发工作经验，2年以上Hadoop/Spark大数据相关工作经验
2、对Java面向对象编程有深入的了解，熟悉Java反射、多线程、NIO、JDBC等技术的使用与原理；
3、熟悉Shell,Python等脚本语言； 
4、熟悉Hadoop、Spark、Hbase等软件源码优先； 
5、有数据仓库、数据挖掘、互联网行业项目经验优先。
工作地址
深圳市市市 - 福田区 - 八卦岭 - 八卦岭八卦三路平安大厦
查看地图
职位发布者:
it-hr
职位发布者
聊天意愿
暂无
回复率--  用时1分钟
简历处理
超快
处理率100%  用时2天
活跃时段
下午
下午5点最活跃
-------------------------------------------------
二维火研发中心招聘
Hadoop/spark开发工程师
15k-25k /杭州 / 经验1-3年 / 本科及以上 / 全职
spark
hadoop
大数据
11:20  发布于拉勾网职位诱惑：
股票期权 快速发展
职位描述：
岗位职责：
1. 负责公司大数据平台基础架构的研发
2. 日常数据系统开发
3. 负责调优数据平台性能，保证数据平台高可用性
任职要求：
1. 具有搭建维护维护 hadoop 相关环境, troubleshooting, turning的经验
2. 熟悉jvm 运行机制，有 java 开发经验优先
3. 熟练的 java、shell、python 开发能力
4. 有海量数据开发经验优先
加分项：
• 在GitHub或其他平台上有过开源项目 
• 有个人技术博客，公开发布过技术文章、论文等
• 喜爱运动
• DOTA & LOL
我们将能提供： 
• 宽松的办公环境
• 五险一金是必须的
• 极具潜力的期权数
• 灵活的考勤方式
• 足够多的水果和零食
• 免费的咖啡和茶
• 每年不少于一次旅游
• 充分的学习机会（培训与分享）
• 餐补+年休假
• 报销所有职业书籍
你要能扛得住： 
• 做为创业公司，加班是必然的，但是会有调休
• 边做业务边改进架构的压力
• 业务快速增长下，能力也要快速提升 

工作地址
杭州 - 拱墅区 - 小河 - 教工路552号
查看地图
职位发布者:
C
chelizi
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
全天
晚上8点最活跃
-------------------------------------------------
京东商城京东大数据研发部招聘
hadoop研发工程师
30k-60k /北京 / 经验不限 / 本科及以上 / 全职
资深
高级
架构师
软件开发
大数据
架构
2018-01-16  发布于拉勾网职位诱惑：
技术导向
职位描述：
职位描述：
1，负责京东大数据技术的总体架构设计与研发；
2，负责hadoop的平台改造，保证集群的稳定性、性能监控和性能优化等；
3，技术导向的性能提升，通过协议、io、网络、算法的设计，提升平台稳定性、可扩展性，提升平台整体性能；
5，组织核心成员对现有平台的不足进行分析，找出问题，并推动改革

职位要求
1，拥有多年Java开发经验，理解io、多线程、集合等基础框架，对JVM原理有一定的了解；
2，具备良好的技术分析能力，能够结合技术场景抽象问题能力； 有强力的架构设计能力 
3，熟悉分布式系统的设计和应用，熟悉分布式系统；能对分布式存储, 计算引擎, 调度系统原理有了解； 
4，良好的沟通技能，团队合作能力，勤奋好学； 
5，喜欢尝试最新的技术，追求编写优雅的代码，从技术趋势和思路上能影响技术团队； 
6，有大数据源码开发经验的朋友的优先

工作地址
北京 - 朝阳区 - 亚运村 - 北辰西路8号北辰世纪中心A座
查看地图
职位发布者:
张逸
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
快
处理率2%  用时1天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
DATATOM技术体系招聘
Hadoop工程师
10k-15k /上海 / 经验1-3年 / 本科及以上 / 全职
后端开发
spark
hadoop
大数据
医疗健康
2天前  发布于拉勾网职位诱惑：
自主研发
职位描述：
岗位职责：
1.负责公司大数据平台的Hadoop技术栈研发。
2.负责Hadoop平台（分布式存储、分布式资源管理和调度、分布式计算等）的架构规划、设计、搭建工作；
3.负责hadoop集群的整体产品化、安装部署、运维开发等相关技术
4.负责探索, 推广新的 Hadoop 计算引擎技术, 存储引擎技术。
5.制定hadoop整体集群使用规范，规范的Hadoop平台开发、应用、日常维护、监控、异常处理等工作，保障集群稳定运行规范解决方案

任职资格：
1.一年以上hadoop集群架构开发或运维经验。
2.具有搭建维护维护 hadoop 相关环境, 针对 Hadoop 组件版本跟进,补丁跟踪,bug 定位的经验
3.熟悉Hadoop集群管理及优化、熟悉Hive/Sqoop开发及优化
3.熟悉linux系统及调错经验，熟悉 jvm 运行机制，有 shell、python开发经验。
4.有钻研新技术的热情和能力，善于交流和表达，富有团队精神
5.有互联网厂家大数据系统设计经验者优先。
6.有公安、医疗、交通等行业hadoop系统架构设计经验者优先。
7.具备丰富的分布式软件架构设计经验，熟悉Hadoop、Spark等主流的大数据处理系统架构、各组件原理与优化设计原理；
工作地址
上海 - 徐汇区 - 虹梅路 - 虹漕路448号9楼
查看地图
职位发布者:
L
liu
职位发布者
聊天意愿
很弱
回复率--  用时1分钟
简历处理
超快
处理率100%  用时1天
活跃时段
下午
下午3点最活跃
-------------------------------------------------
北京联创智融信息技术有限公司技术部招聘
Hadoop开发工程师
8k-16k /长沙 / 经验3-5年 / 大专及以上 / 全职
中级
后端开发
python
银行
linux
OpenStack
2018-01-18  发布于拉勾网职位诱惑：
项目稳定,年终奖丰厚,上市公司
职位描述：
1、计算机相关专业本科及以上学历，3年以上IT工作经验；
2、熟悉hadoop体系，熟悉hive、hbase、spark、scala，有hadoop平台2年以上实施运维经验；对cdh架构熟悉者优先
3、熟悉linux环境和命令，能编写简单的shell脚本；
4、熟悉JAVA编程、熟悉J2EE框架结构等。
5、具有独立分析问题，解决问题的能力，良好的团队合作精神、沟通协作能力和敬业精神
6.，有银行bi相关行业知识优先
工作地址
长沙市市市 - 开福区 - 芙蓉区政府 - 芙蓉中路新闻大酒店13楼办公区
查看地图
职位发布者:
Ann
招聘专员
聊天意愿
一般
回复率40%  用时1小时
简历处理
暂无
处理率100%  用时--天
活跃时段
下午
下午3点最活跃
-------------------------------------------------
什么值得买消费大数据招聘
资深Hadoop工程师
15k-25k /北京 / 经验不限 / 学历不限 / 全职
后端开发
spark
hadoop
大数据
1天前  发布于拉勾网职位诱惑：
六险一金,定期体检,弹性工作
职位描述：
职位描述：
1、负责消费大数据Hadoop平台的设计、搭建、版本升级、系统优化、故障处理、集群监控等工作；
2、负责基于Hadoop技术的海量数据处理，构建基于Hadoop生态（如Sqoop、Kafka、Hive、Spark等）下的准实时多维分析系统和深度挖掘系统；
3、为项目开发人员提供大数据技术指导及解决大数据平台应用中遇到的技术难题；
4、不断解决规模增长带来的技术和业务问题，确保大数据平台高效完成公司的数据任务工作。
  任职要求：
1、3年以上互联网公司相关研发经验，在工作中独立负责过Hadoop集群搭建与维护；
2、精通Hadoop以及其生态圈上的各种主流应用；
3、精通Java、Python，精通MapReduce，熟悉linux环境下的开发工作；
4、对大数据有强烈的兴趣，对代码要求苛刻；
5、学习能力强，有良好的团队意识。
工作地址
北京 - 丰台区 - 木樨园 - 洋桥12号院 近地铁10号线角门东
查看地图
职位发布者:
什么值得买
hr
聊天意愿
暂无
回复率--  用时--
简历处理
超快
处理率100%  用时1天
活跃时段
全天
早10点最活跃
-------------------------------------------------
泰岳智桥金融招聘
Hadoop专家
26K-46K /北京 / 经验5-10年 / 本科及以上 / 全职
架构师
hadoop
数据分析
2天前  发布于拉勾网职位诱惑：
六险一金、n+1天带薪年假、发展空间大
职位描述：
公司：北京新媒传信科技有限公司
岗位职责：
1、 进行数据分析和数据处理；
2、 实现对银行的大数据平台的建设和开发。
任职资格：
1、 熟悉hadoop数据库平台或华为分布式数据库；
2、 具有海量数据处理和数据分析开发经验，或数据体系搭建经验；
3、熟悉Teradata体系架构或有相关开发经验者优先；
4、具有金融数据相关背景经验者优先；
5、5年以上大数据相关经验，能够独立进行架构体系设计；
6、计算机、数学或统计学等相关专业，本科以上学历。
工作地址
北京 - 朝阳区 - - 北苑路甲13号院神州泰岳大厦1塔18层
查看地图
职位发布者:
Z
zhenxia...
职位发布者
聊天意愿
很弱
回复率--  用时8分钟
简历处理
快
处理率2%  用时1天
活跃时段
早上
早8点最活跃
-------------------------------------------------
考满分技术部招聘
中级Hadoop研发工程师
15k-30k /北京 / 经验1-3年 / 本科及以上 / 全职
hadoop
软件开发
大数据
Java
09:50  发布于拉勾网职位诱惑：
五险一金,免费午晚餐,各路大牛,文娱活动
职位描述：

工作职责：
1. 负责数据平台 Hadoop、Spark、ES 等集群的设计与开发；
2. 负责日志处理、离线计算、实时计算功能、性能和扩展，解决并实现业务需求；
3. 负责与产品经理沟通数据需求

任职资格：
1. 本科及以上学历，计算机专业，2-3年 Hadoop 研发工作经验；
2. 熟悉 Hadoop/HBase/Spark/Storm/Hive;
3. 熟悉 Java、Scala、Python、Shell;
4. 对数据敏感，业务理解力强，良好的数据建模和沟通能力，能有效将产品问题转化为数据问题;
5. 强烈责任感、缜密的逻辑思维能力，善于用数据说话，具备良好的项目管理及执行能力；
6. 熟悉 Spark Streaming、Storm流式处理，有相关开发经验者优先；
工作地址
北京市 - 朝阳区 - 亚运村 - 小营路25号房地置业大厦9层
查看地图
职位发布者:
H
hr
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
全天
早10点最活跃
-------------------------------------------------
唯品会数据平台与应用部招聘
大数据平台工程师（Hadoop）
25k-40k /广州 / 经验5-10年 / 本科及以上 / 全职
高级
spark
hadoop
大数据
Java
18:36  发布于拉勾网职位诱惑：
核心团队
职位描述：
职位描述：
1、负责HDFS/Yarn/Spark/Hive的故障分析，性能改进和功能扩展。
2、负责处理大数据平台Hadoop/Hive/Spark的疑难问题，为Hadoop开发者提供可靠的技术支持。
3、确保Hadoop关键作业及时完成，保持作业稳定运行。

职位要求
1、计算机软件相关专业，Java3年以上开发经验。
2、对技术有追求，能够刨根问底的搞定技术问题。
3、熟悉Hadoop/Spark/Hive等开源项目，精通其中一种源码，有patch源码经验者优先。
4、大规模集群调优有经验者优先。

工作地址
广州 - 荔湾区 - 花海街20号
查看地图
职位发布者:
L
lickey.han
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
超快
处理率100%  用时1天
活跃时段
早上
早10点最活跃
-------------------------------------------------
慧影医疗研发部招聘
Hadoop开发工程师
15K-25K /北京 / 经验1-3年 / 本科及以上 / 全职
资深
高级
hadoop
软件开发
1天前  发布于拉勾网职位诱惑：
最好的平台，发展前景广阔，升职加薪幅度大
职位描述：
岗位职责：
1.配合产品/项目客户完成需求调研和需求分析，提出技术解决方案；
2.参与系统设计、开发与实现；
3.结合需求设计实现安全、稳定、高伸缩性、高性能、易维护、易用性好的业务系统；
任职要求：
1.计算机及相关专业本科以上学历；
2.至少2年以上大数据平台经验；
3.精通Java语言及面向对象设计和开发；
4.熟悉hadoop体系，有实际开发经验；
5..熟悉Linux/Unix操作系统；
6.有良好的工作及编码习惯；
7.良好的团队协作意识，能承受一定工作压力。
工作地址
北京 - 海淀区 - 西三旗 - 西小口路66号中关村东升科技园D3楼207
查看地图
职位发布者:
S
Shaly Chen
人力资源总监
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午3点最活跃
-------------------------------------------------
沪江招聘
Hadoop大数据开发工程师
25k-35k /上海 / 经验5-10年 / 大专及以上 / 全职
资深
高级
中级
hadoop
算法
spark
2天前  发布于拉勾网职位诱惑：
上市前夜 弹性办公 周末双休
职位描述：
工作职责：
1. 负责Java Web前端和后端的设计、开发与优化工作
2. 参与数据产品的需求分析、概要设计以及功能模块的开发实现
3. 遵循软件开发规范，建立起统一可维护的软件架构，能快速实现产品需求，及时发现并解决问题
4. 对于产品设计给出相应地UI方案并进行实施，持续改善用户交互体验

任职资格：
1. 最少3年以上的Java Web开发工作经验，扎实的Java基础和大数据开发能力，熟悉基础的数据结构与算法，逻辑思维清晰。
2. 熟练使用HTML5、Javascript、CSS3.0、JQuery、Bootstrap前端技术，能快速完成前台组件的设计与开发。
3. 熟练使用Spring、MyBatis等技术框架，能设计出良好的程序架构，提高开发效率与质量。
4. 熟悉MySQL数据库，注重SQL的性能优化，熟悉使用Redis。
5. 具有良好的代码风格与编程习惯，注重文档的编写与整理工作。
6. 具有良好的抗压能力、敬业精神和团队合作精神，有上进心，责任感强，自我学习能力强，善于沟通
工作地址
上海 - 浦东新区 - 张江 - 浦东软件园博云路2号浦软大厦6-8楼
查看地图
职位发布者:
Leo Liu
招聘经理
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午2点最活跃
-------------------------------------------------
还呗-智能信贷领先者研发部招聘
Hadoop平台开发工程师
15k-25k /上海 / 经验不限 / 本科及以上 / 全职
中级
hadoop
大数据
平台
09:07  发布于拉勾网职位诱惑：
移动金融,未来金矿,精英团队,助力成长
职位描述：
数禾科技，是上市公司分众传媒（股票代码002027）旗下互联网金融子公司，团队成员来自于招商银行、中国银联、大众点评、群硕科技等知名金融或互联网企业。
公司致力于成为中国最有影响力的个人/家庭财务管理的科技金融企业，现已面市APP产品包括“拿铁财经——智能投顾专家”、“还呗——信用卡余额代偿”等，用户量正处于快速增长趋势，详询我司官网或分众传媒旗下楼宇/框架/电影院等广告展示。

工作职责：
1.    负责搭建、维护与管理Hadoop平台，以及Haddop平台上的数据存储、维护与优化。
2.   参与基于Hadoop中间件的设计开发工作。
3.   参与离线处理流程和实时处理流程的设计开发工作。

任职要求：

1.    精通分布式数据处理，有三年以上的Hadoop相关开发经验（Hive，Spark，HBase，Sqoop，Flume等）。
2.    熟悉数据仓库逻辑架构，熟悉ETL流程、元数据管理、数据质量监控等数据仓库主要环节。
3.   熟悉Java、Python等开发语言，精通MapReduce，能编写Hive UDF，熟悉shell脚本。
4.   有较强的ETL性能优化及问题分析、解决能力。
5.   对技术有激情，对代码有苛刻要求。
6.   有良好的快速学习能力和团队协作能力。
7.   有高度责任感和敬业精神，善于沟通，积极主动，能够以目标为导向理解工作中相关任务的处理优先级关系。
工作地址
上海 - 浦东新区 - 张江 - 上海市浦东新区金科路2889弄A座2层01室
查看地图
职位发布者:
徐方典
行政服务
聊天意愿
弱
回复率11%  用时35分钟
简历处理
超快
处理率100%  用时1天
活跃时段
下午
下午6点最活跃
-------------------------------------------------
凤凰网移动互联网部招聘
Hadoop研发工程师
15k-30k /北京 / 经验3-5年 / 本科及以上 / 全职
Java
大数据
平台/后台
hadoop
中间件
分布式
2018-01-11  发布于拉勾网职位诱惑：
七险一金,年底奖金,假期多多,各种补助
职位描述：
岗位描述：
1、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行；
2、负责 Hadoop、HBase、Hive、Spark、Kafka、Storm等集群的维护、 优化工作；
3、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长；
4、了解产品业务，加入产品从原型设计到正式上线的整个过程，基于对产品的理解，从技术架构的角度给予持续的优化意见；
5、开发大数据自动化运维、监控、故障处理工具，监控所有基础设施组件、应用程序，提供紧急应急措施；
  任职要求：
1、熟悉Hadoop、HBase、Kafka、Hive、Spark等组件的工作原理，并有2年以上Hadoop生态系统维护经验；
2、搭建、调优并维护过至少30个节点以上的Hadoop、HBase、Spark集群；
3、搭建、调优并维护过Hive、Storm、Kafka、Redis等服务；
4、精通一门以上脚本语言（Shell、Python等）,有开发经验者优先；
5、熟悉Linux软硬件环境、系统管理和优化，有做过大数据服务监控者优先；
6、主动性强，具有良好的沟通、协调和组织能力，富有团队精神，有较强的文档编写能力
7、熟悉分布式系统设计范型，有大规模系统设计和工程实现者优先；
8、有阅读过Hadoop等的源码并持续跟踪Hadoop社区发展方向者优先；
9、熟悉spark Streaming、storm流式处理，有相关开发经验者优先；
工作地址
北京 - 朝阳区 - 望京 - 望京街 中轻大厦
查看地图
职位发布者:
anting
HR
聊天意愿
一般
回复率25%  用时3小时
简历处理
暂无
处理率--  用时--天
活跃时段
下午
中午1点最活跃
-------------------------------------------------
e代驾招聘
Hadoop平台开发工程师
15k-25k /北京 / 经验3-5年 / 本科及以上 / 全职
高级
算法
spark
hadoop
数据挖掘
大数据
09:14  发布于拉勾网职位诱惑：
六险一金 弹性工作 季度年度奖金
职位描述：
岗位职责：
数据清洗、hadoop平台建设、ETL、及报表开发

岗位说明：
1.   扎实的计算机专业基本功，熟悉Linux系统操作，熟悉Linux命令    
2. 熟悉Shell脚本开发，Python脚本开发、有数据报表开发经验优先    
3. 具有Java基础开发能力，会Spark是加分项    
4. 熟练掌握 MySQL， Hive SQL语法，有实际提数经验    
5. 熟悉Hadoop大数据系统，有相应的数据挖掘、数据分析经验者优先    
6. 具有较强的学习、分析能力，善于分析、归纳、解决问题；    
7.本科及以上学历，统计、计量、数学、计算机等相关专业优先    
工作地址
北京 - 朝阳区 - 来广营 - 望京北路9号叶青大厦D座13层
查看地图
职位发布者:
e代驾HR
HRBP
聊天意愿
很弱
回复率--  用时10分钟
简历处理
暂无
处理率--  用时--天
活跃时段
全天
早10点最活跃
-------------------------------------------------
平安科技招聘
资深Hadoop开发工程师
12k-24k /深圳 / 经验不限 / 本科及以上 / 全职
大数据
2天前  发布于拉勾网职位诱惑：
年终奖丰厚，带薪休假，福利多
职位描述：
工作职责：
负责数据接入、大数据计算、数据清洗、数据平台搭建 负责金融大数据计算和管理平台的开发和应用
  岗位要求：
有5年以上数据仓库、数据挖掘方面的相关工作经验
  熟悉数据仓库、数据建模相关的技术细节，熟悉SQL/Hadoop/Hive/Hbase/Spark等大数据工具
 至少熟悉C++、JAVA、Python、Shell中的一种语言
 有BAT相关数据分析平台的工作经验优先。
工作地址
深圳市 - 福田区 - 八卦岭 - 八卦岭八卦三路平安大厦
查看地图
职位发布者:
it-hr
职位发布者
聊天意愿
暂无
回复率--  用时1分钟
简历处理
超快
处理率100%  用时2天
活跃时段
下午
下午5点最活跃
-------------------------------------------------
FreeWheel大数据招聘
高级大数据开发-Hadoop/Spark
30k-40k /北京 / 经验3-5年 / 本科及以上 / 全职
高级
后端开发
大数据
R
C++
Java
2天前  发布于拉勾网职位诱惑：
美资互联网,英文环境,补充养老金,技术导向
职位描述：
ABOUT THE OPPORTUNITY: 
FreeWheel is looking for passionate Software Engineers to help design and build our high-quality, innovative video advertising platform. This position is based in Beijing.  FreeWheel helps the television industry to monetize their premium contents through a robust technology platform, which enables consumers to view high quality videos on any devices including PC, smart phone, OTT device, set-top box and traditional TV.  FreeWheel's Beijing Engineering Hub is the center of our global engineering group that is building the one-stop solution for TV industry to manage its billion-dollar revenue. Our tech platform is capable of handling billions of daily requests, providing insightful forecasting of inventory and audience, processing terabytes of raw daily data, and optimizing clients' business.
   RESPONSIBILITIES: 
* Be responsible for the complete lifecycle of software development, including designing, prototyping, implementation, testing, maintenance and technical support.
* Produce technical specifications and determine operational feasibility.
* Write well designed, testable, efficient code.
* Develop software verification plans and quality assurance procedures.
* Integrate software components into a fully functional software system.
* Document and maintain software functionality.
* Tailor and deploy engineering tools, processes and metrics.
* Serve as the expert of online advertising industry, and drive the industry with continuous technical innovation.
* Partner with global engineering, product and operations teams to further incorporate collective innovations.
      Additionally, A Sr. Software Engineer in Reporting team will:
* Coordinate within and outside of the team to complete complex product feature or infrastructure development on time with high quality.
* Be responsible for a critical aspect within an application, both in developments and operations.
* Be responsible for the quality of the product related to the related functional area.
* Executing and providing feedback to technical decisions and ideas for refactoring or redesign.
* Lead junior members of the team  

ABOUT YOU
* Extensive experience on (3+ years) on building and operating large scale data processing system.
* Solid foundation in CS, with strong competencies in DS/Algorithm/DB.
* Solid programming skills, fluent with C/C++/Java/Go/Python .
* Strong passion with learning / practicing new technics 
* Familiar with Linux or similar systems.
* Experience with big data ecosystem is preferred.
* Good English skills on listening, speaking, reading and writing.
* Logical thinking style, good communication skills.
* Team working spirit, flexible on working pressure.
* Master's degree in Computer Science or related field is a plus. 
工作地址
北京 - 朝阳区 - 三元桥 - 亮马桥润世中心
查看地图
职位发布者:
Y
yaqi wang
招聘
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率100%  用时--天
活跃时段
下午
下午5点最活跃
-------------------------------------------------
京东商城京东商城招聘
Hadoop开发工程师
20k-40k /北京 / 经验1-3年 / 本科及以上 / 全职
数据分析
hadoop
大数据
032578
数据挖掘
2018-01-05  发布于拉勾网职位诱惑：
免费班车,员工助学
职位描述：
工作职责：
1.Hadoop集群以及Hive、HBase等相关软件配置、优化、维护、管理； 
2.负责Hadoop数据分析模块与其它系统/模块之间的衔接，提供基础数据分析能力； 
3.运用数据挖掘算法，解决海量数据分析、挖掘方面的业务需求。

任职资格:
1.计算机、数学或统计学等相关专业本科及以上学历； 
2.有线上Hadoop集群的搭建，管理及调优经验； 
3.熟悉Hadoop和Hive，有MapReduce编程经验； 
4.具有优秀的学习能力、独立分析问题和解决问题能力； 
5.有Spark、Storm等开源组件的使用经验者优先。
工作地址
北京 - 大兴区 - 亦庄 - 亦庄经济开发区朝林广场A座
查看地图
职位发布者:
Alvin
Recruiter
聊天意愿
暂无
回复率--  用时--
简历处理
超快
处理率100%  用时1天
活跃时段
下午
下午2点最活跃
-------------------------------------------------
中科聚信IT部招聘
高级工程师（Hadoop）
15k-30k /北京 / 经验3-5年 / 本科及以上 / 全职
专家
hadoop
大数据
数据分析
电商
2018-01-19  发布于拉勾网职位诱惑：
五险一金,平台极佳,餐补宿舍
职位描述：
岗位职责：
1.负责Hadoop平台基于HDFS和MapReduce的应用开发；
2.构建数据集市，支撑公司产品和业务迭代扩张；
3.负责大数据平台数据抽取.清洗.转换和建模的开发；
4.构建数据的监测与分析体系，帮助产品运营人员快速、及时了解产品使用动态；
5.承担过大规模 Hadoop YARN 集群的管理工作，与业务一起解决性能优化、容量规划、预算审计等问题，保障集群高效稳定经济运行
6. 与开源社区保持交流，发现对业务场景有帮助的特性并引入生产环境，或将经内部验证的特性贡献到社区
任职要求：
1.熟悉数据集市的开发流程，了解数据仓库(DW)/商业智能(BI)的数据框架；    
2.2年以上大数据相关工作经验，熟练掌握Python/Java至少一种编程语言，熟悉java者优先； 
3.熟悉Mysql/Oracle等至少一种关系型数据库，熟悉SQL开发；
4.熟悉HDFS、HBase、Hive、MapReduce、Impala、Oozie、Sqoop、Kettle等相关技术/工具，具备大数据分析项目经验；
5.熟悉Linux系统，能实际编写Shell脚本；
6.两年以上Java/Python开发相关工作经验；
7.有数据仓库开发、海量数据处理经验者优先考虑；
8.有电商数据分析、网站数据分析经验者优先；
工作地址
北京 - 海淀区 - 中关村 - 中关村资本大厦
查看地图
职位发布者:
ping.yang
职位发布者
聊天意愿
一般
回复率50%  用时17分钟
简历处理
快
处理率59%  用时1天
活跃时段
下午
下午2点最活跃
-------------------------------------------------
LinkDoc技术研发部招聘
Hadoop开发工程师
30k-40k /北京 / 经验3-5年 / 本科及以上 / 全职
高级
python
数据分析
大数据
docker
Java
2天前  发布于拉勾网职位诱惑：
技术挑战,医疗大数据,15薪
职位描述：
岗位职责：
负责Hadoop系统的资源管理和日常维护；
负责Hive/HBase/Spark/Impala等组件的优化和二次开发。

任职资格：
   1.熟悉Hadoop、Hbase、Hive，3年以上Hadoop开发经验；
   2.理解MapReduce计算框架的思想，熟悉分布式计算模型或有高效索引  技术经验者优先；
  3.精通JAVA语言，熟悉J2EE相关技术；
  4.至少熟练使用Shell、Python、Perl等脚本语言之一；
  5.热爱技术，工作认真、严谨，有团队精神。
工作地址
北京 - 海淀区 - 中关村 - 海淀大街8号中钢国际A座8层
查看地图
职位发布者:
零氪
HR
聊天意愿
暂无
回复率--  用时--
简历处理
超快
处理率100%  用时1天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
泰迪智慧研发部招聘
Hadoop运维工程师
9k-18k /武汉 / 经验不限 / 学历不限 / 全职
云计算
运维
linux
2018-01-19  发布于拉勾网职位诱惑：
四海八荒一切尽有
职位描述：
工作职责：
1.搭建安装hadoop集群以及相关的组件；
2.负责分布式集群的运维以及调优；
3.运维相关的shell脚本或者python的编写；
4.为其它部门提供技术支持。

任职要求：
1.熟悉linux系统，至少3年以上相关的运维经验；
2.熟悉hadoop的安装部署维护以及性能调优；
3.了解hadoop相关组件的功能；
4.熟悉shell、python中的一种，熟悉java更佳；
5.责任心强，良好的沟通能力和学习能力，具备团队合作精神 ；
6.本科及以上学历，计算机及相关专业，3年及以上相关工作经验。
工作地址
武汉 - 洪山区 - 鲁巷 - 民族大道182号中南民族大学北区16栋6F607
查看地图
职位发布者:
anita
部门经理
聊天意愿
一般
回复率50%  用时38分钟
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
卡车之家大数据招聘
Hadoop工程师
15K-25K /北京 / 经验3-5年 / 本科及以上 / 全职
hadoop
spark
hive
2018-01-02  发布于拉勾网职位诱惑：
七险一金、带薪年病假、弹性工作
职位描述：
岗位职责：
1、负责Hadoop生态系统的资源管理和日常维护；
2、负责hadoop平台上的数据存储，数据维护和优化；
3、集群账号权限管理，账号资源调配、监控；
4、确保实时、离线数据入库及时、准确。
职位要求：
1、计算机、数学等相关专业，本科及以上学历；
2、至少2年java使用经验，熟练掌握java基础技术；至少1年大数据类项目数据开发经验。
3、熟练掌握Linux各种命令行工具，良好的shell，awk,sed功底；
4、熟悉Spark编程、mapreduce编程；
5、熟悉Hadoop生态系统组件，如：Hive、Flume、Kafka、Sqoop、Redis、Hbase等；
6、具备Hadoop/Hbase/Hive/Zookeeper/Spark等10台以上规模集群运维经验者优先。
工作地址
北京 - 朝阳区 - 望京 - 望京soho
查看地图
职位发布者:
Sunny
招聘经理
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
暂无
--点最活跃
-------------------------------------------------
蓝盾信息安全技术股份有限公司研发中心招聘
Hadoop工程师
8k-15k /广州 / 经验1-3年 / 本科及以上 / 全职
大数据
2017-12-27  发布于拉勾网职位诱惑：
各种福利、五险一金、完善的晋升机制
职位描述：
岗位职责：
1、  从事Hadoop、Spark、Storm等分布式大数据平台产品的设计和开发；
2、  针对部门大数据业务进行大数据分析、挖掘应用的开发；
3、  为项目开发人员提供大数据技术指导及解决大数据平台应用中遇到的技术难题。
任职要求：
1、1 年以上Hadoop/Spark大数据相关工作经验；
2、熟悉Java、Shell等脚本语言；
3、熟悉Hadoop、Spark、Hbase、Storm等软件源码优先；
4、有有海量数据的分析能力和处理经验、对数据分析和数据挖掘有浓厚兴趣者优先考虑；
5、强烈的责任心和团队合作能力，良好的学习能力，逻辑思维能力并且敢于创新和接受挑战，能够在一定压力下工作。
工作地址
- 黄埔大道中路336号御发商务中心6楼
查看地图
职位发布者:
F
fwt
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
全天
下午2点最活跃
-------------------------------------------------
Thinking Data技术研发部招聘
hadoop研发工程师
20K-30K /上海 / 经验3-5年 / 本科及以上 / 全职
高级
数据分析
搜索
spark
hadoop
大数据
2天前  发布于拉勾网职位诱惑：
员工持股,发展空间大,弹性作息
职位描述：
岗位职责：
   1、负责分布式数据平台建设、数据应用开发
   2、分布式平台应用开发（Hadoop/Hive/Spark/ElasticSearch）
   3、开发数据统计及挖掘系统，各类统计及挖掘程序的开发
   4、系统的性能分析与系统优化
岗位要求：
   1、良好的编程开发能力，精通Java开发语言
   2、精通Hadoop2.0框架，熟悉分布式系统部署、开发、测试、维护过程与方法
   3、Hive、ZooKeeper、Hbase、Spark、ElasticSearch、kafka、flume等分布式开源软件实际开发和应用经验者优先
   4、熟练掌握Linux常规命令与工具，熟悉shell脚本语言
   5、熟悉数据分析和数据挖掘等技术，具备对常用挖掘算法的使用能力者优先
   6、对新技术敏感，有一定独立分析，技术研究能力，具有良好的团队合作精神
工作地址
上海市 - 长宁区 - 虹桥 - 华闻国际1203
查看地图
职位发布者:
D
dana
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
全天
早9点最活跃
-------------------------------------------------
搜狗桌面事业部招聘
搜狗金融-Java（hadoop）高...
20k-40k /北京 / 经验3-5年 / 本科及以上 / 全职
资深
高级
Java
hadoop
金融
大数据
09:57  发布于拉勾网职位诱惑：
海量用户，初创产品，前景广阔
职位描述：
【项目介绍】
定位于服务平台互联网用户的金融产品。由搜狗公司内部孵化。深度挖掘搜狗在互联网端的用户规模优势以及多年的大数据能力积累。在当下大热的互联网金融领域，搜狗将发挥用户服务和智能算法优势，并结合平台的综合运营实力。如果你认同互联网金融，智能风控，大数据模型等概念，欢迎加入我们共同创造事业。
【职位优惠】海量客户群体，成熟互联网公司内部的创业团队，低风险高成功可能，业务快速增长，个人职业具有极大的上升空间，团结和谐充满激情的小伙伴。
【特别提示】搜狗欢迎专情的你，所以提醒你只能选择两个项目，请慎重投递。
【岗位职责】
1、负责后端各种数据服务的开发。
2、负责前端业务数据ETL并进入后端存储；
3、理解业务场景、产品逻辑和分析需求，规划各种数据间的关联关系；
4、 参与公司大数据处理方向的技术拓展。
任职条件
1. 丰富的Java后端开发经验，熟悉jvm内存模型和gc机制，熟悉python core。熟悉shell，scala优先；
2. 能熟练使用常用的开发框架：Spring、Mybatis、elastic search，熟练使用IDEA，Git；
3. 熟练使用mysql，redis，队列（rabbitmq，cmq...)，具备一定的mysql调优能力；
4. 熟悉Hadoop/MapReduce/Hive/HBase/Kafka/Spark等一项或多项大数据处理技术，具有较丰富的大数据开发经验优先；
5. 熟悉各种设计模式及多线程开发，熟悉性能优化、对架构设计有一定理解和实践经验者优先；
工作地址
北京 - 海淀区 - 五道口 - 中关村东路一号院清华科技园搜狐网络大厦
查看地图
职位发布者:
sogou
HR
聊天意愿
很弱
回复率--  用时25分钟
简历处理
超快
处理率100%  用时1天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
重庆优启科技有限公司招聘
Hadoop开发工程师/大数据...
8k-16k /重庆 / 经验1-3年 / 大专及以上 / 全职
hadoop
软件开发
大数据
数据仓库
09:28  发布于拉勾网职位诱惑：
五险一金，季度绩效奖金，年终奖金
职位描述：
岗位职责：
1.负责Hadoop平台MapReduce、Hive、HBase、Impala、ETL等应用开发；
2.构建数据仓库，全方位支撑公司产品和业务迭代扩张；
3.负责大数据平台数据抽取.清洗.转换和建模的开发；
4.构建数据的监测与分析体系，帮助业务运营人员快速、及时了解业务动态；
任职要求：
1.了解数据仓库开发流程，熟悉数据仓库(DW)/商业智能(BI)的数据框架；
2.2年以上大数据工作经验，熟练掌握Python/Java至少一种编程语言，熟悉java者优先；
3.熟悉Mysql/Oracle等至少一种关系型数据库，熟悉SQL开发；
4.熟悉HDFS、HBase、Hive、MapReduce、Impala、Oozie、Sqoop、Kettle等相关技术/工具，具备大数据分析项目经验；
5.熟悉Linux系统，能实际编写Shell脚本；
6.两年以上Java/Python开发相关工作经验；
7.有数据仓库开发、海量数据处理经验者优先考虑；
工作地址
重庆 - 渝北区 - 龙溪 - 洪湖西路24号B栋8楼
查看地图
职位发布者:
李
李
人力
聊天意愿
很弱
回复率--  用时1分钟
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
美团点评技术工程及基础数据平台招聘
数据平台 - Spark/Hadoop...
20k-40k /北京 / 经验1-3年 / 本科及以上 / 全职
hadoop
spark
大数据
10:48  发布于拉勾网职位诱惑：
公司规模大,发展空间大
职位描述：

美团点评崇尚用数据说话，自上线起数据平台团队一直在不断完善公司级的统一数据平台。
数据平台基于Hadoop构建，目前每天执行20万次计算流程，负责每天百TB的数据存储、分析和实时计算，有2000多个业务指标，为十几个业务线、各层级的团队管理和产品运营，提供大量的数据决策支持。
随着美团以每年超过3倍的速度成长，数据规模带来的存储和计算压力，是我们面临的最大挑战。
现在我们开始组建负责 Hadoop 性能的技术专家团队，需要对 Hadoop/Spark 性能优化方面具有丰富经验的人才加入。这个团队负责构建稳定高效的大规模数据存储、计算服务，并确保在数据量快速增长的同时，每天凌晨重要的数据计算任务按时高效的完成。

工作职责：

- Spark/YARN/HDFS//HBase/Kylin/Presto/Hive 的性能改进、功能扩展、故障分析；
- 不断解决规模增长带来的技术和业务问题，确保Hadoop 数据平台每天上午8点完成重要数据的计算。


职位要求：

- 理工类211、985院校本科及以上学历；
- 对技术有着永无止境的追求，自认为是技术Geek，具备很强的问题解决能力；
- 熟悉Hadoop生态系统开源项目，至少精读过其中某一个的源码，对大规模数据处理具有独到的理解，有patch源代码经验者优先；
- 1年以上 Hadoop/Hive 生产环境工作经验；
- 有团队管理经验者优先。
工作地址
北京 - 朝阳区 - 望京 - 望京东路4号恒电大厦C座
查看地图
职位发布者:
杨慧
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午5点最活跃
-------------------------------------------------
竞技世界TSC招聘
hadoop运维
15k-30k /北京 / 经验3-5年 / 本科及以上 / 全职
运维
1天前  发布于拉勾网职位诱惑：
过节费，旅游，年终奖金，各种福利等着你！
职位描述：
工作职责：
1、负责Hadoop平台的容量规划、部署、及扩容；
2、负责Hadoop平台各组件服务的监控及故障处理；
3、负责Hadoop平台的用户管理、权限分配、资源分配、性能优化；
4、负责撰写相关技术文档；
  职位要求：
1、了解Hadoop、Hbase、Kafka、Hive、Spark等组件的工作原理，并有2年以上Hadoop生态系统运维经验；
2、精通一门以上脚本语言（shell、Python、perl）；
3、具备团队合作精神、责任心强，善于沟通；
4、熟悉Cloudera优先；
  我们为您提供：    1、工资奖金 ——薪资在业内极有竞争力，一年13-15个月工资，且年度有2次调薪机会；    2、五险一金 —— 按工资基数全额缴纳五险一金；    3、多种福利——交通补助、餐补、每年5000元左右过节费、春节报销回家路费、春节开门红奖金等等；   4、多种激励 —— 月度个人或项目评优、丰厚的人才推荐奖、高效团队合作奖等各种奖励；    5、员工旅游 —— 春游、夏游、秋游、大型年会，当年被评为金牌员工可以享受出国游，让您旅游玩到high；    6、健身中心——宽敞明亮随用随有的免费健身房，羽毛球、乒乓球、台球、跑步机等各种健身设施应有尽有，更有各种俱乐部，篮球、跆拳道等各种部落群让您找到志同道合的玩友！    7、健康体检——每年一度的健康体检让您的身体定期做个检查；    8、工作居住证——为符合北京市规定的员工办理北京市工作居住证；优秀的应届毕业生更有机会解决北京市户口；   9、上班时间——每天弹性工作制，错峰上下班；   10、培训分享 —— 新员工培训、沙龙、托展培训、外部培训等等，在JJ我们一起成长！
工作地址
- 上地创业路17号竞技世界大厦
查看地图
职位发布者:
Kelley
HR
聊天意愿
暂无
回复率--  用时--
简历处理
快
处理率87%  用时3天
活跃时段
早上
早10点最活跃
-------------------------------------------------
集奥聚合（GEO）研发部招聘
hadoop研发工程师
15k-25k /北京 / 经验3-5年 / 本科及以上 / 全职
hadoop
大数据
10:12  发布于拉勾网职位诱惑：
六险一金,补助,福利,期权
职位描述：
岗位要求：
1.负责构建和优化基于hadoop/hive/Hbase的存储计算平台；
2.负责整体提升hadoop/Hbase/Storm/Spark集群的高可用性、高性能、高扩展特性；
3.根据业务需求，提出最优的技术解决方案；
4.负责基于hadoop平台mapreduce和hive hql计算任务开发；
任职资格：
1.熟悉Java/php/shell/python等开发，至少1年以上Hadoop和hive ql相关开发经验；
2.具备数据库系统基本理论知识，至少掌握一种主流商业数据库产品如MySQL的管理和应用，精通SQL语言；
3.对hadoop的Map/Reduce原理有深入研究，有相关项目的实际开发经验；
4.熟悉Hadoop、Hive、spark、hbase、storm等开源项目；
5.对基于hadoop的大数据处理体系有深入认识，具备相关产品（hadoop/spark/storm/hive/hbase）项目应用研发经验；
6.熟悉分布式系统、分布式计算系统的工作机制，能熟练掌握相关核心技术的工作机理。
7.有很强的沟通和理解能力，有良好的团队协作精神、环境适应能力和执行力，在较大压力下保持工作激情。
工作地址
北京 - 东城区 - 东直门 - 东直门外大街46号天恒大厦A座1605
查看地图
职位发布者:
S
sunny
招聘主管
聊天意愿
暂无
回复率--  用时--
简历处理
超快
处理率100%  用时1天
活跃时段
早上
早9点最活跃
-------------------------------------------------
点春科技开发部招聘
hadoop开发工程师
5k-10k /无锡 / 经验1-3年 / 本科及以上 / 全职
中级
hadoop
spark
数据挖掘
大数据
2018-01-20  发布于拉勾网职位诱惑：
新项目,新技术
职位描述：
岗位职责：
1、参与公司大数据分析平台设计开发
2、基于大数据技术实现业务Service的开发；
3、从事大数据平台化的开发，提升海量数据的处理性能；
4、集群运维，解决各种疑难杂症，对系统进行性能调优;

任职要求：
1.计算机相关专业大学本科及以上学历，两年以上java开发经验，有网站/数据平台架构经验尤佳；
2.熟悉spark,storm等一种或多种实时数据处理框架；
3.熟悉Hadoop生态圈的zookeeper、hive、hbase、spooq、flume、pig等框架；
4.熟悉Redis，Memcached，Hbase，Mongodb等一种或多种NOSQL的设计和开发；
5.熟练掌握消息中间件原理，如activemq，rabbitmq或kafka等；
6.有分布式系统开发经验，熟悉分布式服务治理，分布式数据库，负载均衡等
工作地址
无锡 - 新吴区 - 菱湖大道228号天安智慧城A1-9楼
查看地图
职位发布者:
司
司鹏飞
开发总监
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
暂无
--点最活跃
-------------------------------------------------
FreeWheel大数据招聘
资深大数据开发-Hadoop/Spark
35k-50k /北京 / 经验5-10年 / 本科及以上 / 全职
资深
hadoop
spark
大数据
2天前  发布于拉勾网职位诱惑：
美资互联网,长期激励,补充养老金,技术导向
职位描述：
ABOUT THE OPPORTUNITY:
FreeWheel is looking for passionate Software Engineers to help design and build our high-quality, innovative video advertising platform. This position is based in Beijing.
  FreeWheel helps the television industry to monetize their premium contents through a robust
technology platform, which enables consumers to view high quality videos on any devices including PC, smart phone, OTT device, set-top box and traditional TV.
  FreeWheel’s Beijing Engineering Hub is the center of our global engineering group that is building the one-stop solution for TV industry to manage its billion-dollar revenue. Our tech platform is capable of handling billions of daily requests, providing insightful forecasting of inventory and audience, processing terabytes of raw daily data, and optimizing clients’ business.
  RESPONSIBILITIES:
·       Be responsible for the complete lifecycle of software development, including designing, prototyping, implementation, testing, maintenance and technical support
·       Produce technical specifications and determine operational feasibility
·       Write well designed, testable, efficient code
·       Develop software verification plans and quality assurance procedures
·       Integrate software components into a fully functional software system
·       Document and maintain software functionality
·       Tailor and deploy engineering tools, processes and metrics
·       Serve as the expert of online advertising industry, and drive the industry with continuous technical innovation
·       Partner with global engineering, product and operations teams to further incorporate collective innovations
         Additionally, A Lead Software Engineer in Reporting team will
·       Be responsible for a mission critical application or an application group, assisting manager in making technical decisions
·       Coordinate within and outside of the team to complete complex product feature or large scale infrastructure development on time with high quality
·       Oversee and be responsible for the architecture of the application or application group, work with architect group to accomplish technical initiatives
·       Lead and mentor technical members in the team, providing first hand performance review feedback to the manager of the team
  ABOUT YOU
·       Extensive experience on (5+ years) on building and operating large scale data processing system
·       Solid foundation in CS, with strong competencies in DS/Algorithm/DB
·       Solid programming skills, in depth knowledge and hands on experience with C/C++/Java/Go/Python
·       Strong passion with learning / practicing new technics
·       In depth knowledge and hands on experience with big data ecosystem
·       Knowledgeable about Linux or similar systems
·       Proficient in speaking, writing, reading and listening English
·       Logical thinking style, good communication skills
·       Team working spirit, flexible on working pressure
工作地址
北京 - 朝阳区 - 三元桥 - 亮马桥润世中心
查看地图
职位发布者:
Y
yaqi wang
招聘
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率100%  用时--天
活跃时段
下午
下午5点最活跃
-------------------------------------------------
美团点评技术工程及基础数据平台招聘
hadoop平台开发工程师
14k-25k /北京 / 经验不限 / 本科及以上 / 全职
hadoop
spark
大数据
10:48  发布于拉勾网职位诱惑：
公司规模大,发展空间大
职位描述：
美团点评基础数据部的离线计算组
拥有国内顶级的hadoop集群规模与服务，主要负责Hadoop生态系统平台化的搭建，开发与维护服务，为美团点评所有的事业群，提供稳定的海量数据存储、计算、查询、数据分析平台，支撑起美团点评O2O和全渠道零售线上和线下大数据采集、整合、分析和应用。

团队同学技术水平很高，有多个hadoop开源项目的commiter与contributor; 主要突破事迹包括: 
1. 深度改造了hadoop底层架构, 支撑万节点集群常态跨机房运行
2. 维护的YARN版本性能做到了社区的100倍以上，并支持异构资源和环境的调度，同时支撑离线/实时/机器学习/深度学习/模型在线服务的混部
3. 有两名Apache Kylin PMC和一名Apache Kylin committer，向多个开源项目贡献超过100个patch，尤其向Apache Kylin社区贡献了独立HBase集群、精确去重计数、分布式构建与HA、构建性能优化等5项核心改进
4. 向Spark社区贡献了基于磁盘的Shuffle实现，Shuffle并发控制，推测执行算法优化等核心模块优化改造

一些公开资料:
美团大数据平台架构实践
Apache Kylin在美团点评的应用
美团点评数据平台融合实践
Spark在美团的实践

工作职责：
- Spark/Hive/MapReduce, Tensorflow/MXNet, Hdfs/HBase, Yarn, Kylin, Druid,Presto 等引擎性能改进、功能扩展、故障分析；
- 不断解决规模增长带来的技术和业务问题，构造高度稳定可用的大数据分布式系统, 支撑数据价值的持续交付.
- 构建与持续迭代符合公司数据开发新模式需要的计算平台能力. 如机器学习pipeline, 下一代BI分析能力.

要求：
1. 熟悉常用数据结构与算法，代码能力必须过关。
2. 熟练掌握Java/Python/C++，熟练应用其中两者优先。
3. 学习能力强，对新技术能快速上手。
4.对分布式计算平台有理解和一定的实践经验, 对于构建超大规模集群系统以及革新开源架构有浓厚的兴趣.

下面几项是加分项，有其中一项或者多项最佳：
1. 有上述分布式计算平台内核研究经验优先。
2. 熟悉常见的机器学习算法或者深度学习算法优先。
3. 有科研能力并有成果发表在国际顶级会议、期刊者优先。

该团队现面向2018届的有能力的小伙伴开展部门定向招聘（包括校招正式岗位和长期实习岗位）
工作地址
北京 - 朝阳区 - 望京 - 望京东路4号恒电大厦C座
查看地图
职位发布者:
杨慧
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午5点最活跃
-------------------------------------------------
东方国信金融事业部招聘
Hadoop运维开发工程师
6k-10k /北京 / 经验1-3年 / 本科及以上 / 全职
后端开发
hadoop
大数据
docker
16:05  发布于拉勾网职位诱惑：
上市公司，发展前景好，薪酬福利佳
职位描述：
工作内容：
1、负责Hadoop平台的容量规划、部署、及扩容；
2、负责Hadoop平台各组件服务的监控及故障处理； 
3、负责Hadoop平台的用户管理、权限分配、资源分配、性能优化； 
4、负责撰写相关技术文档； 
5、日常监控管理值班。
岗位要求：
1、有一线coding能力，2年以上Hadoop或HBase的Java运维经验，有金融行业开发经验优先 
2、熟悉Hadoop、HBase、Hive、Spark等组件的部署、调试、参数调优，.熟练掌握Java、Scala、C++中至少一种语言。 
3、熟悉Lucene，ElastiSearch、solr框架优先。 
4、精通shell、perl开发。 
5、熟悉数据仓库，具有相关ETL开发经验优先。
工作地址
北京 - 朝阳区 - 望京 - 来广营创达三路1号院
查看地图
职位发布者:
L
lijingyun
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
快
处理率1%  用时1天
活跃时段
下午
下午5点最活跃
-------------------------------------------------
北京国文互联技术中心招聘
Hadoop运维工程师
15k-20k /北京 / 经验3-5年 / 本科及以上 / 全职
云计算
运维
linux
大数据
docker
09:42  发布于拉勾网职位诱惑：
五险一金,餐补,交通补助,通讯补助
职位描述：
工作职责：
1.负责公司大数据业务平台的架构设计、搭建工作，确保高可用
2.负责Hadoop集群的日常维护、监控、异常处理等工作，保障集群稳定运行；
3.设计实现大规模分布式集群的运维、报警监控和管理平台；
4.参与业务架构设计，在设计阶段给出可运维性改进建议；
5.深入研究大数据业务相关运维技术，持续优化集群服务架构，探索新的大数据运维技及发展方向。


任职要求：
1、统招本科以上学历
2、3年以上linux经验，至少1年hadoop运维经验；有Java开发经验；   
3、有良好的计算机和网络基础，熟悉linux文件系统、内核、性能调优，TCP/IP、HTTP等协议
4、对hadoop原理有深刻认识，具备相关产品（MapReduce、HDFS、Hive、Presto、Pig、Sqoop、Oozie、Flume、Zookeeper）的应用经验；
5、熟悉JAVA语言，熟练使用shell、python等脚本语言开发相关运维管理工具；
6、良好的文档撰写习惯。
工作地址
北京 - 海淀区 - 双榆树 - 北三环西路25号
查看地图
职位发布者:
X
xuelong
职位发布者
聊天意愿
强
回复率64%  用时11分钟
简历处理
快
处理率18%  用时1天
活跃时段
下午
下午2点最活跃
-------------------------------------------------
百度基础架构部招聘
Hadoop资深研发工程师
15k-30k /北京 / 经验3-5年 / 本科及以上 / 全职
Java
分布式
hadoop
C/C++
算法
系统架构
2018-01-16  发布于拉勾网职位诱惑：
弹性工作,500强
职位描述：
工作职责:
-设计、开发、优化大规模分布式计算或文件存储系统
-为百度相关产品线提供分布式计算技术解决方案
职责要求:
-精通Java或C++，精通网络编程和多线程编程技术
-精通数据结构和算法，有极强的算法分析和工程实现能力
-熟悉分布式系统设计范型，有大规模系统设计和工程实现的经验
-良好的团队合作，较强的沟通能力，对解决具有挑战性问题充满激情
-能够指导普通工程师的工作和技术成长
具有以下条件者优先：
-2年+hadoop系统研发经验，有大型互联网服务的设计和开发经验
-MapReduce及其他并行计算的实践经验，或者HDFS等分布式文件系统的实践经验
工作地址
北京 - 海淀区 - 西北旺 - 西北旺东路10号院百度科技园2号楼
查看地图
职位发布者:
mengzhen
recruiter
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午2点最活跃
-------------------------------------------------
人民网科技研发部招聘
推荐系统工程师/Hadoop开...
15k-25k /北京 / 经验3-5年 / 本科及以上 / 全职
python
hadoop
算法
推荐
2017-12-26  发布于拉勾网职位诱惑：
公司平台大,发展空间大,福利健全
职位描述：
岗位职责：
1、负责个性化推荐系统的架构、算法和开发，实现在相关产品中的精准推荐；
2、负责用户画像系统的设计和开发；
3、负责内容标签化系统的设计和开发。
任职资格：
1、计算机相关专业，本科及以上学历，3年以上数据开发经验；
2、处理海量实时数据和离线数据，熟悉Hadoop、Spark、HBase、Hive、Presto、Redis等计算平台和工具；
3、熟悉Java、Scala、C++等开发语言；
4、熟悉Linux系统，熟练使用脚本语言(shell或python)；
5、熟悉常用的推荐算法,有推荐系统、用户画像、NLP相关经验者优先。
工作地址
北京 - 朝阳区 - 呼家楼 - 金台西路2号新媒体大厦
查看地图
职位发布者:
S
shangda...
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
博奥特科技数据中心招聘
大数据开发工程师（hadoop）
18k-25k /深圳 / 经验5-10年 / 大专及以上 / 全职
高级
中级
Java
大数据
hadoop
15:41  发布于拉勾网职位诱惑：
大数据,金融行业,稳定发展
职位描述：
工作内容：
      1.负责总部基础架构组的大数据项目的运维开发
      2.负责运维大数据分析平台和应用的并行框架监控的实施；
      3.并且辅助CDH和elastic测试环境的测试工作。
任职要求：
       1. 专科工龄7年以上, 本科工龄5年以上,
       2. 熟悉分布式hadoop分布式
       3. 具备spark、mapreduce、jstorm/logstash任意一种开             发经验优先
       4. 有大规模团队协作开发经验, Git,单元测试等经验
       5. 具备项目经理和需求管理的经验优先 
工作地址
深圳 - 罗湖区 - 笋岗 - 红岭，国信证券
查看地图
职位发布者:
jiangqy
招聘
聊天意愿
一般
回复率57%  用时4分钟
简历处理
慢
处理率6%  用时4天
活跃时段
早上
早8点最活跃
-------------------------------------------------
百融金服运维部招聘
Hadoop运维工程师
15k-25k /北京 / 经验5-10年 / 本科及以上 / 全职
hadoop
云计算
运维
spark
docker
信息安全
13:50  发布于拉勾网职位诱惑：
六险一金,弹性工作,福利多多
职位描述：
岗位职责：
1、负责大数据平台相关系统的运维保障，包括：Hadoop、kafka、Spark、Flume、Elasticsearch、Redis分布式集群等开源系统；
2、负责大数据平台的架构审核、业务监控、持续交付、应急响应、容量规划、性能优化；
3、对hadoop各组件的权限、安全、kerberos进行配置管理；
4、负责Hadoop平台的用户管理、权限分配、资源分配；
5、熟悉mapreduce算法，能够编写和提交分布式计算任务；

任职要求：
1、计算机相关专业统招本科及以上学历；3年以上大数据平台运维工作经验
2、深入理解linux系统，运维体系结构，精于容量规划、架构设计、性能优化；
3、熟悉Hadoop大数据生态圈，包括但不限于HDFS、YARN、Hive、HBase、Spark、Kafka、Flume等，了解各组件的原理，并有实际部署维护及优化经验，有阅读源码能力者优先；
4、有开发经验优先，精通一门以上脚本语言(shell/perl/python等)；
5、具备很强的ownership，故障排查能力，有很好的技术敏感度和风险识别能力；
6、良好的服务意识，主动思考，自我驱动力强；
工作地址
北京 - 海淀区 - 中关村 - 科学院南路2号融科资讯中心C座20层
查看地图
职位发布者:
HR
HR
聊天意愿
很弱
回复率--  用时2分钟
简历处理
快
处理率23%  用时1天
活跃时段
全天
早10点最活跃
-------------------------------------------------
唯品会数据平台与应用部招聘
Hadoop平台研发工程师
20k-40k /上海 / 经验3-5年 / 本科及以上 / 全职
高级
spark
hadoop
大数据
Java
2018-01-09  发布于拉勾网职位诱惑：
核心团队,团队氛围好
职位描述：
负责HDFS/Yarn/Spark/Hive的故障分析，性能改进和功能扩展。
负责处理大数据平台Hadoop/Hive/Spark的疑难问题，为Hadoop开发者提供可靠的技术支持。
确保Hadoop关键作业及时完成，保持作业稳定运行。

职位要求
计算机软件相关专业，Java3年以上开发经验。
对技术有追求，能够刨根问底的搞定技术问题。
熟悉Hadoop/Spark/Hive等开源项目，精通其中一种源码，有patch源码经验者优先。
大规模集群调优有经验者优先。
工作地址
上海市 - 闵行区 - 华漕 - 申长路1588弄26号
查看地图
职位发布者:
L
lickey.han
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
超快
处理率100%  用时1天
活跃时段
早上
早10点最活跃
-------------------------------------------------
航仕科技数据开发部招聘
hadoop大数据开发/spark大...
30k-50k /广州 / 经验5-10年 / 本科及以上 / 全职
高级
spark
hadoop
大数据
数据挖掘
13:48  发布于拉勾网职位诱惑：
超高分红,弹性工作,亿万数据
职位描述：
工作职责：
负责PB级大数据平台服务开发、性能调优工作


岗位要求：
1 具备扎实的编程基础，熟悉java/scala/python/c++任意一种编程语言。
2 熟悉大数据生态圈服务，如Hadoop/Spark/Hive/Kafka/Flume等。
3 深入理解大数据服务框架原理，有源码阅读经验。
4 具备比较丰富的大数据服务性能调优经验。
5 良好的沟通表达、团队协作能力。
  工作地址
广州市市市 - 天河区 - 东圃 - 天河区黄埔大道中309-315号
查看地图
职位发布者:
H
hr
高级招聘经理
聊天意愿
一般
回复率22%  用时23分钟
简历处理
超快
处理率100%  用时1天
活跃时段
早上
早10点最活跃
-------------------------------------------------
晶赞科技Zamplus研发部招聘
Hadoop数据处理工程师
15k-30k /上海 / 经验3-5年 / 本科及以上 / 全职
数据挖掘
大数据
Java
09:21  发布于拉勾网职位诱惑：
科技公司,弹性工作,国内外游,免费早餐
职位描述：
工作职责：
1、参与数据产品的需求分析、设计和开发，并能预先评估项目风险，做出合理的项目预估和进度安排。
2、针对DMP系统，制定数据处理流程，开发数据处理工具。
3、根据任务安排，按时高质量完成开发工作，并对软件问题进行跟踪和分析，配合测试人员及时合理地解决问题。
  技能要求：
1、计算机及相关专业，本科及以上学历，3年以上工作经验。
2、精通Core Java，熟悉javaIO、NIO、集合、多线程开发，了解JVM运行机制和内存管理。掌握软件设计原则、面向对象开发方法。熟悉SVN、Maven等构建工具。熟悉spring者优先。
3、精通Hadoop/HBase生态体系的使用和管理，精通Hadoop、HBase、MapReduce、HDFS、Hive、Spark、Flume等开源项目原理和开发使用。
4、熟悉linux，熟练使用shell。熟悉python，熟练编写python脚本，有python框架开发经验经验者优先，有爬虫经验优先。
5、热爱互联网技术，喜欢钻研创新。具有快速学习能力，能够承受一定的工作压力，有责任心。性格积极阳光，有良好的沟通能力和团队协作能力。
工作地址
上海 - 闸北区 - 汶水路 - 灵石路695号3号楼1101室
查看地图
职位发布者:
Zamplus...
HR
聊天意愿
暂无
回复率--  用时--
简历处理
快
处理率22%  用时1天
活跃时段
早上
早10点最活跃
-------------------------------------------------
智慧星光技术中心招聘
大数据开发工程师--Hadoop...
20k-35k /北京 / 经验3-5年 / 本科及以上 / 全职
数据分析
spark
hadoop
数据挖掘
大数据
18:35  发布于拉勾网职位诱惑：
办公环境好
职位描述：
岗位职责：
1、承担建设基于Hadoop/Hbase/Spark生态的大数据离线/实时处理平台；
2、负责公司大数据集群的构建、运维、开发工作，确保高可用。
3、负责集群容量规划、扩容及集群性能优化，参与大数据基础环境的架构设计与改进；
4、参与业务数据、生产日志的抽取、转储、检索等相关工作；
5、跟进大数据前沿技术的发展，将合适的技术方案适时引入业务场景；


任职要求：
1、至少3年互联网大数据集群部署经验；有实时处理工作经历并有一定解决方案者优先；
2、熟悉大数据开源技术，包含(不限于)Hadoop/Spark/Spark Streaming/Hive/Hbase/Kafka/Solr/Es/Nosql等分布式框架/计算/存储/检索相关技术；
3、熟悉Linux操作系统的配置、管理及优化，能够独立排查及解决操作系统层面的问题；
4、掌握Java编程；熟悉Python或Shell一种脚本语言；
5、掌握SQL，Hive，SparkSQL进行数据开发；拥有较好的SQL性能调优经验；
6、优秀的分析、解决问题能力，充分的数据敏感度；有一定的高性能支撑经验和故障排除能力。
工作地址
北京市 - 海淀区 - 中关村 - 辉煌时代大厦
查看地图
职位发布者:
大数据hr
智慧星光HRbp
聊天意愿
很弱
回复率--  用时28分钟
简历处理
超快
处理率100%  用时1天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
秒针系统招聘
Hadoop运维工程师
15k-30k /北京 / 经验1-3年 / 本科及以上 / 全职
架构师
大数据
hadoop
python
linux
运维
10:29  发布于拉勾网职位诱惑：
六险一金；带薪年假；餐补房补；弹性工作
职位描述：
职位描述

负责大数据平台及相关业务系统的运维及架构工作；
研究大数据前沿技术，改进现有系统的服务和运维架构，提升运维效率

职位要求

精通Shell、Python等脚本语言，熟悉Java、Scala、Go等开发语言者优先。
熟悉Hadoop生态系统框架Hbase, HDFS, Spark, Hive等，清楚原理和机制；
精通Linux系统，熟悉TCP/IP以及常用的网络协议；
熟悉自动化运维管理工具，熟悉集群监控管理工具；
阅读过开源代码，活跃于开源社区者优先；
工作地址
北京 - 朝阳区 - 望京 - 望京soho T3B座10层
查看地图
职位发布者:
MiaozhenHR
招聘主管
聊天意愿
很弱
回复率--  用时3分钟
简历处理
快
处理率54%  用时2天
活跃时段
早上
早11点最活跃
-------------------------------------------------
新浪网信息系统部招聘
Hadoop平台开发工程师
15k-30k /北京 / 经验1-3年 / 本科及以上 / 全职
hadoop
spark
大数据
Java
14:14  发布于拉勾网职位诱惑：
大公司,班车,健身房
职位描述：
工作职责：
1.参与优化改进新浪集团数据平台基础服务，参与日传输量超过百TB的数据传输体系优化，日处理量超过PB级别的数据处理平台改进，多维实时查询分析系统的构建优化；
2.分布式机器学习算法在数据平台的构建与优化（包括常见的LR、GBDT、FM、LDA、Word2Vec及DNN等）；
3.深入源码改进各种开源大数据项目（包括Hadoop、Spark、Kafka、HBase等）。

岗位要求：
1.计算机或相关专业本科以上学历；
2.熟悉Linux环境下开发，熟练掌握C++/Java/Scala等一种以上编程语言；
3.熟悉Hadoop生态系统相关项目，精通以下项目之一的源码（Hadoop/Spark/Kafka/HBase/Flume/ElasticSearch/Druid/Kylin）；
4.具备良好的学习能力、分析能力和解决问题的能力。
工作地址
北京 - 海淀区 - 西北旺 - 北京市海淀区西北旺东路10号院西区8号楼新浪总部大厦
查看地图
职位发布者:
V
vicky
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率2%  用时--天
活跃时段
下午
下午2点最活跃
-------------------------------------------------
雁联计算招聘
初中高级hadoop
10k-18k /深圳 / 经验1-3年 / 本科及以上 / 全职
hadoop
MySQL
数据开发
大数据
数据分析
数据挖掘
2天前  发布于拉勾网职位诱惑：
国企背景、薪资待遇完善、发展前景好
职位描述：
岗位职责：
1、根据业务方提出的建模需求，编写大数据分析方案；
2、基于Oracle或者Hadoop体系架构的Hive大数据仓库数据，发现符合业务需求的数据模型，分析数据模型各组成部分之间的关系；
3、按照规定的格式存储和展示大数据分析结果；
4、开发数据分析结果的访问服务及其API接口，供其它系统或组件调用；
5、开发数据分析服务及其API接口，供其它系统或组件调用。

任职要求:
1、大专及以上学历、计算机或数学相关专业，3年以上BI/大数据建模经验；
2、独立完成过至少一个业务主题的数据分析工作；
3、熟悉Hadoop体系架构，包括Hive、Hbase、MapReduce等组件，能熟练使用MapReduce和SparkStreaming工具进行数据计算和处理；
4、精通oracle、postgresql或mysql主流数据库，有大规模数据仓库实施项目经验；
5、熟练掌握至少一种数据分析工具软件的使用；
6、具有较强的逻辑思维能力，具有良好的团队协作精神和沟通理解能力。
工作地址
深圳市 - 福田区 - 益田村 - 保税区市花路1号创凌通大厦B栋13楼
查看地图
职位发布者:
L
liangme...
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
亚鸿世纪研发部招聘
Hadoop开发工程师
10k-20k /武汉 / 经验1-3年 / 本科及以上 / 全职
大数据
2天前  发布于拉勾网职位诱惑：
六险一金/双休/年终奖/股权
职位描述：
岗位要求：
1、本科以上学历，熟悉Hadoop生态环境，对Hadoop, Hbase, Hive, Spark等至少一个项目有着深入的了解。

2、扎实的Java基础，3年以上java实际使用经验。

3、熟悉Linux系统常用操作。

4、对数据有着强烈兴趣，有部署大规模Hadoop集群的经验者优先。

5、良好的学习能力，保持对新技术的敏感性。
工作地址
- 关山大道光谷软件园F3栋11楼
查看地图
职位发布者:
A
ailinlin
人事行政主管
聊天意愿
一般
回复率33%  用时22分钟
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午5点最活跃
-------------------------------------------------
美团点评运维部招聘
Hadoop运维/集群运维
28k-50k /北京 / 经验3-5年 / 本科及以上 / 全职
资深
hadoop
linux
运维
系统工程师
3天前  发布于拉勾网职位诱惑：
可年后入职,丰厚待遇,团队大牛,全球业务
职位描述：


岗位职责
·为全球科技团队调配和管理Hadoop生态系统基础设施的一部分。
·支持全球企业基础设施，在美国及中国设有办事处。
·监控所有基础设施组件，应用程序和提供紧急应急措施。
·文件系统/网络的设计和操作程序。

任职资格
·3+年的工作经验，2年以上的运维工作经验，1年以上的hadoop的应用经验。
·在 Hadoop 基础的数据平台（HDFS, HBase, YARN, Spark, MapReduce, Kafka, Hive）有操作的实际经验。
·熟悉软件工程、 系统设计和可扩展故障容错的web体系结构。
·了解 LDAP，TCP，NTP、SNMP、SMTP、ARP、HTTP、SSH，RSYNC，SSL，使用Linux的知识。
·熟悉监控系统 Nagios, Zabbix, Splunk, ELK,等等
·利用如 scrum 敏捷方法的工作经验。
工作地址
北京 - 朝阳区 - 望京 - 望京东路4号院
查看地图
职位发布者:
John
HR
聊天意愿
一般
回复率21%  用时11分钟
简历处理
快
处理率66%  用时1天
活跃时段
早上
早9点最活跃
-------------------------------------------------
思特奇Si-tech招聘
Hadoop高级工程师
15k-30k /北京 / 经验5-10年 / 本科及以上 / 全职
大数据
2018-01-15  发布于拉勾网职位诱惑：
七险一金，弹性工时
职位描述：
岗位职责：
1、开发基于Hadoop、Spark、Storm的项目系统；
2、根据业务需要为大数据仓库的实现提供支持；
3、撰写规范专业的技术文档，研究行业前沿技术；
4、完成项目分配的工程任务。
  任职要求：
1、3年以上Java开发相关工作经验，熟悉Java核心技术；
2、一年以上Hadoop项目开发经验，对Hadoop、Hive、HBase、Spark有深入了解；
3、对分布式计算原理有较深的理解，熟悉MapReduce编程、Storm计算；
4、熟悉Hive开发及优化、了解Hadoop集群管理及优化；
5、熟悉linux开发环境，熟悉shell脚本，熟悉Python语言优先；
6、有很强的分析问题和解决问题的能力，有强烈的责任心。  
工作地址
北京 - 海淀区 - 牡丹园 - 花园路2号中关村数字电视产业园牡丹科技楼A座6层
查看地图
职位发布者:
思特奇
HR
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
早上
早9点最活跃
-------------------------------------------------
今日头条招聘
Hadoop研发工程师
25k-45k /北京 / 经验1-3年 / 本科及以上 / 全职
后端开发
2018-01-17  发布于拉勾网职位诱惑：
六险一金，免费三餐，租房补贴
职位描述：
职位职责：
1、Hadoop 技术栈的开发和管理，解决实际业务挑战，e.g. YARN, HDFS, MapReduce, Spark, etc；
2、与开源社区保持交流，发现对业务场景有帮助的特性并引入生产环境，或将经内部验证的特性贡献到社区；
3、承担千台-万台规模 Hadoop YARN 集群的管理工作，与业务一起解决性能优化、容量规划、预算审计等问题，保障集群高效稳定经济运行。

职位要求：
1、思维活跃，熟悉 Hadoop Stack 及相关基础设施；
2、优秀的设计和编码能力：针对具体的业务场景问题，快速设计和实现解决方案；对工程质量有很高的自我要求；
工作地址
北京 - 海淀区 - 北京市海淀区北三环西路43号中航广场
查看地图
职位发布者:
J
jo
职位发布者
聊天意愿
很弱
回复率--  用时1小时
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午5点最活跃
-------------------------------------------------
江苏亿科达研发部招聘
大数据hadoop开发
10k-20k /深圳 / 经验3-5年 / 本科及以上 / 全职
后端开发
分布式
spark
hadoop
大数据
1天前  发布于拉勾网职位诱惑：
五险一金,带薪年假,年度体检,节日福利
职位描述：
岗位要求：
1、本科以上学历、3年以上大数据开发或管理经验；  
2、精通oracle数据库、具备优秀的sql编写和调优能力；
3、熟悉 Hadoop、yran、hive 或 Spark 等分布式系统的工作原理，具备较强的架构、性能优化能力； 
4、有主导完成优秀应用或大型大数据项目开发经验者优先；
5、熟悉java等开发语言，熟悉常用的分布式系统；
6、有良好的团队协作与沟通能力。
工作地址
深圳市市市 - 福田区 - 购物公园 - 购物公园
查看地图
职位发布者:
T
Tina
职位发布者
聊天意愿
很弱
回复率--  用时6分钟
简历处理
超快
处理率100%  用时1天
活跃时段
下午
下午3点最活跃
-------------------------------------------------
趣店数据智能招聘
hadoop架构师
30k-50k /北京 / 经验3-5年 / 本科及以上 / 全职
后端开发
spark
hadoop
大数据
docker
11:30  发布于拉勾网职位诱惑：
上司公司,大牛云集,千万级用户,18薪
职位描述：
职位描述：
1. Hadoop相关分布式计算平台的搭建与运维
2. 分布式计算平台资源管理和作业管理
3. 集群资源与作业管理平台的建设 

职位要求： 
1. 计算机相关专业，本科以上学历 ；
2. 对分布式计算原理有较深的理解，熟悉MapReduce编程
3. 熟悉Hadoop集群管理及优化、熟悉Hive/Sqoop开发及优化
4. 熟悉Linux环境和svn，awk，vim等工具

具备以下经验者优先：
1. 熟悉python、PHP
2. 具有hadoop源码经验
工作地址
北京 - 朝阳区 - 亚运村 - 慧忠北里222号楼15层及13层
查看地图
职位发布者:
Mr. Ren
HRBP
聊天意愿
暂无
回复率--  用时--
简历处理
快
处理率71%  用时1天
活跃时段
暂无
--点最活跃
-------------------------------------------------
ofo技术部招聘
Hadoop 开发
25k-40k /北京 / 经验3-5年 / 本科及以上 / 全职
阅读
hadoop
数据挖掘
推荐
大数据
解决方案
2017-12-28  发布于拉勾网职位诱惑：
D轮融资 独角兽 广阔空间
职位描述：
【职位描述】
  1、参与公司数据仓库架构设计与研发，建设PB级的公共数据平台和服务系统，实现高质量数据的互通与共享；
2、参与公司数据产品与应用的数据研发，发觉数据商业价值，打造极致体验的数据产品；
3、助力数据化运营业务，构建丰富多样的BI应用。
  【任职要求】
1、有过大数据量下的经验，至少每日新增日志条数10亿+，新增文件大小300G+；
2、擅长sql，能用已知sql下的所有功能，解决当下问题，如果sql不满足能开发相应函数满足要求；
3、对spark、hadoop、kafka有深入了解，了解其运行机制、阅读过源码、能结合业务需求找到最优的解决方案；
4、Java或者python功底深厚，能写出优雅的代码；
5、在机器学习方面有自己的理解，能结合当前业务找到最优的解决方案。
6、极强的责任心和抗压能力。
工作地址
北京市 - 海淀区 - 中关村 - 理想国际大厦
查看地图
职位发布者:
庆辉
HR
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午6点最活跃
-------------------------------------------------
哔哩哔哩数据平台招聘
大数据开发-资深Hadoop
25k-40k /上海 / 经验5-10年 / 本科及以上 / 全职
专家
资深
hadoop
大数据
hive
10:38  发布于拉勾网职位诱惑：
年终奖,六险一金,互联网
职位描述：
工作职责：
1、hadoop大规模集群优化；
2、各种分布式存储方案构建；
3、集群数据安全相关体系建设；
1.、 4.hbase集群整体优化和功能开发；
2.、 5.hive集群性能优化；
3.、 6.Spark／Storm等相关应用，平台开发；
  职位要求
1.、 本科及以上学历，计算机及相关专业；
2.、 具有至少3年以上Java开发经验，熟悉python/shell等脚本语言，熟悉tcp/ip网络协议，熟悉基本存储原理；
3.、 熟悉hadoop相关各种开源项目，Hive/Hbase等有实际应用开发经验，具有一定独立解决问题的能力；
4.、 掌握MapReduce处理问题思想，熟悉分布式计算模型或有高效索引技术经验者优先；
5.、 熟悉多进程、多线程、数据库、IO、内存管理等方面编程者优先；
6.、 相关具体技术方向1年以上项目经验；
7.、 熟悉软件开发过程、相关规范和开发工具，能独立完成软件模块的详细设计；
逻辑思维清晰，沟通能力良好，大型互联网公司相关从业经验优先。
工作地址
上海 - 杨浦区 - 复旦大学 - 国正中心
查看地图
职位发布者:
zhaopin
招聘
聊天意愿
暂无
回复率--  用时4分钟
简历处理
超快
处理率100%  用时1天
活跃时段
下午
下午3点最活跃
-------------------------------------------------
小年糕技术部门招聘
Spark/Hadoop/Storm
25k-50k /北京 / 经验3-5年 / 本科及以上 / 全职
移动互联网
大数据
数据挖掘
2天前  发布于拉勾网职位诱惑：
弹性时间,长年假,下午茶,团建丰富
职位描述：
相遇即是缘，年轻就应该做些有挑战的事。欢迎加入创业团队。
职位描述
1. 研究业界最新的大数据技术，负责大数据系统的设计与开发
2. 组建及领导团队的机会
3. 为公司提供大数据存储、分析、计算支持

职位要求：
1、本科及以上学历，计算机相关专业；
2、熟练Java语言，有两年以上java开发经验，对分布式有深刻理解。
3、熟悉Hadoop/Storm/Spark/HIVE/Hbase等分布式开源项目及其工作原理，并有实际开发经验。
4、熟悉常用脚本语言shell,python等。
5、良好的trouble shooting能力
6、有互联网或移动互联网公司背景优先

要敢于接受创业带来的挑战，一切皆可谈。 
公司现在是初创期，一定有各种挑战，希望你充分考虑，你的经验、能力可以帮助我们和你都实现梦想…
工作地址
北京 - 海淀区 - 学院路 - 高德大厦
查看地图
职位发布者:
小年糕HR
职位发布者
聊天意愿
很弱
回复率--  用时12分钟
简历处理
快
处理率64%  用时1天
活跃时段
全天
早10点最活跃
-------------------------------------------------
滴滴出行招聘
hadoop运维工程师
20k-40k /杭州 / 经验3-5年 / 本科及以上 / 全职
运维
17:14  发布于拉勾网职位诱惑：
期权激励，六险一金，靠谱团队，福利最全
职位描述：
岗位职责:
1、负责公司大数据平台的运维保障；
2、负责大数据平台的架构审核、业务监控、持续交付、应急响应、容量规划等；
3、为线上服务高效稳定运行负责，支撑业务和数据量的快速扩张；
4、深入理解大数据平台架构，发现并解决重大故障及性能瓶颈，打造一流的大数据平台；
5、持续的创新和优化能力，提升产品整体质量，改善用户体验，控制系统成本；
  任职资格:
1、计算机相关专业本科及以上学历；
2、深入理解linux系统，运维体系结构，精于容量规划、架构设计、性能优化；
3、熟悉Hadoop大数据生态圈，包括但不限于HDFS、YARN、Hive、HBase、Spark等；
4、有1年以上Hadoop相关运维开发经验，了解Hadoop各组件的原理，并有实际部署维护经验；
5、有开发经验优先，精通一门以上脚本语言(shell/perl/python等)，熟悉java/C/C++等开发语言一种及以上；
6、深入理解Hadoop各组件的原理和实现，有阅读源码能力者优先；
7、具备很强的ownership，故障排查能力，有很好的技术敏感度和风险识别能力；
8、良好的服务意识，善于团队协作，项目管理，主动思考，自我驱动力强。
工作地址
杭州 - 西湖区 - 高新文教区 - 华星路96号互联网金融大厦15楼 北京市海淀区
查看地图
职位发布者:
毛
毛三艳
滴滴打车
聊天意愿
弱
回复率18%  用时34分钟
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午2点最活跃
-------------------------------------------------
信用宝-我爱卡数据与智能能中心招聘
Hadoop开发工程师
15k-25k /深圳 / 经验3-5年 / 本科及以上 / 全职
资深
高级
中级
hadoop
大数据
数据仓库
2天前  发布于拉勾网职位诱惑：
大咖领导,奖金多,帅哥美女,福利多样
职位描述：
工作内容：
1. 带领团队开发和完善互金领域理财和贷款方面数据仓库。
2. 负责数据仓库的架构设计。
3. 维护基于hadoop的大数据平台稳定运行;

岗位要求：
1、 计算机或者相关专业本科及以上学历, 3年以上相关工作经验;
2、 具备较强的逻辑分析能力和沟通能力；
3、熟悉Hadoop工作流程，熟练使用SQL，熟悉数据库原理，熟练使用至少一种主流关系型数据库；
4、熟悉ETL开发，能熟练使用至少一种ETL(talend,kettle等)转化开源工具;
5、熟悉Linux操作系统，熟练使用常用命令，熟练使用shell脚本;
6、有金融行业从业经验优先考虑。
工作地址
深圳 - 南山区 - 科技园 - 高新科技园南区高新南一道9南门中科大厦14B
查看地图
职位发布者:
Cindy 梁
招聘
聊天意愿
暂无
回复率--  用时--
简历处理
超快
处理率88%  用时2天
活跃时段
早上
早11点最活跃
-------------------------------------------------
大搜车数据平台开发部招聘
Hadoop架构师
15k-25k /杭州 / 经验3-5年 / 本科及以上 / 全职
架构师
spark
hadoop
大数据
10:01  发布于拉勾网职位诱惑：
大平台,弹性工作
职位描述：
岗位职责：
1.负责大搜车大数据平台的Hadoop技术研发。
2.负责集群容量规划, 扩容及集群性能优化。
3.负责探索, 推广新的 Hadoop 计算引擎技术, 存储引擎技术。
4.制定hadoop整体集群使用规范，规范的Hadoop平台开发及应用。
任职要求：
1.具有搭建维护维护 hadoop 相关环境, 针对 Hadoop 组件版本跟进,补丁跟踪,bug 定位的经验
2.熟悉分布式算法设计，对海量数据的分析处理、挖掘和分布式存储有丰富经验；
3.熟悉 jvm 运行机制，有 java开发经验
4.熟悉 Linux 操作系统, 有 开发经验
5.有钻研新技术的热情和能力，善于交流和表达，富有团队精神
加分项：
1.在GitHub或其他平台上有过开源项目 
2.有个人技术博客，公开发布过技术文章、论文等
工作地址
杭州 - 余杭区 - 五常大道175号
查看地图
职位发布者:
hr
HR
聊天意愿
很弱
回复率--  用时19分钟
简历处理
超快
处理率100%  用时2天
活跃时段
早上
早9点最活跃
-------------------------------------------------
广州丰石科技研发部招聘
Hadoop研发工程师
12k-24k /广州 / 经验3-5年 / 本科及以上 / 全职
hadoop
spark
hive
大数据
Java
2天前  发布于拉勾网职位诱惑：
周末双休,期权激励,硅谷游学,年度旅游
职位描述：
职位描述：
1.负责公司大数据引擎Hadoop应用程序设计、开发、部署、测试、发布及技术支持。
  任职要求：
1.本科及以上学历，优秀的英文读写能力，事业心强，敢于面对挑战及干劲十足；
2.熟悉基于hadoop大数据平台的部署及配置；
3.精通java/Hive/Hbase/Kafka/Spark/Sqoop/Impala编程及部署；
4.已有基于hadoop的大数据项目设计、开发、部署、测试、发布及技术支持经验；
5.熟悉ElasticsSearch编程及部署；
6.优秀的领导能力，优秀的团队协作沟通能力及团队合作精神，具备较强的项目分析及高效解决问题的能力。

本岗位接受优秀应届生！！！
应届生实习期3-5K，转正6-10K。
工作地址
广州 - 天河区 - 元岗 - 天河慧通产业广场-b区
查看地图
职位发布者:
蔡
蔡小姐
职位发布者
聊天意愿
一般
回复率38%  用时23分钟
简历处理
快
处理率75%  用时1天
活跃时段
早上
早9点最活跃
-------------------------------------------------
五八到家在线电商技术部招聘
Hadoop高级研发工程师
12k-20k /长沙 / 经验3-5年 / 大专及以上 / 全职
python
大数据
Java
C
2天前  发布于拉勾网职位诱惑：
独角兽公司，背靠58同城，腾讯，阿里。
职位描述：
岗位描述： 
1. 负责数据仓库应用产品设计和开发； 
2. 负责数据仓库建模、数据预处理子系统的设计和开发； 
3. 负责数据仓库ETL流程的优化及解决ETL相关技术问题。 
岗位要求： 
1. 熟练数据仓库的ETL的开发和数据建模，2年以上数据仓库实施经验； 
2. 熟悉分布式数据库平台开发（hadoop，spark等），熟悉分布式平台工作原理； 
3. 至少熟练使用shell、python等脚本语言之一； 
4. 有DBA经验或分布式计算平台经验者优先； 
5. 有在网站公司或海量数据处理工作经验，数据分析和挖掘经验者优先。
工作地址
长沙 - 岳麓区 - 麓谷 - 长沙市高新开发区尖山路39号中电软件园17栋
查看地图
职位发布者:
H
houfw
长沙技术负责人
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
暂无
--点最活跃
-------------------------------------------------
武汉佰钧成技术有限公司ISBG-BU15招聘
Hadoop大数据开发-外包天...
10k-15k /天津 / 经验3-5年 / 大专及以上 / 全职
征信
中级
银行
算法
数据挖掘
数据分析
11:23  发布于拉勾网职位诱惑：
办公环境好,五险一金,年终旅游,带薪年假
职位描述：
Hadoop平台管理：
工作职责：
1.管理Hadoop集群日常运行，稳定提供服务；
2.优化集群性能和资源利用率；
3.深入理解Hadoop原理，对开发人员提供帮助。
任职要求：
1.熟悉java、python、SQL、网络协议，熟悉hadoop和hive，有MapReduce分布式编程经验 ；
2.熟悉hadoop集群的搭建，管理及调优；
3.实时解决方案，如Hbase有经验者更佳；
4.性格积极乐观，诚信，有较强的语言表达能力；具备强烈的进取心、求知欲及团队合作精神；
5.有相关技术产品认证或厂商工作经历优先
  大数据开发：
工作职责：
1.负责数据仓库、数据集市的建设；
2.负责信贷市场数据的统计分析挖掘；
3.负责信贷市场数据分析平台的设计、研发及应用；
4.基于征信信贷数据的分析、建模，利用模型进行产品的评测、改进及推荐。
任职要求:
1.计算机或相关专业本科及以上学历；
2.掌握数据仓库基本理论，精通hadoop/hive开发等；
3.具有良好的编程能力，熟悉Java/Python/php/shell等编程语言；
4.熟悉SQL/HQL，有较好的SQL性能调优经验；
5.敏锐的数据感觉，学习能力强，优秀的逻辑思维能力和业务需求分析能力，较好的沟通交流能力，能够迅速融入团队；
6.有数据仓库大型项目经验者优先。

工作时间：早上9点--11：30     下午1：30--6：00，中午休息2个小时
         （因近期项目紧急，可能会需要加班，可以选择在周六加班后调休）
工作地点：天津滨海新区洞庭北路融汇商务园二区四号楼中国人民银行征信中心（有免费班车）
  福利待遇：
1、免费班车路线：有二条班车路线，其中2号线走市内，1号班车线在空港经济区上车，直达公司。（班车线路图见附件）
2、人行提供三餐需自费，早餐10元、中餐20、晚餐15元，全部为自助餐，菜式丰富，6个菜，1个汤，1个粥，4种主食，各种饮料，晚餐提供酒水。菜品质量非常好，保证物超所值
3、现场办公环境非常好，中午提供2小时休息时间，可在座位休憩，或在副楼中休闲娱乐（晚上下班后也可使用），
有台球室、乒乓球室、麻将室、健身房、KTV、两个可容纳30人的电影放映室（可媲美电影院VIP厅）、瑜伽室等。
注意：该职位是以外包的形式到天津人行工作，请谨慎投递简历！非诚勿扰，谢谢！
工作地址
天津 - 滨海新区 - 洞庭北路融汇商务园二区四号楼中国人民银行征信中心
查看地图
职位发布者:
B
B-30378
招聘专员
聊天意愿
一般
回复率27%  用时19分钟
简历处理
快
处理率12%  用时1天
活跃时段
早上
早9点最活跃
-------------------------------------------------
今日头条招聘
Hadoop研发工程师
35k-70k /上海 / 经验1-3年 / 本科及以上 / 全职
后端开发
2018-01-17  发布于拉勾网职位诱惑：
六险一金，免费三餐，租房补贴
职位描述：
职位职责：
1、Hadoop 技术栈的开发和管理，解决实际业务挑战，e.g. YARN, HDFS, MapReduce, Spark, etc；
2、与开源社区保持交流，发现对业务场景有帮助的特性并引入生产环境，或将经内部验证的特性贡献到社区；
3、承担千台-万台规模 Hadoop YARN 集群的管理工作，与业务一起解决性能优化、容量规划、预算审计等问题，保障集群高效稳定经济运行。

职位要求：
1、思维活跃，熟悉 Hadoop Stack 及相关基础设施；
2、优秀的设计和编码能力：针对具体的业务场景问题，快速设计和实现解决方案；对工程质量有很高的自我要求；
工作地址
上海 - 徐汇区 - 上海市徐汇区漕溪北路333号中金国际广场B座901-903室
查看地图
职位发布者:
J
jo
职位发布者
聊天意愿
很弱
回复率--  用时1小时
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午5点最活跃
-------------------------------------------------
美团点评技术工程及基础数据平台招聘
hadoop运维
15k-30k /北京 / 经验1-3年 / 本科及以上 / 全职
hadoop
python
运维
大数据
docker
10:48  发布于拉勾网职位诱惑：
公司规模大,发展空间大,绩效奖金,五险一金
职位描述：
岗位职责：
1.负责公司大数据业务集群的运维工作，确保高可用
2.负责基础运维、故障定位、容量规划、扩容及性能优化；
3.设计实现大规模分布式集群的运维、报警监控和管理平台；
4.参与业务架构设计，在设计阶段给出可运维性改进建议；
5.深入研究大数据业务相关运维技术，持续优化集群服务架构，探索新的大数据运维技及发展方向。

任职要求：
1. 必须要求：
1）掌握shell语言和java/python中的一种语言。
2）至少有2年的网站运维、系统运维经验。
3）熟悉Lvs/Nginx等基本的服务配置，熟悉MySQL数据库。
4）熟悉Linux操作系统的配置、管理及优化，熟悉域名能够独立排查及解决操作系统层面的问题；
5）良好的客户服务意识，强烈的责任心和使命感，执行力强，富有团队合作精神；

2. 加分项：
1）熟悉Hadoop/Hbase/Hive/Storm/Spark/Kafka/Elasticsearch/Flume等开源项目，有实操经验优先；
2）掌握puppet、kerberos应用的优先；
3）掌握CDN原理，有集群维护经验、可以评估集群瓶颈点、掌握集群结构的优先；
4）有运维团队管理经验者优先；
工作地址
北京 - 朝阳区 - 望京 - 望京东路4号恒电大厦C座
查看地图
职位发布者:
杨慧
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午5点最活跃
-------------------------------------------------
上海宏鹿信息技术服务有限公司技术研发中心招聘
Hadoop数据工程师
15k-30k /上海 / 经验3-5年 / 本科及以上 / 全职
硬件制造
hadoop
数据分析
spark
大数据
2018-01-19  发布于拉勾网职位诱惑：
弹性工作,住房补贴,员工旅游,年终奖
职位描述：
1、Hadoop集群设计包括软硬件架构、节点配置、网络、存储和容量规划；
2、大数据平台运行性能、可用性、扩展性等监控与优化调控；
3、负责基于Hadoop/Spark生态系统的研发；
4、责基于Spark的计算和挖掘研发
5、基于Hadoop各种开发工具和框架实施数据采集、分析和报表。


任职资格：
1、熟练掌握Java或Scala语言；
2、熟悉Java、Python、Shell语言，较强的独立开发能力，具备良好的代码风格；
3、具备以下1种或多种工具的开发和实施经验：Java-Mapreduce, Hive, PIG, Sqoop, Flume, HBASE, Cassandra, MangoDB, CouchDB, Spark, Shark；
4、有良好的Hadoop上分布式研发的经验，熟悉MR编程；
5、具有HBase、Hive、Storm、Spark相关的实际开发经验；
6、有独立分析和解决问题的能力；
7、能够承担一定工作压力，具备创新思维、具备团队协作精神。
  工作地址
上海 - 浦东新区 - 张江 - 盛夏路666号D栋6楼
查看地图
职位发布者:
宗
宗勤红
职位发布者
聊天意愿
弱
回复率11%  用时2小时
简历处理
暂无
处理率10%  用时--天
活跃时段
下午
下午6点最活跃
-------------------------------------------------
平安银行零售大数据招聘
Hadoop工程师
20k-30k /深圳 / 经验5-10年 / 本科及以上 / 全职
中级
后端开发
Java
大数据
hadoop
2天前  发布于拉勾网职位诱惑：
扁平管理 福利优厚
职位描述：
岗位职责：
负责大数据集群系统运维，包含系统监控、应急响应、容量规划等，研究大数据业务相关运维技术，持续优化集群服务架构，探索新的大数据运维技术及发展方向；
设计和指导基于Hadoop的MapReduce、Hive、HBase等应用开发；
1、负责公司核心集群的运维工作,保证其高可用和稳定性。
2、负责集群容量规划、扩容及集群性能优化。
3、深入研究大数据业务相关运维技术，持续优化集群服务架构，探索新的Hadoop运维技术及发展方向。
4、设计实现分布式集群的运维、监控和管理平台。
  任职要求：
1、精通Hadoop，Mapreduce，Hbase，Yarn，Spark等技术并有3年以上的开发经验。
2、精通Hive的SQL性能优化。
3、熟悉ClouderaHadoop的管理和维护尤佳。
4、精通Java开发语言，熟悉Shell，Python，Perl至少一种脚本语言。
5、3年以上中大规模集群环境下的Hadoop/Spark集群相关运维管理经验；
6、熟悉基于Hadoop的大数据平台应用开发及调优；
7、拥有Hadoop/Spark等大数据开源社区开发经验者
工作地址
深圳 - 罗湖区 - 深圳市罗湖区深南大道5047号平安银行大厦
查看地图
职位发布者:
平
平安银行
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
一般
处理率37%  用时3天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
汽车之家大数据招聘
Hadoop大数据开发工程师（...
15k-25k /北京 / 经验3-5年 / 本科及以上 / 全职
数据开发
hadoop
ETL
数据仓库
大数据
1天前  发布于拉勾网职位诱惑：
大平台,氛围好,薪资待遇好
职位描述：
岗位职责：
1.负责数据仓库ETL开发运维、数据集市搭建工作，；
2、负责数据分析指标体系建设及元数据管理；
3、负责数据质量稽查和监控设计；
4、负责数据报表系统等数据仓库应用数据产品的开发。
任职要求：
1、具备数据仓库开发经验，了解数据仓库相关理论知识；
2、熟悉Hadoop生态圈，具备Hive、Hbase、Sqoop、MR等开发能力；
3、3年以上Java软件项目开发经验；
4、熟悉SqlServer、MySQL等关系型数据库，掌握数据库应用开发；
4、熟悉Linux系统环境，具备shell、perl等脚本开发能力；
5、责任心强，热爱开源技术，有较强的逻辑思维和清晰的表达能力，具备团队协作意识；
6、具有海量数据处理、数据分析挖掘相关项目经验、互联网从业背景者优先。
工作地址
北京 - 海淀区 - 中关村 - 丹棱街三号中国电子大厦B座10层
查看地图
职位发布者:
Z
zhaoxin
招聘组
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
全天
早9点最活跃
-------------------------------------------------
斗鱼直播研发招聘
高级Hadoop/Spark大数据开发
10k-20k /武汉 / 经验3-5年 / 本科及以上 / 全职
数据库
数据
大数据
2018-01-13  发布于拉勾网职位诱惑：
福利好,机会多
职位描述：
岗位职责：
1、负责公司各类数据的处理、大数据平台框架的研发设计工作；
2、使用Spark、MapReduce、Storm、Kafka等组件进行数据处理；
3、新技术框架和解决方案预研与落地，以提高处理和分析大数据的效率和速度。

任职要求：
1、熟悉Hadoop以及Hadoop生态圈中的多个组件，如HBase、Hive、Kafka、Storm、Impala等；
2、精通JAVA编程语言，熟悉Linux操作，可以编写代码编程使用Hadoop生态中的组件和基于组件开发的大数据处理；
3、熟悉开源组件源码者优先。

工作地址
武汉市 - 洪山区 - 光谷 - 光谷软件园F3栋
查看地图
职位发布者:
斗
斗鱼直播
HR
聊天意愿
很弱
回复率--  用时24分钟
简历处理
快
处理率18%  用时1天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
宝宝树运维安全招聘
hadoop高级运维工程师
25k-30k /北京 / 经验3-5年 / 本科及以上 / 全职
hadoop
python
运维
linux
大数据
解决方案
2018-01-18  发布于拉勾网职位诱惑：
年轻朝气,团队专业,管理扁平
职位描述：
工作职责：
1、负责Hadoop集群的日常维护、监控、异常处理等工作，保障集群稳定运行；
2、对Hadoop平台运维不断优化，提升数据产品的质量和响应速度；
3、探索海量数据不断增长的解决方案，解决快速增长的业务需求；
4、负责集群服务器网络的配置、管理工作；

任职要求：
1、统招本科以上学历
2、3年以上linux经验，至少1年hadoop运维经验；有Java开发经验；   
3、有良好的计算机和网络基础，熟悉linux文件系统、内核、性能调优，TCP/IP、HTTP等协议
4、对hadoop原理有深刻认识，具备相关产品（MapReduce、HDFS、Hive、Presto、Pig、Sqoop、Oozie、Flume、Zookeeper）的应用经验；
5、熟悉JAVA语言，熟练使用shell、python等脚本语言开发相关运维管理工具；
6、良好的文档撰写习惯
   
        工作地址
北京 - 朝阳区 - 东三环北路甲26号博瑞大厦A座6层
查看地图
职位发布者:
J
jobs
HR
聊天意愿
很弱
回复率--  用时9分钟
简历处理
快
处理率55%  用时2天
活跃时段
下午
下午5点最活跃
-------------------------------------------------
中文万维技术部招聘
hadoop研发工程师
10k-20k /北京 / 经验1-3年 / 大专及以上 / 全职
中级
hadoop
大数据
数据分析
2天前  发布于拉勾网职位诱惑：
弹性时间,带薪年假,五险一金,工作餐
职位描述：
岗位职责：
1、支撑产品和运营各种业务数据分析需求；
2、持续不断的优化数据统计并实现自动化。

任职要求：
1、熟悉hadoop并能合理运用yarn,mapreduce,spak，hive,kettle,shell,sqoop来实现统计任务；
2、熟悉zeppelin,kylin,flume,strom等框架；
3、对Hadoop、Hive、HBase、spark等的原理及运维、调优方法，阅读和修改过源代码者优先；
4、善于借助工具分析服务进行服务的优化；
5、具备良好的沟通和协作能力；
6、两年及以上hadoop数据分析工作经验；
7、专科及以上学历，计算机专业。
工作地址
北京 - 东城区 - 东四 - 东四北大街168号中文万维
查看地图
职位发布者:
赵
赵先生
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
暂无
--点最活跃
-------------------------------------------------
思特奇Si-tech招聘
Hadoop工程师
8k-15k /北京 / 经验1-3年 / 本科及以上 / 全职
大数据
2018-01-15  发布于拉勾网职位诱惑：
参与大型项目开发、从中学习和锻炼
职位描述：
岗位职责： 
1、负责Hadoop相关项目的设计与开发工作； 
2、基于大数据处理平台的模型设计与数据处理工作； 
3、Hadoop相关业务脚本的性能优化与提升，不断提高系统运行效率。 

任职资格： 
1、本科及以上学历，计算机或者相关专业; 
2、2年以上JAVA开发经验，对JVM原理有一定的了解; 
3、熟悉hadoop相关各种开源项目，有Hive/Hive/HBase实际经验者优先; 
4、掌握MapReduce处理问题思想，熟悉分布式计算模型或有高效索引技术经验者优先; 
5、熟悉Linux系统，有电信BI行业经验者优先录用;  
6、软件基础理论知识扎实，具有良好的数据结构、算法功底; 
7、对数据分析新技术敏感，有一定独立分析，技术研究能力，具有良好的团队合作精神。 
工作地址
北京 - 海淀区 - 牡丹园 - 花园路2号中关村数字电视产业园牡丹科技楼A座6层
查看地图
职位发布者:
思特奇
HR
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
早上
早9点最活跃
-------------------------------------------------
搜狐媒体搜狐大数据中心招聘
Hadoop/Spark开发工程师
15k-30k /北京 / 经验1-3年 / 硕士及以上 / 全职
大数据
2018-01-19  发布于拉勾网职位诱惑：
核心业务，团队靠谱
职位描述：
【岗位要求】
1.211、985高校计算机或相关专业本科或以上学历
2.扎实的数据结构与算法基础
3.熟悉JAVA、Linux操作系统，良好的Shell脚本编程能力
4.使用过Hadoop、zookeeper、kafka、或spark者优先
【岗位职责】
1. 参与数据挖掘、数据分析工作，帮助公司建立高质量的个性化推荐产品
2. 数据离线数据平台相关基础设施搭建
3. 参与实时计算平台构建，为线上系统提供支持
工作地址
北京 - 海淀区 - 中关村 - 科学院南路2号院3号楼搜狐媒体大厦
查看地图
职位发布者:
Y
yichen2...
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午3点最活跃
-------------------------------------------------
广州棒谷科技股份有限公司研发中心招聘
Hadoop运维工程师
10k-20k /广州 / 经验1-3年 / 大专及以上 / 全职
高级
hadoop
运维
大数据
2018-01-19  发布于拉勾网职位诱惑：
跨境电商,晋升平台大,团队大牛多,工作氛围好
职位描述：
岗位职责：
1.负责Hadoop相关项目日常运行维护、故障排查工作；
2.负责Hadoop集群的监控和配置调优工作；
3.负责Hadoop平台的用户管理、权限分配、资源分配；
4.负责集群服务器软件的安装、维护、部署、更新；
任职要求：
1、统招大专及以上学历，计算机相关专业背景；
2、一年及以上Hadoop运维相关经验优先；
3、有团队合作精神。
工作地址
广州 - 白云区 - 白云大道 - 广州市白云区景泰街机场东门路01号豪泉大厦2楼前台
查看地图
职位发布者:
文先生
招聘组高级经理
聊天意愿
暂无
回复率--  用时--
简历处理
快
处理率6%  用时2天
活跃时段
下午
下午3点最活跃
-------------------------------------------------
互联网教育技术部招聘
Hadoop
18k-35k /杭州 / 经验不限 / 本科及以上 / 全职
spark
hadoop
大数据
2018-01-15  发布于拉勾网职位诱惑：
公积金实缴,保底16薪,技术氛围好,发展空间大
职位描述：
大数据工程师
  职位描述
1.负责Hadoop集群的搭建、管理、开发以及调优工作；
2.负责对接产品需求，并制定相应解决方案；
3.参与新技术选型以及调研工作，解决不断增长的海量数据。


职位要求
1. 熟悉Linux操作，具有java开发经验；
2.掌握MapReduce思想，并实际运用Hadoop、Hive、HBase等分布式开源项目，有丰富的集群部署.
3.熟悉其他分布式计算框架者，有数据仓库相关工作经验者优先；
4. 具有较强的学习能力，有一点的算法基础，对新技术敏感, 有独立分析和技术研究能力；
5.具备极强的团队精神和合作精神，对工作有热情，能够承受住压力.
工作地址
杭州 - 西湖区 - 西湖 - 文三路黄龙国际
查看地图
职位发布者:
小
小青
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午2点最活跃
-------------------------------------------------
鹏锐研发部招聘
Hadoop开发工程师
10k-20k /深圳 / 经验1-3年 / 本科及以上 / 全职
hadoop
软件开发
大数据
10:22  发布于拉勾网职位诱惑：
福利待遇,发展平台,薪酬
职位描述：
职位职责：
1.负责分布式数据平台建设、数据仓库各子系统开发
2.负责海量数据处理与开发工作，满足各类数据应用需求
3.系统的性能分析与系统优化，不断提高系统运行效率

职位要求：
4.本科及以上学历，通信或计算机相关专业；
5.熟练java开发，能够独立搭建Hadoop集群；
6.能够独立编写Map-Reduce代码；
7.熟悉大数据相关组件，如：HDFS、Hive；
8.熟练SQL开发，熟练Mysql、Redis数据库中的一种；
9.熟悉Linux系统，具备Shell、Python、Scala等脚本开发能力；
10.熟练使用版本管理软件Git；
11.学习能力强，喜欢研究新技术，有团队观念，乐于知识分享；
12.有电力相关经验者优先；

薪资待遇：
1、基本工资+绩效奖金；
2、综合医疗保险、失业保险、工伤保险、生育保险与养老保险；
3、住房公积金；
4、工作日提供餐补；
5、每一季度进行员工活动或员工聚餐；
6、带薪年假15天；
7、周末双休；
8、丰富多彩的员工文体活动；
9、其他补贴。
工作地址
深圳 - 南山区 - 西丽 - 留仙大道1183号南山云谷山水楼B3
查看地图
职位发布者:
Z
zhongwe...
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
全天
晚上10点最活跃
-------------------------------------------------
百度基础架构部招聘
基础架构部_Hadoop资深研...
15K-20K /北京 / 经验1-3年 / 本科及以上 / 全职
架构师
2018-01-16  发布于拉勾网职位诱惑：
平台大
职位描述：
工作职责:
-设计、开发、优化大规模分布式计算或文件存储系统
-为百度相关产品线提供分布式计算技术解决方案
职责要求:
-精通Java或C++，精通网络编程和多线程编程技术
-精通数据结构和算法，有极强的算法分析和工程实现能力
-熟悉分布式系统设计范型，有大规模系统设计和工程实现的经验
-良好的团队合作，较强的沟通能力，对解决具有挑战性问题充满激情
-能够指导普通工程师的工作和技术成长
具有以下条件者优先：
-2年+hadoop系统研发经验，有大型互联网服务的设计和开发经验
-MapReduce及其他并行计算的实践经验，或者HDFS等分布式文件系统的实践经验
工作地址
北京 - 海淀区 - 西北旺 - 西北旺东路10号院百度科技园2号楼
查看地图
职位发布者:
mengzhen
recruiter
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午2点最活跃
-------------------------------------------------
Hypers技术部门招聘
Hadoop工程师（北京）
8k-15k /北京 / 经验不限 / 学历不限 / 全职
hadoop
大数据
10:29  发布于拉勾网职位诱惑：
福利待遇好，发展空间巨大，公司前景好。
职位描述：
岗位职责：                                 
1.负责基于Hadoop（CDH、HDP）平台架构的规划、设计和搭建；
2.独立或者带领团队完成各种面向业务目标的数据分析模型定义和应用开发；
3.针对海量的数据开发具有数据收集、统计、分析和挖掘能力的创新型产品；
4.基于MapReduce、Spark、Flume等的大数据开发；
5.学习和研究大数据技术最新动向以满足产品、项目的需求。

要求：
1.计算机相关专业本科及以上；一年及以上工作经验
2.软件基础理论知识扎实，具有良好的数据结构、算法功底；
3.精通Hadoop等分布式开发，如：MapReduce、Spark，具有扎实的Java／Scala等开发语言功底；
4.熟悉Hadoop相关各种开源项目，如：Flume、Hive、Hbase等，并有实际应用者优先；
5.熟悉Solr／Lucene开发，熟悉NoSQL数据库者优先；
6.对新技术敏感，有一定独立分析，技术研究能力；
7.熟练使用Linux环境下开发者优先；熟悉至少一种版本控制工具，如：Git、SVN、Mercurial；
8.有个人开源项目或参与开源项目者优先；
9.有代码洁癖和自发组织Code Review的开发者优先。
工作地址
北京 - 朝阳区 - 三里屯 - 工体北路4号机电院80号楼3层科技寺滚石店
查看地图
职位发布者:
HR
职位发布者
聊天意愿
一般
回复率26%  用时15分钟
简历处理
超快
处理率100%  用时2天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
今日头条招聘
Hadoop研发工程师
35k-70k /深圳 / 经验1-3年 / 本科及以上 / 全职
后端开发
2018-01-17  发布于拉勾网职位诱惑：
六险一金，免费三餐，租房补贴
职位描述：
职位职责：
1、Hadoop 技术栈的开发和管理，解决实际业务挑战，e.g. YARN, HDFS, MapReduce, Spark, etc；
2、与开源社区保持交流，发现对业务场景有帮助的特性并引入生产环境，或将经内部验证的特性贡献到社区；
3、承担千台-万台规模 Hadoop YARN 集群的管理工作，与业务一起解决性能优化、容量规划、预算审计等问题，保障集群高效稳定经济运行。

职位要求：
1、思维活跃，熟悉 Hadoop Stack 及相关基础设施；
2、优秀的设计和编码能力：针对具体的业务场景问题，快速设计和实现解决方案；对工程质量有很高的自我要求；
工作地址
深圳 - 南山区 - 深圳市南山区海德三道海岸城东座B区15楼优客工厂 CR04房间
查看地图
职位发布者:
J
jo
职位发布者
聊天意愿
很弱
回复率--  用时1小时
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午5点最活跃
-------------------------------------------------
平安银行零售大数据研发团队招聘
Hadoop工程师
20k-30k /上海 / 经验5-10年 / 本科及以上 / 全职
中级
spark
hadoop
大数据
2天前  发布于拉勾网职位诱惑：
福利待遇佳
职位描述：
岗位职责：
负责大数据集群系统运维，包含系统监控、应急响应、容量规划等，研究大数据业务相关运维技术，持续优化集群服务架构，探索新的大数据运维技术及发展方向；
设计和指导基于Hadoop的MapReduce、Hive、HBase等应用开发；
1、负责公司核心集群的运维工作,保证其高可用和稳定性。
2、负责集群容量规划、扩容及集群性能优化。
3、深入研究大数据业务相关运维技术，持续优化集群服务架构，探索新的Hadoop运维技术及发展方向。
4、设计实现分布式集群的运维、监控和管理平台。
  任职要求：
1、精通Hadoop，Mapreduce，Hbase，Yarn，Spark等技术并有3年以上的开发经验。
2、精通Hive的SQL性能优化。
3、熟悉ClouderaHadoop的管理和维护尤佳。
4、精通Java开发语言，熟悉Shell，Python，Perl至少一种脚本语言。
5、3年以上中大规模集群环境下的Hadoop/Spark集群相关运维管理经验；
6、熟悉基于Hadoop的大数据平台应用开发及调优；
7、拥有Hadoop/Spark等大数据开源社区开发经验者。
工作地址
上海 - 浦东新区 - 陆家嘴 - 全华信息大厦
查看地图
职位发布者:
平
平安银行
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
一般
处理率37%  用时3天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
百联全渠道电商大数据部招聘
Hadoop运维
17k-34k /上海 / 经验1-3年 / 本科及以上 / 全职
hadoop
spark
大数据
09:37  发布于拉勾网职位诱惑：
氛围,突破
职位描述：
岗位职责
1. 负责企业大数据/Hadoop/storm/spark/OLAP等在线离线数据平台运维保障；
2. 负责企业内部大数据自动化运维以及数据化运营平台开发工作； 
3. 负责Hadoop/Hbase等系统的架构审核、业务监控、持续交付、应急响应、容量规划等； 
4. 为平台的稳定、高效运行负责，支撑企业业务的快速发展；
5. 深入理解数据平台架构，发现并解决重大故障及性能瓶颈，打造一流的数据平台；
6. 持续的创新和优化能力，提升产品整体质量，改善用户体验，控制系统成本。

任职要求
1. 深入理解linux系统，运维体系结构，精于容量规划、架构设计、性能优化；
2. 熟悉Hadoop大数据生态圈，包括但不限于CDH、HDFS、YARN、Hive、HBase、Spark等；
3. 有2年以上Hadoop相关运维开发经验，了解Hadoop各组件的原理，并有实际部署维护经验；
4. 有开发经验优先，精通一门以上脚本语言(shell/perl/python等)，熟悉java/C/C++等开发语言一种及以上；
5. 深入理解Hadoop各组件的原理和实现，有阅读源码能力者优先；
6. 具备很强的ownership，故障排查能力，有很好的技术敏感度和风险识别能力；
7. 良好的服务意识，善于团队协作，项目管理，主动思考，自我驱动力强。
工作地址
上海市 - 黄浦区 - 外滩 - 四川南路26号
查看地图
职位发布者:
B
BLHR
HRBP
聊天意愿
很弱
回复率--  用时2分钟
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午3点最活跃
-------------------------------------------------
爱卡汽车技术部招聘
Hadoop运维
15K-25K /北京 / 经验3-5年 / 本科及以上 / 全职
cdh
ganglia
docker
2018-01-18  发布于拉勾网职位诱惑：
大数据团队，多样的发展空间
职位描述：
  职位描述：
1、  负负责公司Docker容器的架构设计与系统开发；
2、  负责公司mycat搭建和维护；
3、  负责公司hadoop集群监控；
任职要求：
1、3年及以上的开发经验，熟悉shell,perl,python,java,php脚本或开发语言一种以上
2、精通Docker,熟悉Mesos、Kubernetes等至少一种管理工具
3、精通hadoop集群监控,熟练掌握常见监控软件zabbix、Ganglia、Nagios等监控软件的使用
4、熟悉mycat搭建和运维,熟悉mysql调优
 5、深入理解Linux系统
6、 具备优秀的逻辑思维能力，对解决挑战性问题充满热情，善于解决问题和分析问题，乐于沟通和技术分享，具备团队合作精神。
工作地址
北京 - 朝阳区 - - 盘古大观
查看地图
职位发布者:
刘涛
数据研发组主管
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
暂无
--点最活跃
-------------------------------------------------
有礼派大数据项目组招聘
Hadoop工程师
8k-15k /广州 / 经验1-3年 / 本科及以上 / 全职
spark
数据开发
hadoop
大数据
2天前  发布于拉勾网职位诱惑：
大数据项目 周末双休 五险一金
职位描述：
 Hadoop开发工程师1人 
岗位职责：
1)负责公司大数据产品的ETL开发工作；
2)负责公司大数据仓库建设，接口建模；
3)负责公司大数据分析相关
任职资格：
1)大学本科或以上学历，计算机相关专业，1年以上java开发经验；
2)熟练大数据相关技术方案，如hadoop、hive、sqoop等，熟悉CDH；
3)熟悉Linux、具有良好的shell、SQL脚本开发能力；
4)能够进行数据处理程序的设计、开发、优化，能够设计合理的数据架构，数据模型和数据处理流程，并实现，保证高性能；
5)有较强的分析问题、解决问题的能力，对技术和业务的领悟力强；
6)具有良好的团队合作精神，善于沟通；有强烈的责任心，积极主动。
工作地址
广州 - 天河区 - 石牌 - 天河东路67号丰兴广场写字楼A幢22F
查看地图
职位发布者:
W
wendy wu
HRS
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午5点最活跃
-------------------------------------------------
汇付科技研发部招聘
Hadoop 工程师
15K-25K /上海 / 经验1-3年 / 本科及以上 / 全职
hadoop
2018-01-19  发布于拉勾网职位诱惑：
互联网 科技
职位描述：
职位要求：
1、一本相关专业毕业,有敬业精神
2、熟悉Hadoop、Mapreduce、Hive、HBase和Zookeeper，熟悉Spark和Storm
3、熟悉Java应用开发，有大数据2年以上的应用开发的经验
4、了解Spring、Mybatis等框架
5、能接受出差者优先
工作地址
上海 - 徐汇区 - 田林 - 宜山路700号C5栋
查看地图
职位发布者:
linsy
hadoop
-------------------------------------------------
中文万维技术部招聘
Hadoop开发工程师
18k-28k /北京 / 经验3-5年 / 大专及以上 / 全职
高级
python
hadoop
大数据
数据分析
2018-01-15  发布于拉勾网职位诱惑：
五险一金,各种补助,零食供应,年终奖
职位描述：
岗位职责：

1、支撑产品和运营各种业务数据分析需求；
2、持续不断的优化数据统计并实现自动化。

任职要求：
1、熟悉hadoop并能合理运用yarn,mapreduce,spak，hive,kettle,shell,sqoop来实现统计任务；
2、熟悉zeppelin,kylin,flume,sotrm等框架；
3、对Hadoop、Hive、HBase、spark等的原理及运维、调优方法，阅读和修改过源代码者优先；
4、善于借助工具分析服务进行服务的优化；
5、具备良好的沟通和协作能力；
6、四年及以上hadoop数据分析工作经验；
7、专科及以上学历，计算机专业。
工作地址
北京 - 东城区 - 东四 - 东四北大街168号中文万维
查看地图
职位发布者:
Y
yangl
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
早上
早10点最活跃
-------------------------------------------------
滴滴出行大数据招聘
Hadoop运维工程师
20k-30k /杭州 / 经验1-3年 / 本科及以上 / 全职
运维
11:18  发布于拉勾网职位诱惑：
15薪、期权、六险一金
职位描述：
岗位职责:
1、负责公司大数据平台的运维保障；
2、负责大数据平台的架构审核、业务监控、持续交付、应急响应、容量规划等；
3、为线上服务高效稳定运行负责，支撑业务和数据量的快速扩张；
4、深入理解大数据平台架构，发现并解决重大故障及性能瓶颈，打造一流的大数据平台；
5、持续的创新和优化能力，提升产品整体质量，改善用户体验，控制系统成本；
  任职资格:
1、计算机相关专业本科及以上学历；3年以上相关工作经验
2、深入理解linux系统，运维体系结构，精于容量规划、架构设计、性能优化；
3、熟悉Hadoop大数据生态圈，包括但不限于HDFS、YARN、Hive、HBase、Spark等；
4、有1年以上Hadoop相关运维开发经验，了解Hadoop各组件的原理，并有实际部署维护经验；
5、有开发经验优先，精通一门以上脚本语言(shell/perl/python等)，熟悉java/C/C++等开发语言一种及以上；
6、深入理解Hadoop各组件的原理和实现，有阅读源码能力者优先；
7、具备很强的ownership，故障排查能力，有很好的技术敏感度和风险识别能力；
8、良好的服务意识，善于团队协作，项目管理，主动思考，自我驱动力强。
工作地址
杭州 - 西湖区 - 高新文教区 - 华星路96号互联网金融大厦13层
查看地图
职位发布者:
L
lizhifang
职位发布者
聊天意愿
弱
回复率16%  用时20分钟
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午3点最活跃
-------------------------------------------------
苏小研大数据产品部招聘
Hadoop产品经理
15k-20k /苏州 / 经验1-3年 / 本科及以上 / 全职
大数据
产品经理
2017-12-27  发布于拉勾网职位诱惑：
交通补贴,通讯补贴,餐饮补贴,节日福利
职位描述：
工作职责:
1，负责大数据行业发展趋势、用户需求和新技术的分析和研究。
2，负责大数据平台相关产品的规划和设计工作。
3，协调各团队和各类资源达成产品目标。
4，负责大数据产品相关文档和ppt等材料的撰写。
5，支撑公司内部产品、技术培训要求。
任职资格要求:
1，熟悉Hadoop开源大数据技术的基本体系架构，有大数据行业从业经验优先。
2，具有良好的文档编写能力，包含解决方案、演示PPT等。
3，具有良好的沟通能力，善于与客户进行有效交流，善于挖掘并引导客户需求。
4，具有良好的英文读写能力。
5，具有一定的项目管理能力。
6，具有较强的学习能力和抗压能力，能接受较频繁的短期出差。
工作地址
苏州 - 高新区 - 科技城昆仑山路58号中移软件园
查看地图
职位发布者:
Tom
公司人力
聊天意愿
暂无
回复率--  用时--
简历处理
超快
处理率80%  用时1天
活跃时段
早上
早9点最活跃
-------------------------------------------------
慕课网内容部招聘
大数据（hadoop） 讲师
16k-32k /北京 / 经验3-5年 / 学历不限 / 兼职
推荐
大数据
数据分析
视频
电商
1天前  发布于拉勾网职位诱惑：
时间自由,分成丰厚,持续分成
职位描述：
慕课网招募兼职讲师，负责创作视频课程的内容。

要求：

互联网电商行业背景，有推荐系统经验优先。

2年以上大数据从业经验，精通hive+hbase数据分析模式，具有一定算法应用能力。

精通Hive、Tez、Impala、Spark SQL、Phoenix等HBase查询工具中两种或两种以上，能对比讲解查询工具之间的差异

热爱分享，逻辑思路清晰，普通话标准，语言表达流畅，有公司内部分享或大会分享经验优先。
工作地址
北京 - 海淀区 - 魏公村 - 北京理工大学国防科技园
查看地图
职位发布者:
W
wangqifei
职位发布者
聊天意愿
一般
回复率50%  用时17分钟
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午5点最活跃
-------------------------------------------------
微医集团技术中心招聘
Hadoop架构师
20k-40k /杭州 / 经验不限 / 本科及以上 / 全职
资深
1天前  发布于拉勾网职位诱惑：
平台好
职位描述：
岗位职责：
1. 负责公司核心集群的运维工作,保证其高可用和稳定性。
2. 负责集群容量规划、扩容及集群性能优化。
3. 深入研究大数据业务相关运维技术，持续优化集群服务架构，探索新的Hadoop运维技术及发展方向。
4. 设计实现分布式集群的运维、监控和管理平台。
5. 制定hadoop整体集群使用规范，规范的Hadoop平台开发及应用；制定hadoop整体集群使用规范，规范的Hadoop平台开发及应用；
岗位要求：
1、擅长hadoop生态系统各个组件的运用和调优， 如Spark、hadoop、hbase、hive、flume、sqoop等任意3项以上, 有相关参数调优、性能优化等有实际经验，尤其在Spark领域有丰富实战经验者优先。
2、擅长Linux shell，及 java编程；
3、有实际踩坑经历, 对于相关组件的版本跟进, 补丁跟踪, bug追踪等有相关经验。
4、实际处理过各种集群在线版本升级, 数据迁移, 集群扩容, 稳定性监控等工作。
5、熟悉Kerberos安全认证系统，实施过集群权限管理, 资源隔离方面的方案规划或二次开发工作。
6、有Cloudera的CM使用经验或通过Hadoop相关认证尤佳。
工作地址
杭州 - 萧山区 - 西兴 - 启迪路198号杭州湾信息港B-13F（靠近滨江三桥）
查看地图
职位发布者:
R
recruit
招聘经理
聊天意愿
暂无
回复率--  用时--
简历处理
快
处理率8%  用时2天
活跃时段
全天
早9点最活跃
-------------------------------------------------
云盛海宏平台部招聘
高级Hadoop工程师（数据平...
13k-20k /深圳 / 经验5-10年 / 本科及以上 / 全职
资深
Java
平台/后台
hadoop
数据分析
数据
2天前  发布于拉勾网职位诱惑：
大数据,Hadoo,电商数字化
职位描述：
岗位描述：
1、主导数据平台的HBase部分架构规划、集群搭建、维护、扩展开发；
2、参与HBase相关的存储、查询的场景开发；
3、负责HBase相关生产问题与事件处理、性能调优、监控告警、迁移备份、容灾处理等；
4、指导初/中级HBase/Java开发人员进行相关开发。
岗位要求：
1、本科以上学历，5年以上Java开发经验；
2、精通使用Java语言、HBase技术；
3、熟练使用SpringMVC、MyBatis、Flume、Kafka等其中至少一项技术；
4、熟练使用面向对象编程、多线程编程；
5、熟练使用Eclipse、Maven、SVN等开发工具；
6、熟练使用Linux/UNIX，会Shell编程；
7、熟练使用关系型数据库MySQL、Oracle、PostgreSQL等其中一种技术；
8、有电商、零售、物流、数据仓库背景者优先；

工作地址
深圳 - 南山区 - 深圳湾 - 百丽大厦
查看地图
职位发布者:
L
lai.jm
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
早上
早10点最活跃
-------------------------------------------------
虎瑞科技大数据部招聘
大数据开发工程师/hadoop...
15k-25k /深圳 / 经验3-5年 / 大专及以上 / 全职
资深
高级
hadoop
数据开发
BI
spark
2天前  发布于拉勾网职位诱惑：
双休,五险一金,福利好,活动多
职位描述：
【工作内容】
1、负责大数据产品的系统设计和开发。
2、负责大数据关键技术研究和难点解决。
3、根据对数据产品的理解,，优化现有大数据系统和设计新数据开发流程

【任职要求】
1、计算机相关专业,本科及以上学历，3至8年BI数据开发经验；
2、熟悉大数据处理相关产品架构和技术（如Hadoop/Hive/HBase/Spark/Kafka/Storm/Flume/Kylin等），对内部实现机制深入了解，对其中的部分组件能进行源代码级的研究和优化；
3、熟悉数据仓库理论与技术，对ETL及BI有概念并具有丰富的实际操作经验，熟悉ETL开发流程；
4、对mysql、oracle有丰富经验，有较强的数据库脚本编程能力，有较强的存储过程编写能力；
5、熟练操作linux系统，熟悉shell脚本；
6、熟悉Java等开发语言；
7、有较强的逻辑思维能力，善于分析、归纳、快速定位并解决问题；
8、工作踏实，具有强烈的责任心和团队合作精神。愿意在技术上深入研究和持续发展，勇于迎接挑战。
工作地址
深圳 - 南山区 - 科技园 - 科苑北路东方科技大厦10楼 1001室
查看地图
职位发布者:
Q
qiufurong
职位发布者
聊天意愿
一般
回复率44%  用时27分钟
简历处理
暂无
处理率100%  用时--天
活跃时段
全天
下午2点最活跃
-------------------------------------------------
深圳博瑞得成都分公司招聘
Hadoop
10k-20k /成都 / 经验不限 / 本科及以上 / 全职
高级
中级
大数据
2018-01-16  发布于拉勾网职位诱惑：
周末双休、年度旅游、年终1-4、五险一金
职位描述：
岗位职责：
1、负责大数据相关技术研究，解决海量数据不断增长面临的挑战；
2、负责海量数据的处理、分析、挖掘和存储；
3、大数据挖掘计算平台集群管理、部署、优化、排错；
4、大数据分析项目的软件开发、维护、架构设计，文档编写等工作； 
任职要求：
1、计算机相关专业本科及以上学历；
2、有扎实的Java语言基础，熟悉JVM运行机制和内存管理，熟悉Scala语言者为佳；
3、熟悉Hadoop 2.0以上版本体系结构、各个模块的功能，对Hadoop生态圈有较全面了解，同时具有源码级开发经验；
4、对Hive、HBase、Map/Reduce、Spark有深入了解，能熟练编写Map/Reduce程序和Spark程序；
5、熟悉Hadoop运行监控及调优技术；
6、具备机器学习算法理论基础，如分类、聚类、推荐、关联规则，具备相关项目经验为佳；
7、有互联网公司或海量数据处理工作经验，数据分析和挖掘经验者优先。

技术大牛，薪酬另议。
工作地址
成都 - 高新区 - 孵化园德商国际A座
查看地图
职位发布者:
B
broadtech
HR
聊天意愿
很弱
回复率--  用时1分钟
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
至易科技IT事业部招聘
Hadoop
10k-20k /武汉 / 经验1-3年 / 本科及以上 / 全职
稳定性高、福利
大数据
数据挖掘
Java
2018-01-05  发布于拉勾网职位诱惑：
平台大、前景好、稳定性高
职位描述：
工作职责
1、参与大数据相关技术研究、大数据应用开发；
2、负责解决大数据应用相关的疑难技术问题。
    任职要求
1、教育背景：
统招二本及以上学历，专业不限，计算机相关专业优先。
2、工作经验：
具有2年以上的大数据应用开发经验；
开发过Mapreduce、Hive、HBase、Storm、Lucene/Solr等程序。
3、专业知识：
熟练掌握Java/Python/Scala/R等语言；
熟悉Hadoop技术体系，熟悉Spark、Storm等主流大数据技术。
4、技能要求：
 具备良好的逻辑分析能力和解决实际问题的能力；
 具有较强的责任心、团队精神、执行力，愿意接受工作挑战。
5、语言要求：
 英语CET-4以上。
6、个性特征：
乐观外向，积极上进，善于口头表达与人际沟通，具有沟通技巧及亲和力。
工作地址
武汉 - 洪山区 - 光谷 - 光谷创业街
查看地图
职位发布者:
A
aimee
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率50%  用时--天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
平安银行零售大数据研发团队招聘
Spark/Hadoop开发工程师
25k-40k /上海 / 经验3-5年 / 本科及以上 / 全职
专家
大数据
Java
架构
2天前  发布于拉勾网职位诱惑：
薪资福利待遇优、老板nice
职位描述：

岗位职责：
1.为海量数据的处理和分析提供高效解决方案；
2.研究Hadoop/Spark/Hbase/Hive等开源项目，对线上任务进行调优，并开发通用组件；
3.基于Hadoop平台、数仓、图库开发离线、实时数据流应用。
  任职要求：
1.扎实的计算机系统和算法基础知识；良好的英文阅读能力；
2.扎实的Java、Scala语言基础，对JVM运行机制有深入了解；
3.熟悉Hadoop、Spark并有丰富的开发经验；
4.对常见开源框架代码有研究；
5.熟悉SQL和noSQL的设计和开发；
6.熟悉企业应用设计模式、面向对象的分析和设计技术，包括设计模式、UML建模等；
7.善于思考，能独立分析和解决问题，热衷于互联网技术的研究和创新；
8.责任心强，沟通能力好，具备良好的团队合作精神；
9.有深入研究过Hadoop/Spark源码者优先。
工作地址
上海 - 浦东新区 - 陆家嘴 - 全华信息大厦
查看地图
职位发布者:
平
平安银行
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
一般
处理率37%  用时3天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
中国电信IT研发中心大数据招聘
Hadoop开发
15k-20k /上海 / 经验3-5年 / 本科及以上 / 全职
大数据
2018-01-04  发布于拉勾网职位诱惑：
央企编制 开源项目 大数据 补充公积金 17薪
职位描述：
工作职责：
1、hadoop/hbase/spark工具和插件开发。
2、hadoop/hbase/spark监控平台开发。
3、mapreduce/spark job代码优化。
4、hadoop/hbase/spark实时metrics查询框架开发。
5、hadoop/hbase/spark管理平台开发。
6、hadoop/hive/hbase/spark源码研究。
7、技术攻关和创新技术引入。
8、根据个人情况，可以选择hdfs/hive/hbase/mapreduce/spark/storm某个方向深入发展。
职位要求：
1、全日制本科以上学历，计算机或相关专业毕业。
2、精通算法和数据结构。
3、熟悉hadoop/hbase/spark原理和内部运行机制。
4、有基于Hadoop/hbase/spark系统开发和调优的经验。
5、精通java编程，有scala编程经验更佳。
6、熟悉Python/Perl/Bash shell等脚本编程语言。
7、熟悉Linux系统。
8、熟悉hadoop/hbase/spark/storm源码者优先考虑。
9、5年以上互联网行业的软件开发经验。
10、3年以上大数据平台或应用开发经验。
11、良好的团队合作精神，对解决挑战型问题充满激情。
工作地址
- 秀沿西路189号中国电信信息园B23栋
查看地图
职位发布者:
Z
zhangjunli
HRBP
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
早上
早9点最活跃
-------------------------------------------------
泰一指尚数据中心招聘
大数据高级研发工程师（Had...
15k-25k /杭州 / 经验3-5年 / 本科及以上 / 全职
数据
大数据
2018-01-15  发布于拉勾网职位诱惑：
领导nic,福利好,氛围好,上市
职位描述：
工作职责：

1、负责大数据应用相关解决方案的设计，进行技术方案材料的撰写；

2、负责大数据应用相关产品的整体架构设计，进行大数据平台上数据挖掘产品的规划及研发；

3、完成各种面向业务目标的数据分析模型的定义和应用开发；

4、开发具有数据分析、数据挖掘能力的创新型产品；

岗位要求：

1、计算机相关专业，本科及以上学历，3年以上Spark,Hadoop相关开发经验；

2、熟悉主流的云计算、大数据产品（hadoop、spark、flume等）和数据分析技术（机器学习)并具有相关项目经验；

3、精通算法设计/数据结构，精通JAVA或Scala语言编程；

4、熟悉Linux/Unix平台上的开发环境；

5、思路敏捷清晰，良好的表达和理解能力，良好的学习能力，强烈的创新意识；
工作地址
杭州 - 滨江区 - 江南 - 阡陌路482号智慧e谷a座16f－18f
查看地图
职位发布者:
Alex
HR
聊天意愿
很弱
回复率--  用时21分钟
简历处理
暂无
处理率--  用时--天
活跃时段
全天
下午4点最活跃
-------------------------------------------------
路拓科创研发部招聘
Hadoop
15k-30k /北京 / 经验3-5年 / 本科及以上 / 全职
数据分析
spark
hadoop
大数据
系统架构
Java
2017-12-25  发布于拉勾网职位诱惑：
大数据
职位描述：

任职资格
1. 本科及以上学历，五年或以上工作经验，两年以上大数据系统分析、设计和实施经验；
2. 精通Java语言及设计模式，熟悉SpringMVC、Hibernate等主流开源框架及原理；
3. 熟悉Hadoop生态，具有大型系统的架构设计经验，精通大数据相关技术，熟悉Spark、kafka、Hive、HBase、zookeeper、HDFS、MR等应用设计及开发；
4. 具有良好的分析和解决问题能力，对攻关疑难问题具有浓厚兴趣,对新技术有钻研精神，有带领团队经验者优先。
  工作地址
北京市 - 海淀区 - 皂君庙 - 大钟寺
查看地图
职位发布者:
wangjing
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
早上
早9点最活跃
-------------------------------------------------
还呗-智能信贷领先者研发部招聘
Hadoop平台架构师
20k-40k /上海 / 经验3-5年 / 学历不限 / 全职
高级
数据分析
数据挖掘
大数据
Java
09:07  发布于拉勾网职位诱惑：
移动金融,未来金矿,精英团队,助力成长
职位描述：
工作职责：
1.    负责搭建、维护与管理Hadoop平台，以及Haddop平台上的数据存储、维护与优化。
2.   参与基于Hadoop中间件的设计开发工作。
3.   参与离线处理流程和实时处理流程的设计开发工作。

任职要求：

1.   精通分布式数据处理，有三年以上的Hadoop相关开发经验（Hive，Spark，HBase，Sqoop，Flume等）。
2.   熟悉数据仓库逻辑架构，熟悉ETL流程、元数据管理、数据质量监控等数据仓库主要环节。
3.   熟悉Java、Python等开发语言，精通MapReduce，能编写Hive UDF，熟悉shell脚本。
4.   有较强的ETL性能优化及问题分析、解决能力。
5.   对技术有激情，对代码有苛刻要求。
6.   有良好的快速学习能力和团队协作能力。
7.   有高度责任感和敬业精神，善于沟通，积极主动，能够以目标为导向理解工作中相关任务的处理优先级关系。
工作地址
上海市 - 浦东新区 - 张江 - 金科路2889弄A座2层
查看地图
职位发布者:
徐方典
行政服务
聊天意愿
弱
回复率11%  用时35分钟
简历处理
超快
处理率100%  用时1天
活跃时段
下午
下午6点最活跃
-------------------------------------------------
美团点评数据部招聘
资深Hadoop大数据平台开发
35k-45k /北京 / 经验3-5年 / 本科及以上 / 全职
hadoop
spark
大数据
3天前  发布于拉勾网职位诱惑：
期权,年假,大牛团队
职位描述：
职位描述：
1.参与优化改进数据平台基础服务，参与日传输量超过百TB的数据传输体系优化，日处理量超过PB级别的数据处理平台改进，多维实时查询分析系统的构建优化；
2.分布式机器学习算法在数据平台的构建与优化（包括常见的LR、GBDT、FM、LDA、Word2Vec及DNN等）；
3.深入源码改进各种开源大数据项目（包括Hadoop、Spark、Kafka、HBase等）。
  任职要求：
1.计算机或相关专业本科以上学历；
2.熟悉Linux环境下开发，熟练掌握C++/Java/Scala等一种以上编程语言；
3.熟悉Hadoop生态系统相关项目，精通以下项目之一的源码（Hadoop/Spark/Kafka/HBase/Flume/ElasticSearch/Druid/Kylin）；
4.具备良好的学习能力、分析能力和解决问题的能力。
工作地址
北京 - 朝阳区 - 望京 - 望京
查看地图
职位发布者:
John
HR
聊天意愿
一般
回复率21%  用时11分钟
简历处理
快
处理率66%  用时1天
活跃时段
早上
早9点最活跃
-------------------------------------------------
江苏亿科达研发部招聘
hadoop spark工程师
10k-20k /深圳 / 经验1-3年 / 本科及以上 / 全职
中级
初级
金融
数据挖掘
ETL
BI
1天前  发布于拉勾网职位诱惑：
周末双休,五险一金,节日福利,带薪年假
职位描述：
职位诱惑：
团队强,项目好,待遇优,环境棒
职位描述：
岗位要求：
1、1年以上hadoop的应用开发经验
2、至少一个企业级数据仓库项目开发经验或者大数据处理项目经验；
3、 良好的编程习惯和开发能力，熟悉Java或python等开发语言，
4、熟悉常用开源分布式系统，Hadoop/Hive/Spark/Yarn，
5、1年以上mysql, oracle等数据库经验，具备优秀的SQL编写和调优能力；
6、有金融行业经验优先考虑
工作地址
深圳 - 福田区 - 购物公园 - 购物公园
查看地图
职位发布者:
T
Tina
职位发布者
聊天意愿
很弱
回复率--  用时6分钟
简历处理
超快
处理率100%  用时1天
活跃时段
下午
下午3点最活跃
-------------------------------------------------
势航网络技术中心招聘
Hadoop高级工程师
15k-25k /上海 / 经验3-5年 / 本科及以上 / 全职
spark
汽车
hadoop
软件开发
大数据
物流
2017-12-25  发布于拉勾网职位诱惑：
薪资优厚,发展空间,各种补贴
职位描述：
岗位描述：
1、参与数据平台架构设计和开发；
2、进行大数据相关技术的基础研究工作，承担并独立完成所分配的开发任务，并对交付代码质量负责；
3、完成数据处理系统的开发和技术文档的编写；
4、辅助管理Hadoop集群。

岗位要求：
1、计算机或相关专业本科及以上学历，计算机理论基础扎实，对数据结构和算法设计有较为深刻的理解；
2、精通JAVA编程语言，有良好的面向对象思想；
3、熟悉Hadoop，深入理解Map/Reduce、Hive、Hbase、HDFS相关原理及高级特性，具有丰富的海量数据处理开发经验；
4、有丰富的Hadoop集群部署、开发和维护管理经验，熟悉常见的开源大数据处理软件（Storm、Kafka、Spark等）；
5、有海量数据的分析能力和处理经验、对数据分析和数据挖掘有浓厚兴趣；
6、具备良好的团队协作精神、执行力和抗压能力；
7、有GIS、汽车、物流或物联网行业从业经验优先。
工作地址
上海 - 青浦区 - 徐泾 - 高光路215弄99号（高光路园区）5号楼3楼
查看地图
职位发布者:
hr
hr
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
早上
早11点最活跃
-------------------------------------------------
滴滴出行招聘
高级hadoop运维工程师
20k-40k /杭州 / 经验1-3年 / 本科及以上 / 全职
运维
17:14  发布于拉勾网职位诱惑：
期权激励，六险一金，靠谱团队，福利最全
职位描述：
岗位职责:
1、负责公司大数据平台的运维保障；
2、负责大数据平台的架构审核、业务监控、持续交付、应急响应、容量规划等；
3、为线上服务高效稳定运行负责，支撑业务和数据量的快速扩张；
4、深入理解大数据平台架构，发现并解决重大故障及性能瓶颈，打造一流的大数据平台；
5、持续的创新和优化能力，提升产品整体质量，改善用户体验，控制系统成本；
  任职资格:
1、计算机相关专业本科及以上学历；
2、深入理解linux系统，运维体系结构，精于容量规划、架构设计、性能优化；
3、熟悉Hadoop大数据生态圈，包括但不限于HDFS、YARN、Hive、HBase、Spark等；
4、有1年以上Hadoop相关运维开发经验，了解Hadoop各组件的原理，并有实际部署维护经验；
5、有开发经验优先，精通一门以上脚本语言(shell/perl/python等)，熟悉java/C/C++等开发语言一种及以上；
6、深入理解Hadoop各组件的原理和实现，有阅读源码能力者优先；
7、具备很强的ownership，故障排查能力，有很好的技术敏感度和风险识别能力；
8、良好的服务意识，善于团队协作，项目管理，主动思考，自我驱动力强。
工作地址
杭州
查看完整地图
职位发布者:
毛
毛三艳
滴滴打车
聊天意愿
弱
回复率18%  用时34分钟
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午2点最活跃
-------------------------------------------------
广州棒谷科技股份有限公司大数据人工智能研发招聘
BI开发/ETL开发（hadoop方向）
9k-17k /广州 / 经验1-3年 / 本科及以上 / 全职
中级
BI
数据开发
ETL
数据仓库
电商
13:37  发布于拉勾网职位诱惑：
海量数据,人工智能
职位描述：
岗位职责：
1.曾从事过BI工作，熟悉数据仓库，并参与过数据仓库的搭建工作
2.能熟练使用Kettle等ETL工具
3.能熟练编写sql语句，了解或熟悉mysql等常见关系型数据库，熟悉shell编程
4.熟悉使用Hive、MapReduce等统计分析技术，具备大数据分析项目经验；
4.独立报表能力，能根据业务需要设计和产生报表
5.有电商行业从业经历
任职要求：
1.数据仓库主题设计，核心表设计，查询性能优化；
2.数据抽取ETL工作，使用存储过程、ETL工具进行数据的萃取和整理；
3.数据项目和报表，能根据业务团队的分析需求开发多维报表，搭建数据
工作地址
广州 - 白云区 - 白云大道 - 景泰街机场东门路01号豪泉大厦2楼大厅
查看地图
职位发布者:
aiko
大数据人工智能HRBP
聊天意愿
一般
回复率45%  用时1小时
简历处理
快
处理率36%  用时1天
活跃时段
全天
早9点最活跃
-------------------------------------------------
绿源数据大数据研发部招聘
高级Hadoop工程师
18k-30k /深圳 / 经验5-10年 / 本科及以上 / 全职
高级
数据分析
金融
spark
hadoop
大数据
2018-01-12  发布于拉勾网职位诱惑：
期权,金融行业,带薪年假,体检、旅游
职位描述：
职位描述：
1、负责金融大数据Hadoop平台的设计、搭建、版本升级、系统优化、故障处理、集群监控等工作；
2、负责基于Hadoop技术的海量数据处理，构建基于Hadoop生态（如Sqoop、Kafka、Hive、Spark等）；
3、为项目开发人员提供大数据技术指导及解决大数据平台应用中遇到的技术难题；

  任职要求：
1、5年以上大数据相关开发经验；
2、精通Hadoop以及其生态圈上的各种主流应用；
3、精通Java、Python，精通MapReduce，熟悉linux环境下的开发工作；
4、对大数据有强烈的兴趣，对代码要求苛刻；
5、学习能力强，有良好的团队意识。
工作地址
深圳 - 南山区 - 后海 - 中洲控股中心A座
查看地图
职位发布者:
H
hemh
ETL
聊天意愿
强
回复率67%  用时1分钟
简历处理
快
处理率25%  用时1天
活跃时段
全天
下午2点最活跃
-------------------------------------------------
大讲台教学部招聘
hadoop、spark、人工智能等...
5k-10k /北京 / 经验3-5年 / 本科及以上 / 全职
数据分析
深度学习
人工智能
大数据
数据挖掘
2018-01-18  发布于拉勾网职位诱惑：
高薪资汇报,时间自由,赚零花钱,积累惊讶
职位描述：
职位描述：
1、配合教学总监研发符合市场需求的课程体系
2、配合数据分析、spark、python、项目课程研发和后期优化；
3、配合教学总监完成相关教学资料（实训大纲、教学 PPT 、教学案例等）的研发工作
4、按照课程体系、教学大纲高质量完成网络授课

任职要求：
1. 本科及以上学历，计算机相关专业，3年以上工作经验；
2. 熟练掌握数据分析、spark、python、项目工具，如SPSS、Matlab、SAS、Python、R等， 具备快速模型求解与优化的能力。
3. 善于沟通，良好的表达能力，乐于技术分享。
4. 具有较强分析问题和解决问题能力。
5.有大数据开发、数据挖掘、数据分析、数据仓库、推荐算法等开发经验者优先。
6.有过培训课程授课经验，能按要求自行制作课件者优先考虑。

长期招聘兼职讲师，hadoop、spark、人工智能、python、数据分析
工作地址
北京 - 海淀区 - 花园桥 - 北京市海淀区车公庄西路甲19号
查看地图
职位发布者:
周小姐
HR
聊天意愿
一般
回复率33%  用时1小时
简历处理
暂无
处理率100%  用时--天
活跃时段
早上
早9点最活跃
-------------------------------------------------
盛世全景研发部招聘
Spark/Hadoop大数据开发
10k-20k /北京 / 经验1-3年 / 本科及以上 / 全职
数据分析
算法
spark
hadoop
数据挖掘
大数据
09:25  发布于拉勾网职位诱惑：
五险一金,年终奖,弹性上下班,节假日福利
职位描述：
岗位职责:
负责基于Spark的并行计算平台的开发与优化工作。

任职资格：
1、熟悉并行计算或者分布式计算，熟悉Spark框架,熟练掌握RDD编程；
2、熟悉Spark源码者优先；
3、熟悉ZooKeeper/kafka/Hadoop/HBase/Flume等平台者优先；
4、有深厚的操作系统，数据结构和算法基础；
5、2年以上软件开发经验，熟练掌握Java或Scala语言；
6、做事严谨踏实，责任心强，条理清楚，善于学习总结，有良好的团队合作精神和沟通协调能力。
工作地址
北京 - 海淀区 - 五道口 - 中关村东路18号财智国际大厦
查看地图
职位发布者:
hr
职位发布者
聊天意愿
很弱
回复率--  用时26分钟
简历处理
超快
处理率100%  用时1天
活跃时段
下午
下午5点最活跃
-------------------------------------------------
武汉佰钧成技术有限公司大数据部门招聘
Hadoop大数据职位介绍
28k-50k /深圳 / 经验5-10年 / 大专及以上 / 全职
Python
spark
hadoop
大数据
2017-12-26  发布于拉勾网职位诱惑：
互联网,长期,稳定,高薪
职位描述：
职位介绍
工作职责： 
1、负责海量数据处理分布式平台以及大数据分析系统架构设计和研发
2、制定项目设计及实现规范，指导设计、开发及部署工作；     3、带领、协助指导工程师解决关键问题； 
4、 设计开发关键功能模块。
 任职资格： 
1、5以上软件研发、分布式系统研发经验，3年以上互联网核心数据系统设计架构经验； 
2、精通Hadoop、HBase，Spark，storm，Redis等大数据相关技术及分布式工具， 具有高扩展性、高性能和分布式系统的实践经验 ，具有大数据以及高并发的系统数据库开发经验，能够应对海量数据的存储，处理和分析需求。 
3、掌握高性能、高并发服务设计的基本方法和实现 
4、具备对未来移动互联网业务以及技术的敏感性，并能主动推进未来相关技术较强的逻辑思维、沟通技巧，有大项目架构设计经验优先 
5、有大数据分析, 算法, 可视化方面经验尤佳.   
工作地址
深圳 - 龙岗区 - 坂田 - 坂田街道新天下集团
查看地图
职位发布者:
B
B-25663
招聘专员
聊天意愿
弱
回复率17%  用时1分钟
简历处理
暂无
处理率--  用时--天
活跃时段
早上
早9点最活跃
-------------------------------------------------
转转数据平台部招聘
Hadoop 大数据架构师
30k-60k /北京 / 经验5-10年 / 本科及以上 / 全职
架构师
spark
hadoop
二次开发
大数据
10:35  发布于拉勾网职位诱惑：
六险一金,核心部门,季度奖,年终奖
职位描述：
岗位要求： 
1、计算机或相关专业本科以上学历，3年以上hadoop生态开发/运维工作经验。 
2、精通Java/Scala程序开发(至少一种)，熟悉Linux/Unix开发环境。 
3、基于Hadoop的大数据体系有深入认识，具备相关产品（Hadoop、Hive、HBase、Spark、Storm、 Flume、Kafka、ES等）项目应用研发经验，有Hadoop集群搭建和管理经验，读过hadoop/spark源码，有 Patch 或二次开发经验优先。
4、算法基础扎实，熟悉常见的数据结构，深入理解分布式算法和以上提到的分布式系统，必须具有一线coding的能力。
5、具有扎实的大数据和数据仓库的理论功底，负责过大数据平台或数据仓库设计。

工作职责： 
1、负责公司大数据底层框架的整体架构设计，结合公司实际业务情况进行技术选型及大数据战略规划；
2、负责统一数据平台项目的整体评估、设计、架构及关键模块的开发与优化，协助团队解决开发过程中的技术难题； 
3、负责新技术的调研，并能在团队内进行推广应用； 
4、参与数据平台开发规范制定，数据建模及核心框架开发；
5、负责对 hadoop 相关组件优化、二次开发、Patch Merge、Bug Fix，保障集群高可用、高性能。

★★★★★ 部门负责人直招，最快可以半天面完所有流程。
★★★★★ 欢迎各位同学自荐或者推荐加入转转，简历符合要求第一时间通知面试。  
工作地址
北京 - 海淀区 - 西三旗 - 西小口路东升科技园
查看地图
职位发布者:
Lee
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
超快
处理率100%  用时1天
活跃时段
早上
早10点最活跃
-------------------------------------------------
平安银行零售大数据招聘
高级/资深Hadoop工程师
25k-40k /深圳 / 经验5-10年 / 本科及以上 / 全职
hadoop
spark
hive
2天前  发布于拉勾网职位诱惑：
扁平管理 福利优厚
职位描述：
职责描述:
1.负责Hadoop集群相关的开发、调优、监控等工作
2.负责Cassandra、Spark、Hive项目开发、实施工作
3.负责数据平台的基础架构设计和优化工作
  职位要求:
1.3年以上大数据基础架构相关工作经验
2.深刻理解Hadoop、Hive、Hbase、Spark等开源软件的工作原理
3.熟练掌握Java开发，有开源软件源码阅读和fix经验者优先
4.技术Geek,对技术有很高的热情
5.有大规模Hadoop集群运维经验者优先
6.具有快速解决问题的能力和较强的学习能力
7.熟悉linux系统
8.附上github地址或blog地址有加分
工作地址
深圳 - 罗湖区 - 深圳市罗湖区深南大道5047号平安银行大厦
查看地图
职位发布者:
平
平安银行
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
一般
处理率37%  用时3天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
江苏亿科达15招聘
hadoop spark工程师
10K-20K /深圳 / 经验1-3年 / 大专及以上 / 全职
高级
中级
BI
金融
ETL
数据挖掘
2018-01-18  发布于拉勾网职位诱惑：
团队强,项目好,待遇优,环境棒
职位描述：
岗位要求：
1、1年以上hadoop的应用开发经验
2、至少一个企业级数据仓库项目开发经验或者大数据处理项目经验；
3、 良好的编程习惯和开发能力，熟悉Java或python等开发语言，
4、熟悉常用开源分布式系统，Hadoop/Hive/Spark/Yarn，
5、1年以上mysql, oracle等数据库经验，具备优秀的SQL编写和调优能力；
6、有金融行业经验优先考虑
工作地址
深圳 - 福田区 - - 购物公园
查看地图
职位发布者:
袁满军
主管
聊天意愿
一般
回复率53%  用时23分钟
简历处理
超快
处理率100%  用时1天
活跃时段
晚上
晚上10点最活跃
-------------------------------------------------
爱奇艺大数据招聘
Hadoop大数据处理
25k-50k /北京 / 经验不限 / 本科及以上 / 全职
数据
hadoop
大数据
数据挖掘
15:51  发布于拉勾网职位诱惑：
大数据开发 hadoop开发 spark开发 hive计算
职位描述：
岗位职责：
1） 负责爱奇艺垂线业务的基础数据体系建设
2） 爱奇艺垂线业务部门的数据支持，为业务部门提供数据解决方案，用数据和技术为业务的发展提供更好的支撑。

职位要求：
 1） 计算机相关专业或者数理统计相关专业，两年以上大数据开发经验
 2） 熟悉 Linux下开发环境，具有一定的java 或者python开发能力
 3） 精通hadoop生态圈的相关技术，熟悉Spark优先，有机器学习能力、熟悉算法尤佳
 4） 较为丰富的数据仓库建模经验，有海量数据场景下的开发经验，有一定的产品思维能力。 
5）思维敏捷，有较强的钻研学习能力,良好的沟通能力，较强的学习能力。
工作地址
北京 - 海淀区 - 中关村 - 海淀北一街2号爱奇艺创新大厦5层
查看地图
职位发布者:
Z
zhaocho...
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
全天
晚上0点最活跃
-------------------------------------------------
今日头条招聘
Hadoop 运维工程师
22k-44k /北京 / 经验1-3年 / 本科及以上 / 全职
后端开发
2018-01-17  发布于拉勾网职位诱惑：
六险一金，免费三餐，租房补贴
职位描述：
职位职责：
1、负责存储 & 计算相关基础设施的容量规划、管理、审计和 trouble shooting，解决实际业务问题
2、千台-万台规模 HDFS/YARN 系统维护的自动化

职位要求：
1、思维活跃，熟悉 Hadoop 技术栈及相关基础设施
2、优秀的设计和编码能力：擅长抽象，针对具体的业务场景问题，快速设计和实现解决方案
工作地址
北京 - 海淀区 - 双榆树 - 北京市海淀区北三环西路43号中航广场
查看地图
职位发布者:
J
jo
职位发布者
聊天意愿
很弱
回复率--  用时1小时
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午5点最活跃
-------------------------------------------------
广州市云润大数据研发部招聘
Hadoop大数据研发工程师
8k-16k /广州 / 经验1-3年 / 大专及以上 / 全职
高级
MySQL
solr
spark
hadoop
hbase
2天前  发布于拉勾网职位诱惑：
五险一金,周末双休,带薪年假,岗位晋升
职位描述：
岗位职责：
1.负责Hadoop的搭建和维护；
2.负责数据表结构的优化；
3.协助技术总监进行高并发和高可用(HA)架构的测试和优化。
岗位要求：
1.熟悉Hadoop及相关组件；
2.熟悉SQL语法；
3.有Solr开发经验者优先。

晋升空间：
小组长、副组长、组长、技术主管、技术总监、架构师、CTO

调岗空间：
AI工程师、数据挖掘工程师、数据分析师
产品助理、产品经理、产品总监
运营助理、运营经理、运营总监
技术助理、需求分析师、解决方案工程师
工作地址
广州 - 天河区 - 棠东东路御富科贸园C3座308室
查看地图
职位发布者:
李
李经理
技术总监
聊天意愿
很弱
回复率--  用时1分钟
简历处理
超快
处理率100%  用时1天
活跃时段
早上
早11点最活跃
-------------------------------------------------
世纪互联世纪互联招聘
分布式（Hadoop）开发工程师
10k-15k /北京 / 经验1-3年 / 本科及以上 / 全职
分布式
区块链
hadoop
算法
大数据
2017-12-28  发布于拉勾网职位诱惑：
五险一金
职位描述：
岗位职责：
1、智慧城市顶层设计、总体规划的撰写，有地方城市智慧城市顶层设计、总体规划经验优先
2、智慧城市总体解决方案、分技术领域解决方案的撰写，有相关智慧城市项目落地经验优先
3、协助参与智慧城市客户需求与市场机会的挖掘；
4、智慧城市相关标准的起草
5、协助项目需求方案的调研与撰写；
6、协助项目技术方案的撰写并在需要时参加具体的研发实施；
7、日常参与智慧城市方面的项目客户拜访、规划设计等具体事务；
8、智能城市实时大规模数据仓库建立, 实现信息抽取, 数据采集与挖掘, 海量信息处理, 用户行为分析, 建立基础用户空间模型,特征选择引擎开发, 合理推荐等
任职资格：
1、在读硕士及以上学历,电子工程或计算机等相关专业
2、善于学习新知识,善于沟通表达,有较强的分析问题和解决问题的能力
3、有志于在IT技术行业应用、系统集成、智慧领域发展；
4、具备技术实施方案的撰写与策划能力；
5、具有良好的沟通能力和团队合作能力；
6、能够适应不定期的中短途出差；
7、熟练掌握C/C++/Java/Python至少一种语言,熟悉Unix/Linux开发环境
8、精通Hadoop以及MapReduce,熟悉Hive,HBase,Storm等
9、有分布式机器学习经验, 熟悉大规模增量算法者优先
工作地址
北京 - 朝阳区 - 酒仙桥 - 酒仙桥东路1号M5楼
查看地图
职位发布者:
S
Sandy
HR
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午3点最活跃
-------------------------------------------------
晶赞科技Zamplus招聘
高级数据分析师（熟悉hadoop)
15k以上 /上海 / 经验1-3年 / 本科及以上 / 全职
数据
大数据
数据分析
分析师
09:21  发布于拉勾网职位诱惑：
弹性工作、国内外outing
职位描述：
【工作内容】
1、负责互联网业务和移动互联网业务的海量数据分析，包括数据汇总，分析、挖掘、总结规律；
2、协助广告投放部门优化投放算法；
3、协助销售部门针对各种统计分析类项目需求提供售前、售后的数据支持；
4、定期发布专题分析报告，为产品和运营提供决策支持；
5、负责与相关工作的人员做各类数据需求与对接，以业务分析推动产品的发展方向与改进思路。

【任职要求】
1、计算机、应用数学或统计学等相关专业本科及以上学历；
2、理智、逻辑性强，具有优秀的学习能力、独立分析和解决问题能力，具有强烈的责任心及工作积极性；
3、熟悉hadoop和hive，有map/reduce编程经验；
4、熟悉linux操作系统，熟悉python脚本编程；
5、参加过以下项目者优先：数据仓库、海量数据分析、数据挖掘、Mahout或SPSS相关项目。
工作地址
上海 - 闸北区 - 汶水路 - 灵石路695号珠江创业园区3号楼11楼
查看地图
职位发布者:
Zamplus...
HR
聊天意愿
暂无
回复率--  用时--
简历处理
快
处理率22%  用时1天
活跃时段
早上
早10点最活跃
-------------------------------------------------
Focusmedia集团战略部招聘
大数据开发工程师(Hadoop)
15k-30k /上海 / 经验3-5年 / 本科及以上 / 全职
硬件制造
数据分析
spark
hadoop
数据挖掘
大数据
2017-12-25  发布于拉勾网职位诱惑：
上市公司,大型项目,发展前景
职位描述：
职位职责：
1.负责基于Hadoop/Spark生态系统的大数据计算和挖掘研发；
2.负责基于Hadoop各种开发工具和框架实施数据采集、分析和报表；
3.大数据平台运行性能、可用性、扩展性等监控与优化调控；
4.Hadoop集群设计包括软硬件架构、节点配置、网络、存储和容量规划；
任职资格：
1、全日制统招本科以上学历，2年以上大数据开发经验。
2、掌握Java/Scala/Shell语言，能熟练进行Hadoop/spark/HBase/storm之上的开发；
3、具备以下2种以上工具的开发和实施经验：Java-MapReduce, Hive, PIG, Sqoop, Flume, Kafka ,HBASE, MangoDB, Redis, Spark, Storm；
4、熟悉MySQL等关系型数据库，掌握数据库应用开发。
工作地址
上海 - 长宁区 - 镇宁路 - 兆丰世贸大厦
查看地图
职位发布者:
Z
zouyueyun
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午2点最活跃
-------------------------------------------------
饿了么BDI大数据部招聘
资深Hadoop工程师／高级Had...
17k-34k /上海 / 经验3-5年 / 本科及以上 / 全职
专家
资深
spark
hadoop
大数据
redis
2017-12-26  发布于拉勾网职位诱惑：
大数据领域大神等你一起来玩耍
职位描述：
职责描述:
1.负责Hadoop集群相关的开发、调优、监控等工作
2.负责Cassandra、Spark、Hive项目开发、实施工作
3.负责数据平台的基础架构设计和优化工作
职位要求:
1.3年以上大数据基础架构相关工作经验
2.深刻理解Hadoop、Hive、Hbase、Spark等开源软件的工作原理
3.熟练掌握Java开发，有开源软件源码阅读和fix经验者优先
4.技术Geek,对技术有很高的热情
5.有大规模Hadoop集群运维经验者优先
6.具有快速解决问题的能力和较强的学习能力
7.熟悉linux系统
8.附上github地址或blog地址有加分
工作地址
上海 - 普陀区 - 长征 - 金沙江路1518弄近铁城市广场北座4楼401室
查看地图
职位发布者:
JOJO
HRBP
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
早上
早10点最活跃
-------------------------------------------------
盛世全景研发部招聘
Spark/Hadoop大数据软件工...
15k-30k /北京 / 经验3-5年 / 本科及以上 / 全职
数据分析
算法
spark
hadoop
数据挖掘
大数据
09:25  发布于拉勾网职位诱惑：
五险一金,年终奖,弹性上下班,节假日福利
职位描述：
岗位职责:
负责基于Spark的并行计算平台的开发与优化工作。

任职资格：
1、熟悉并行计算或者分布式计算，熟悉Spark框架,熟练掌握RDD编程；
2、熟悉Spark源码者优先；
3、熟悉ZooKeeper/kafka/Hadoop/HBase/Flume等平台者优先；
4、有深厚的操作系统，数据结构和算法基础；
5、2年以上软件开发经验，熟练掌握Java或Scala语言；
6、做事严谨踏实，责任心强，条理清楚，善于学习总结，有良好的团队合作精神和沟通协调能力。
工作地址
北京 - 海淀区 - 五道口 - 中关村东路18号财智国际大厦
查看地图
职位发布者:
hr
职位发布者
聊天意愿
很弱
回复率--  用时26分钟
简历处理
超快
处理率100%  用时1天
活跃时段
下午
下午5点最活跃
-------------------------------------------------
广东曼拓信息科技有限公司研发中心招聘
Hadoop平台设计师
15k-25k /广州 / 经验3-5年 / 学历不限 / 全职
Java
hadoop
大数据
2天前  发布于拉勾网职位诱惑：
TB级数据,亚秒级响应,背景硬,平台大
职位描述：
职责描述：
1、负责大数据基础平台的整体规划和架构设计，参与需求分析、建模、架构设计、技术决策以及详细设计；
2、优化、维护、升级现有大数据平台，解决系统中的关键问题和技术难题，不断提升系统的稳定性和效率，为公司的业务提供大数据底层平台的支持和保证；
3、设计并实现对BI分析、数据产品开发、算法开发的系统性支持；
4、持续挑战新的技术方向，攻克大数据量，高并发，高稳定性，易用性等各种技术难点


任职要求：
1、设计过日处理量达到TB级的平台架构；
2、5年以上数据开发经验，至少2年以上大数据架构经验；
3、熟练掌握大数据开发框架，Hadoop、Hive、HBase、Storm、Kafka等大数据主流工具和技术，熟悉常用分析、统计和建模方法，精通Linux操作系统和Shell编程；
4、熟练掌握至少一种内存数据库，如Redis、MongoDB等；
5、熟练掌握至少一种关系型数据库，如Oracle、Mysql等；
6、全面的计算机网络知识体系，熟悉与架构设计相关的数据存储与性能调优等相关领域知识，并能解决项目过程中遇到的技术难题；
7、具备独立进行需求调研及分析、系统分析设计的能力；
8、良好的沟通能力和逻辑思维能力，思维敏捷，同时具备较强的学习能力和文档能力，并能够在压力环境下工作。 
工作地址
广州 - 天河区 - 五山 - 五山路科华街251号乐天创意园A16001
查看地图
职位发布者:
李女士
职位发布者
聊天意愿
一般
回复率35%  用时17分钟
简历处理
暂无
处理率100%  用时--天
活跃时段
早上
早11点最活跃
-------------------------------------------------
中电启明星研发中心招聘
高级软件开发工程师—hadoo...
12k-20k /成都 / 经验3-5年 / 大专及以上 / 全职
高级
linux
系统架构
2017-12-25  发布于拉勾网职位诱惑：
五险一金,餐补,带薪年假
职位描述：
任职要求：
1、两年以上大数据相关系统开发实际工作经验，具有一定的系统架构设计能力，具备数据挖掘相关项目建设经验；
2、具备系统建设期间需求调研、需求分析、技术文档编写的能力；具备系统概要设计、详细设计、开发计划等文档的编制能力；
3、熟悉Hadoop、Hive、pig,Storm、Spark等技术框架;熟悉java、sql等相关技术；
4、熟练使用Hadoop、Hive、pig,Storm、Spark等进行大数据应用开发；
5、熟悉主流应用服务器，熟悉主流Linux操作系统，熟悉shell；
6、熟悉Linux系统运维，Hadoop、Hive、Hbase、Storm、Spark等大数据工具；
7、有规范的编程习惯与文档编写能力，积极配合公司各项规范化建设工作；
8、责任心强，工作踏实，团队协作精神，能适应严格项目管理。

福利待遇：
1、工作时间：周一至周五，朝九晚五点半，周末双休，国定节假日等按国家规定放假；
2、入职既按规定购买社保和公积金；
3、节假日享有各类节假日福利；
4、年底根据公司经营情况及员工个人绩效享有年终奖金；
5、入职既享受各类假期（带薪年假、带薪探亲假等）；
6、定期组织进行职业资格认证考试培训，取得相关证书后给予对应的职称奖励；
7、公司具有完善的制度管理体系及人员培养培训体系，薪酬采用宽幅薪酬政策，依照能力定岗定薪，薪酬水平具有较强的竞争力。
  天高任鸟飞，海阔凭鱼跃，因为有你，启明星这个大家庭会更加精彩！
工作地址
成都 - 高新区 - 华阳 - 益州大道中段1800号天府软件园G区3栋10楼
查看地图
职位发布者:
星小招
HR
聊天意愿
一般
回复率43%  用时7分钟
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
佰安信息运维部招聘
hadoop运维
25K-40K /杭州 / 经验5-10年 / 学历不限 / 全职
高级
运维
2018-01-20  发布于拉勾网职位诱惑：
弹性工作
职位描述：
1、基于Hadoop、Hbase、Spark调优工作； 
3、负责Hadoop集群的优化、维护； 
岗位要求： 
1、专科以上计算机相关专业学历，3年以上Hadoop维护经验； 
2、熟悉Hadoop、Storm、Spark、Hbase等分布式框架； 
3、精通CDH5的部署及管理； 
4、熟悉Linux常用命令；
工作地址
杭州 - 拱墅区 - 和睦 - 莫干山路678号
查看地图
职位发布者:
郭长丰
技术
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
晚上
晚上10点最活跃
-------------------------------------------------
宜信数据组招聘
Java开发工程师（Hadoop）
17k-27k /北京 / 经验3-5年 / 本科及以上 / 全职
高级
中级
Java
大数据
MySQL
金融
2018-01-17  发布于拉勾网职位诱惑：
六险一金,紧邻地铁,核心团队
职位描述：
岗位职责：
1、参与数据平台建设，以及基于数据平台提供便捷的工具系统（如任务调度、数据采集）供公司内部使用。
2、负责核心模块的设计、编码、单元测试、后期迭代、维护升级。
任职要求：
1、熟练掌握java语言，多线程、IO、java集合类的使用。
2、熟练掌握spring、ibatis等主流开框架，有独立搭建项目骨架，以及框架之间集成的能力。
3、熟悉消息通信常用的RPC框架，thrift，protobuf，对java NIO有一定的原理性的了解。
4、熟悉常用的java设计模式，并能再不过度使用的情况下，是代码架构简洁清晰并有可扩展性。
5、熟练使用maven或gradle，git等工具。
6、熟练使用Mysql数据库，对sql优化有一定的了解，对分库分表的开源组件有一定的了解，并有针对业务系统设计数据库结构关系的能力。
7、熟练使用linux系统，对Linux基本的命令熟练使用，可以独立部署应用。
8、由于是数据平台工具系统研发，需要对Hadoop、Hive、Hbase、Spark有一定的了解，熟练掌握会很有加分项。

工作地址
北京 - 朝阳区 - 大望路 - 西大望路1号温特莱中心A座
查看地图
职位发布者:
benyanxin
职位发布者
聊天意愿
弱
回复率11%  用时47分钟
简历处理
快
处理率10%  用时1天
活跃时段
下午
下午2点最活跃
-------------------------------------------------
明泽陆通运维招聘
Hadoop运维工程师
8k-15k /北京 / 经验1-3年 / 本科及以上 / 全职
hadoop
linux
运维
大数据
2018-01-05  发布于拉勾网职位诱惑：
运维
职位描述：
1.负责公司大数据业务集群的运维工作（Hadoop/Hbase/Hive/Presto/Yarn/Spark/Storm/Kafka/Elasticsearch/Flume等）确保高可用
2.负责集群容量规划、扩容及性能优化；
3.设计实现大规模分布式集群的运维、监控和管理平台；
4.深入研究大数据业务相关运维技术，持续优化集群服务架构，探索新的大数据运维技及发展方向。
  任职要求：
1.至少掌握java/python/shell中的一种语言。
2.熟悉Linux操作系统的配置、管理及优化，能够独立排查及解决操作系统层面的问题；
3.掌握puppet、kerberos应用的优先；
4.熟悉Hadoop/Hbase/Hive/Storm/Spark/Kafka/Elasticsearch/Flume等开源项目优先；
5.良好的客户服务意识，强烈的责任心和使命感，执行力强，富有团队合作精神；
6.对大数据方向运维有很高的热情和兴趣
工作地址
北京 - 海淀区 - 中关村 - 海淀区科学院南路2号院3号楼
查看地图
职位发布者:
陈
陈
职位发布者
聊天意愿
弱
回复率17%  用时1小时
简历处理
暂无
处理率--  用时--天
活跃时段
早上
早9点最活跃
-------------------------------------------------
江苏亿科达14招聘
hadoop spark 开发工程师
10k-20k /深圳 / 经验3-5年 / 大专及以上 / 全职
高级
中级
BI
金融
ETL
数据挖掘
1天前  发布于拉勾网职位诱惑：
牛人团队,项目好,工作环境好,带薪年假
职位描述：
岗位要求：
1、3年以上hadoop的应用开发经验
2、至少一个企业级数据仓库项目开发经验或者大数据处理项目经验；
3、 良好的编程习惯和开发能力，熟悉Java等开发语言，
4、熟悉常用开源分布式系统，Hadoop/Hive/Spark/Yarn，
5、3年以上mysql, oracle等数据库经验，具备优秀的SQL编写和调优能力；
6、有金融行业经验优先考虑
工作地址
深圳 - 南山区 - 前海 - 购物公园平安大厦
查看地图
职位发布者:
张
张丹
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
超快
处理率100%  用时1天
活跃时段
全天
下午2点最活跃
-------------------------------------------------
悠易技术部招聘
高级大数据开发工程师 Had...
20k-35k /北京 / 经验3-5年 / 本科及以上 / 全职
广告营销
数据仓库
BI
spark
hive
大数据
10:19  发布于拉勾网职位诱惑：
行业领军,大牛任导师,海外年会,全员持股
职位描述：
高级数据工程师
岗位描述：
1、参与基于hadoop的数据计算平台建设，支持精准广告投放所需的大规模数据计算需求
2、大数据应用相关解决方案的设计，以及相关软件应用技术疑难问题的研究工作
3、基于DMP平台，处理每日T级以上的大数据分析
4、针对具体业务数据进行数据的离线计算或实时计算

岗位要求：
1、计算机相关专业，本科及以上学历，3年以上Hadoop相关开发/维护经验；
2、熟悉Hadoop/HBase/Spark/hive生态系统的搭建和管理，掌握相关项目的原理和使用方法；
3、掌握数据分析的基本流程，擅长数据采集、清洗、分析等环节；
4、具有较强的业务理解能力，并能快速应用于数据分析各阶段；
5、善于发现系统的性能瓶颈、设计缺陷，提出改进方案并进行实施；
6、思路敏捷清晰，良好的表达和理解能力，良好的学习能力，强烈的创新意识；
7、有互联网广告行业工作经历者优先考虑

公司简介：
悠易互通，中国互联网广告行业跨屏程序化购买引领者，依托庞大的专有受众数据库和先进的广告技术，成为多屏融合及大数据营销时代最富创新精神、具营销实效的互联网广告公司。 悠易互通总部位于北京，在上海和广州均设有分公司。
2012年3月，悠易互通在中国推出支持实时竞价（RTB）购买为主的需求方平台（DSP），揭幕中国RTB时代；2013年，悠易互通首次程序化购买概念引入中国，开创国内广告技术新一轮创新与发展；2014年1月，悠易互通推出首个真正意义上的受众数据管理平台，数据银行DataBank，帮助广告主利用大数据实现精准人群的一站式收集分析整理及应用。截止到2015年2月底，悠易跨屏程序化购买平台已对接15万以上媒体资源、6万以上移动APP，能够购买到的多屏广告资源每天已经超过100亿，同时，悠易互通已经成功为包括联合利华、奥迪、丰田、佳能、交通银行、海尔、联想、加多宝、中国移动、中国联通等超千家国内外知名企业，提供成功的品牌和效果解决方案。

北京总部办公地点
北京市朝阳区东三环中路1号环球金融中心东塔5层511室

工作地址
北京 - 朝阳区 - 国贸 - 东三环中路1号北京环球金融中心东塔5层511
查看地图
职位发布者:
悠
悠易互通HR
高级人力资源经理
聊天意愿
很弱
回复率--  用时2小时
简历处理
很慢
处理率14%  用时6天
活跃时段
下午
下午3点最活跃
-------------------------------------------------
图吧招聘
Hadoop大数据高级工程师
18k-25k /北京 / 经验3-5年 / 本科及以上 / 全职
架构师
数据
大数据
1天前  发布于拉勾网职位诱惑：
广阔的发平台，丰富的团体活动
职位描述：
【岗位职责】
1.         负责公司大数据平台搭建、功能设计、及核心模块的开发；
2.         参与公司内外部大数据项目的需求分析及数据建模、方案评估；
3.         对现有大数据架构进行分析，并给出优化建议；
4.         编写大数据技术方案及大数据平台设计开发规范；
5.         能够带领并指导大数据小组进行研发；
6.         相关数据源及应用，涉及车联网、导航、自动驾驶等；

【职位要求】

1.         计算机软件及相关专业，本科及以上学历；
2.         2年以上大数据处理经验；
3.         精通Java编程，具备扎实的数据结构与算法功底；
4.         熟悉hadoop技术体系，hive、pig、hbase、sqoop等开源项目；
5.         对hadoop底层原理及及实现有深入的理解，有实际hadoop集群搭建及维护经验；
6.         理解MapReduce计算框架的思想，熟悉分布式计算模型；
7.         熟练使用Kafka、Flume等开源数据收集工具；
8.         有互联网分布式大数据挖掘、分析、熟悉Mahout及分析算法优先；
9.         热爱大数据技术，主观能动性强，性格积极乐观，良好的沟通能力，工作认真、严谨，有团队精神；
工作地址
北京 - 东城区 - 东直门 - 东直门南大街6号中纺大厦8层（东直门东方花园饭店）
查看地图
职位发布者:
E
erin
HR
聊天意愿
一般
回复率33%  用时1小时
简历处理
一般
处理率100%  用时4天
活跃时段
下午
中午1点最活跃
-------------------------------------------------
涂鸦智能云端开发部招聘
大数据研发工程师（Hadoop/...
15k-25k /杭州 / 经验3-5年 / 本科及以上 / 全职
数据分析
spark
hadoop
大数据
2018-01-18  发布于拉勾网职位诱惑：
五险一金,行业前景好,氛围轻松,精英团队
职位描述：
岗位职责：
1、负责公司互联网数据ETL数据清洗工作；
2、负责在分布式离线/在线/实时计算平台上的设计和研发；
3、负责Hadoop平台数据仓库、数据集成、数据管理的整体架构设计工作。
4、负责服务器端的逻辑编写和优化。

职位要求：
1、有数据库/hive两年以上使用经验，参与过数据仓库的开发与维护工作，有独立建设和维护数据仓库经验者优先
2、熟练掌握Java 程序开发语言；
3、熟悉大数据处理平台 Hadoop、Hive、MR、Spark； 
4、了解缓存、队列等技术，熟悉 Redis、Kafka 等消息中间件；
5、熟悉scala语言,熟悉spark streaming 和spark sql
6、熟悉主流的云计算、大数据产品（hadoop、spark等）和数据分析技术（机器学习)并具有相关项目经验
工作地址
杭州 - 西湖区 - 古墩路 - 古墩路87号浙商财富中心3号楼7-8层
查看地图
职位发布者:
Rachel
HR
聊天意愿
很弱
回复率--  用时22分钟
简历处理
快
处理率20%  用时1天
活跃时段
晚上
晚上9点最活跃
-------------------------------------------------
京东商城AI与大数据部招聘
大数据架构师（Hadoop方向）
30k-60k /北京 / 经验5-10年 / 本科及以上 / 全职
hadoop
大数据
Java
架构
2018-01-16  发布于拉勾网职位诱惑：
福利待遇好,晋升空间大
职位描述：
岗位职责：
1、负责京东大规模HBase集群的高可用和稳定性建设
2、支持业务需求，深度参与业务系统的设计与实施，提供有前瞻性的技术解决方案
3、负责HBase系统二次开发、产品版本迭代、系统性能优化
4、规划平台&集群关键功能、架构的设计，把控平台的发展方向，建立良好的技术分享和提升机制
  任职要求：
1、本科或以上学历，专业不限，但需要有较强的学习能力、责任心强
2、五年以上使用Java语言开发的经验，熟悉IO、多线程、RPC等基础框架
3、熟悉Linux/Unix平台，熟悉bash、perl、python、php、ruby、nodejs中至少两种以上语言
4、熟悉Hadoop/HBase/Zookeeper等的运行机制和工作原理，有大规模数据分析和处理经验
5、能熟练的阅读英文论文与文档，熟练使用英文邮件沟通问题
6、精读过多个优秀开源软件源码，并对coding保持强烈兴趣
7、热爱探索和钻研，参与过开源软件开发或者给某个开源项目提过BUG者优先
工作地址
北京 - 朝阳区 - 大屯 - 北辰西路8号北辰世纪中心A座
查看地图
职位发布者:
张逸
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
快
处理率2%  用时1天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
凤凰金融大数据部招聘
Java工程师（hadoop方向）
20k-35k /北京 / 经验5-10年 / 本科及以上 / 全职
资深
高级
Java
hadoop
金融
spark
2018-01-15  发布于拉勾网职位诱惑：
七险一金 带薪假期 弹性工作 绩效奖金
职位描述：
职位描述：
1、参与大数据平台的规划和设计；
2、参与定义可扩展的、分布式的大数据架构；
3、完成各种面向业务目标的从数据模型、数据分布、数据传输、数据存储等方面进行大数据系统架构的设计和数据架构；
4、开发具有数据分析、数据挖掘能力的创新型产品
5、负责数据平台基础设施的维护、优化等工作；
6、与数据应用的同事交流，能同时从业务和技术的角度对平台进行完善。
7、跟踪大数据技术最新动向，研究基于大数据领域应用并结合项目需求提出金融行业相关解决方案。

任职资格：
1、本科及以上学历，计算机相关专业 ，5年以上工作经验，熟悉主流的大数据产品和数据分析技术并具有相关项目经验。
2、熟练掌握Java、Shell、Sql、Python、Scala编程,熟悉软件开发流程,熟悉主流开源应用框架，如Spring、myBatis、XML、JSON、Maven等开发技术，并且有mysql、nosql相关开发经验
3、熟练掌握Hadoop、MapReduce、HDFS、Hive、Hbase等开发经验
4、熟悉Spark/Storm，具有实时/准实时数据处理平台开发经验
5、熟悉 Flume、Kafka、Redis、ZooKeeper、Solr、elasticsearch等开源分布式产品的架构及使用 6、熟悉互联网日志采集和分析系统开发流程。
7、有数据分析、数据挖掘、数据可视化、在线数据、统计学习等等相关产品的开发经验 8、对新技术敏感，有一定独立分析，技术研究能力，有良好的逻辑分析能力、组织协调能力和团队精神；
9、有持续学习新知识的能力和意愿，善于沟通和逻辑表达，优秀的团队合作意识
工作地址
北京 - 朝阳区 - 来广营 - 朝来高科技产业园18号院18号楼
查看地图
职位发布者:
B
bing.hu
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
超快
处理率100%  用时2天
活跃时段
下午
下午3点最活跃
-------------------------------------------------
飞鱼科技飞鱼科技招聘
数据挖掘工程师（hadoop方向）
8k-16k /厦门 / 经验3-5年 / 大专及以上 / 全职
数据挖掘
2018-01-16  发布于拉勾网职位诱惑：
五险一金、商业保险、上市公司、保卫萝卜
职位描述：
岗位职责:
1. 基于游戏数据，深度分析数据中的规律，挖掘数据价值；
2. 参与数据/工具平台相关的功能接口、数据接口，实现业务功能（数据采集、清洗、落地等）；
3. 参与数据平台/工具平台的架构、设计以及实现；
4. 探索并归纳游戏数据及指标，为优化产品的设计提供支持。
任职资格:
1. 熟悉linux平台下的代码开发，至少精通一门编程语言Java/Python，多种为佳，对数据结构和算法设计有深刻理解；
2. 熟悉分布式架构，精通Hadoop、HBase等大数据开发，对hadoop/hive、MapReduce编程或Spark编程有一定的了解；
3. 精通主流关系型数据库MySQL与NOSQL REDIS；
4. 能独立了解数据需求，并可以转化成系统结构设计及独立进行代码实现；
5. 三年以上互联网数据挖掘工作经验，有游戏行业背景优先；
6. 具有算法设计经验优先；
7. 热爱网络游戏，对游戏行业和游戏制作有一定了解者优先。
工作地址
厦门 - 思明区 - 软件园二期
查看地图
职位发布者:
HR
职位发布者
聊天意愿
很弱
回复率--  用时1分钟
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午3点最活跃
-------------------------------------------------
武汉佰钧成技术有限公司ISBG-BU2招聘
JAVA…HADOOP
12K-15K /佛山 / 经验3-5年 / 大专及以上 / 全职
中级
2天前  发布于拉勾网职位诱惑：
大数据项目
职位描述：
资源需求：JAVA中级
1、 熟悉java,python语言。
2、 熟悉elasticsearch，掌握hadoop，spark，熟练hive，hbase，storm等大数据生态圈的组件。
3、 熟悉爬虫，有实际项目更佳。
4、 熟悉数据库基础知识，熟练Oracle、MySQL，MSSQL数据库操作。
5、 掌握spring，springmvc，mybatis框架使用，了解html，javascript，jsp，css；
6、 熟悉linux系统，熟悉常用命令和环境配置；
7、 熟悉数据结构和常见算法。
工作地址
佛山 - 顺德区 - - 北窖镇美的总部大楼
查看地图
职位发布者:
魏小姐
HR
聊天意愿
强
回复率75%  用时38分钟
简历处理
暂无
处理率--  用时--天
活跃时段
早上
早9点最活跃
-------------------------------------------------
数力网络研发部招聘
Hadoop后端工程师（大数据...
10k-20k /杭州 / 经验1-3年 / 本科及以上 / 全职
后端开发
spark
hadoop
大数据
1天前  发布于拉勾网职位诱惑：
旅游,团建,聚餐
职位描述：
职位职责：
1. 负责公司大数据统计业务的方案设计、搭建和研发，保证实时数据的实行性和离线数据的准确性，完善相关规范培养相应的维护人员；
2. 负责应对海量数据的处理，攻克高并发、高吞吐、高可用性、高可靠性等技术问题；

任职要求：
1. 二年以上大数据开发工作经验，计算机、数学或相关专业本科及以上学历；
2. 熟悉Hadoop、Spark等大数据框架，有大型分布式计算开发、部署等相关经验优先，熟悉阿里云大数据相关服务；
3. 有扎实的Java开发基础，熟悉JAVA平台多种常用框架；
4. 熟悉Linux操作系统和开发环境；
5. 熟悉常见网络协议、数据结构和算法；
6. 了解数据挖掘、机器学习的概念和算法；
7. 能迅速将业务需求转化为实际代码的产出；

其它要求：
1. 对业务领域内的新技术或新的技术趋势及时掌握,善于研究前沿技术和处理技术困难，有较强的创新意识
2. 善于学习，进取心强烈，具有独立分析、解决问题的能力
3. 对新技术敏感，有一定独立分析，技术研究能力，具有良好的团队合作精神。
工作地址
杭州 - 西湖区 - 西溪 - 西溪首座5号楼
查看地图
职位发布者:
数力网络
HR
聊天意愿
一般
回复率33%  用时3分钟
简历处理
超快
处理率100%  用时1天
活跃时段
下午
中午1点最活跃
-------------------------------------------------
新浪微博招聘
搜索平台引擎Hadoop专家
20k-35k /北京 / 经验3-5年 / 本科及以上 / 全职
Java
分布式
hadoop
python
C/C++
云计算
2018-01-15  发布于拉勾网职位诱惑：
弹性工作，定期体检，大平台，健身和班车
职位描述：

工作职责：
  1、负责后台系统研发，分布式调度平台设计开发
2、hadoop集群应用开发与维护
3、搜索离线计算框架应用开发与维护
  职位要求：
1、良好的沟通与表达能力、思路清晰，较强的动手能力与逻辑分析能力
2、2+年后端系统研发经验或者基础架构开发经验，熟练掌握 C/C++或 Java 等至少一种主流语言，熟悉一种以上脚本语言，如Shell、Python等，具备扎实的算法和数据结构功底
3、参与过高并发分布式在线系统的研发，解决过相关性能问题
4、精通 NoSQL 数据库技术和内存数据库技术（如 redis, leveldb）
5、扎实的编程能力，熟悉算法和数据结构，熟悉计算机基础理论，熟悉分布式系统原理，有熟悉hadoop/hive/hbase/spark/kafka/redis等经验优先
工作地址
北京 - 海淀区 - 马连洼 - 西北旺东路10号院西区8号楼新浪总部大厦
查看地图
职位发布者:
李腾
微博研发中心HRBP
聊天意愿
很弱
回复率--  用时1分钟
简历处理
快
处理率23%  用时2天
活跃时段
下午
下午2点最活跃
-------------------------------------------------
慧与产业基地研究院招聘
Hadoop架构师
30k-60k /北京 / 经验3-5年 / 硕士及以上 / 全职
hadoop
linux
大数据
docker
2018-01-09  发布于拉勾网职位诱惑：
架构师,数据开发,前沿技术,高精尖团队
职位描述：
1)负责基于Hadoop/Hbase/Spark生态的大数据离线/实时处理平台的容量规划、部署、及扩容；
2)负责平台各组件服务的监控、故障处理及性能调优；
3)负责平台的用户管理、权限分配、资源分配；
4)负责平台环境的运维和优化工作, 集群性能和资源利用率优化、集群常见问题能迅速定位，并不断优化，提升集群性能；
5)负责整体提升平台的高可用性、高性能、高扩展特性；
6)负责撰写相关技术文档并为开发人员提供支持。
  任职要求
1)计算机相关专业本科或研究生毕业，三年以上相关工作经历；
2)3年以上Hadoop实施经验，具备系统优化与性能调优能力；
3)熟练掌握Linux操作系统，熟悉linux文件系统，内核，网络等性能优化；
4)精通YARN、ZooKeeper、HBase、Spark、Kafka、Storm、Flink、ES等开源生态技术的体系结构和运行原理，对社区有贡献者优先；
5)熟练掌握Hadoop的MapReduce应用开发
6)掌握Java编程，熟悉一门以上脚本语言（Shell、Python、Perl）；
7)熟练掌握至少一种主流Hadoop版本的安装部署、性能监控；
8)具备良好的沟通能力和团队合作精神，具备较强的学习能力并善于独立解决问题。
工作地址
北京 - 朝阳区 - 光顺北大街望京福码大厦A座1501-1
查看地图
职位发布者:
慧与产业基地
招聘主管
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
全天
早11点最活跃
-------------------------------------------------
挚极科技技术开发招聘
大数据工程师(Hadoop、spar...
18k-25k /上海 / 经验1-3年 / 本科及以上 / 全职
中级
数据分析
spark
hadoop
数据挖掘
大数据
08:37  发布于拉勾网职位诱惑：
补充公积金,通讯补贴,丰盛早午餐,免费班车
职位描述：
岗位描述
1、参与平台的整体数据架构设计，完成从业务模型到数据模型的设计工作 ；
2、对数据挖掘及业务开发团队提供技术支持，协助方案规划；
3、负责技术攻关和创新技术引用，开发具有数据分析、数据挖掘能力的创新型产品；
4、负责公司的大数据平台的研发工作（包扩日志采集，离线计算，数据仓库存储和处理等）；
5、负责提升基于Hbase、kudu数据存储集群的高可用性、高性能、高扩展特性；
6、负责设计和建立基于Storm或Spark或flink的实时数据处理框架；
7、研究Hadoop/Spark/Hbase/Hive/flink等开源项目，对线上任务进行调优，并开发通用组件；
8、维持线上服务高效稳定，支撑业务和数据量的快速扩张。
    岗位要求
1、扎实的Java、Scala语言基础，对JVM运行机制有深入了解；
2、熟悉Hadoop、Spark并有丰富的开发经验；
3、熟练使用java语言，并掌握spring、mybatis等开源J2EE框架。使用java、scala、python等开发语言中的一种，有python和scala实际使用经验更佳；
4、有hadoop和spark实际开发经验。了解大数据组件的使用限制和应用场景，如hdfs,yarn,hbase,hive,flume,kafka,zk,impala,kylin,kudu,ES,Storm、MongoDB等。读过spark源码更佳；
5、熟悉mysql、ElasticSearch、Redis等关系型或NoSQL数据库，了解应用场景和使用限制。有实际调优经验者更佳。
6、熟悉linux常用命令，有实际CDH或HDP或apache版本的hadoop部署经验者优先；
7、熟悉并行计算或者分布式计算，熟悉Spark框架,熟练掌握RDD，SQL, Streaming, MLLIB，SparkR编程；
8、英文文档阅读无障碍、熟练掌握常用设计模式、熟练使用maven、git；
9、有深入研究过Hadoop/Spark源码者优先；
10、深入理解MapReduce工作原理，HDFS分布式文件系统架构；熟练掌握Hadoop/Hive/HBASE的运维和调优方法；
11、掌握或使用过Storm、Spark、flume、kafka等工具；
12、1年以上大数据相关工作经验，最好参与并成功部署过1个日均TB级的集群项目。
工作地址
上海 - 嘉定区 - 安亭 - 安亭镇墨玉南路888号16楼
查看地图
职位发布者:
T
Tao
人事
聊天意愿
暂无
回复率--  用时--
简历处理
一般
处理率11%  用时3天
活跃时段
全天
晚上9点最活跃
-------------------------------------------------
智达交通科技ITS事业部招聘
大数据开发工程师（Hadoop、...
15k-25k /北京 / 经验5-10年 / 本科及以上 / 全职
后端开发
python
大数据
Java
地图
2017-12-25  发布于拉勾网职位诱惑：
技术大牛多,股权激励,平台优质,大型项目
职位描述：
岗位职责：
1.维护公司自有大数据平台（Storm、CDH）；
2.研发、维护基于Storm的流式计算程序；
3.研发、维护基于MapReduce的批量计算程序；
4.研发、维护基于Kafka、HBase的地图动态展示。
任职要求：
1.计算机、智能交通与信息系统工程相关专业，硕士及以上学历；
2.熟练掌握Java语言，对分布式有深刻理解；
3.熟悉Hadoop或Storm等分布式开源项目及其工作原理，并有实际开发经验；
4.对于相应服务的优化有实际处理经验。了解HDFS、MapReduce、HBase、Hive的基本原理；
5.掌握Hadoop或Storm环境的部署，能在离线环境下完成大数据环境配置；
6.熟悉常用脚本语言Shell或Python等；
7.熟悉Flume、Kafka或RabbitMQ等消息队列；
8.对于业务需求，能够合理选型，提供架构支持与实现；
9.良好的Trouble shooting能力，能够独立解决问题，综合思考；
10.良好的代码编写习惯和文档能力，并能熟练使用Git或SVN进行版本控制；
11.工作认真负责，自律性好，求知欲强，有较强的自学能力；
12.善于沟通表达，有良好的团队合作精神。
工作地址
北京 - 丰台区 - 丽泽桥 - 六里桥首发大厦C座6层
查看地图
职位发布者:
Z
zhuly
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率50%  用时--天
活跃时段
早上
早11点最活跃
-------------------------------------------------
数云大客户事业部招聘
数据挖掘算法工程师(hadoo...
20k-30k /上海 / 经验3-5年 / 本科及以上 / 全职
广告营销
数据
算法
大数据
数据挖掘
电商
11:00  发布于拉勾网职位诱惑：
十天带薪年假，商业保险，福利体检。
职位描述：
岗位职责：
1. 负责对公司拥有的电商行业消费者大量数据进行数据挖掘和建模工作
2. 负责公司个性化推荐系统算法的开发工作
3. 负责公司精确营销系统中客户模型和客户标签的算法开发工作
4. 对分布式海量数据挖掘算法的研究及开发（hadoop、Spark等）

岗位要求：
1. 重点大学计算机、统计、数学等相关专业，硕士以上学历，3年以上工作经验
2. 算法基础扎实，熟悉数据挖掘、机器学习常见算法
3. 有linux下的开发和工作经验，精通Python、R、MATLAB、SAS等任意一中或者多种数据编程语言
4. 有Java开发经验者优先
5. 有分布式计算开发经验、熟悉hadoop原理优先
6. 有精准广告、推荐系统、精确营销等领域工作经验者尤佳。
7. 对数据挖掘事业极其热爱，工作积极投入
工作地址
上海 - 徐汇区 - 龙华 - 天钥桥路1000号徐汇苑商务楼5楼
查看地图
职位发布者:
周丽雯
人事专员
聊天意愿
很弱
回复率--  用时9分钟
简历处理
超快
处理率100%  用时1天
活跃时段
下午
下午3点最活跃
-------------------------------------------------
东方国信大数据中心招聘
高级JAVA开发工程师(Hadoo...
8k-16k /北京 / 经验1-3年 / 本科及以上 / 全职
Java
hadoop
大数据
中级
2018-01-12  发布于拉勾网职位诱惑：
地铁周边，股票期权，千节点集群，PB级数据
职位描述：
工作内容:
1、东方国信大数据企业版研发，详见http://beh.pezy.cn/
2、项目组大数据解决方案技术支持。
3、产品详情
东方国信大数据企业版（BONC Enterprise Hadoop），简称BEH，
包含了现阶段成熟的大数据处理技术组件，以及东方国信自己开发的相关应用和组件，
能为客户提供包含数据存储、资源调度、ETL作业引擎、Hadoop作业调度、开放作业管理、元数据管理和NoSQL数据储存及查询等相关技术和实现。
使用BEH可以帮助企业快速的搭建大数据平台，处理大数据问题，找到挖掘数据价值的方法，变现数据价值，同时帮助企业减少开发和后期维护成本。 

岗位要求:
0.统招一本以上学历。
1.精通Java语言及面向对象方法，熟悉J2EE体系，软件知识结构全面，基础扎实，精通常用数据结构、算法与设计模式；
2.精通HTML、JSP、Javascript、Ajax、CSS、XML等技术；
3.熟悉MVC，熟练使用Springmvc、Ajax等相关开源框架进行项目开发；
4.熟悉Mysql、Oracle等数据库使用，；
5.熟悉Linux操作系统，能够编写脚本及配置相应Java运营环境，熟悉基于Linux平台和Java容器的负载均衡方案，熟悉数据共享、同步等的实现方案；
6.熟悉主流Web应用服务器JBoss、Tomcat、WebLogic、缓存服务器、优化配置与使用；
7.热爱软件开发，做事认真细致负责，解决问题能力强，沟通能力强，有团队合作精神。
8.大数据平台开发，具有大数据经验优先。
工作地址
北京 - 朝阳区 - 来广营 - 创达路东方国信大厦
查看地图
职位发布者:
田先生
BEH-MANAGER产品总监
聊天意愿
暂无
回复率--  用时--
简历处理
一般
处理率57%  用时3天
活跃时段
全天
早10点最活跃
-------------------------------------------------
京东商城京东大数据研发部招聘
大数据工程师（Spark/Hadoop）
30k-60k /北京 / 经验3-5年 / 本科及以上 / 全职
高级
架构师
spark
hadoop
软件开发
大数据
2018-01-16  发布于拉勾网职位诱惑：
技术导向,源码研发
职位描述：
任职要求:

1、计算机或相关专业本科以上学历（4年以上工作经验）

2、熟悉Java/Scala/C++程序开发(至少一种)，熟悉Linux/Unix开发环境，熟悉常用脚本语言shell,python等。

3、有Spark Streaming/Mllib应用开发经验、熟悉数据挖掘/机器学习等算法者优先；

4、熟悉常用开源分布式系统，熟悉Hadoop/Spark/Hive/Hbase之一源码、有调优经验者优先

5、善于分析和解决问题，比较强的学习和创新能力，有责任心。

6、良好的基础和逻辑思维能力，拥有独立开发功能的能力。



主要职责：

1.负责spark计算平台的算法优化和开发；

2.负责基于Spark技术的海量数据处理（EB级数据规模），分析和挖掘；

3.基于Spark构建业界领先的计算平台；深入源码内核改进优化项目

4. 研究业界最新的大数据技术，负责大数据运维工具、系统的设计与开发
工作地址
北京 - 朝阳区 - 亚运村 - 北辰西路8号北辰世纪中心A座
查看地图
职位发布者:
张逸
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
快
处理率2%  用时1天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
新浪微博视频招聘
大数据开发工程师（hadoop/...
18k-35k /北京 / 经验3-5年 / 本科及以上 / 全职
高级
hadoop
算法
大数据
数据挖掘
2017-12-25  发布于拉勾网职位诱惑：
核心,发展空间大
职位描述：
职位描述：
基于大规模推荐数据平台之上，针对业务场景需求的设计研发工作
负责推荐业务场景下日志的分析统计、数据仓库的设计搭建及ETL工作
负责实现推荐算法及离线数据流程的研发
       任职要求：
大学本科及以上学历，计算机相关专业或有相关职位经验
有良好的数学基础，了解机器学习常用算法，具备自然语言处理、特征分析等方面的基础知识
熟悉hadoop/hive/spark的体系结构，原理和特性。对hadoop生态系统有一定的了解
熟悉java，有丰富的并发编程经验。可以熟练使用python/shell等脚本语言，熟悉linux操作系统
熟悉mysql/redis/memcached/mongo
有海量数据的分析能力和处理优化过程的经验
有大型分布式系统（计算/存储）的开发/运维优先
有推荐、广告、搜索等相关领域工作经验优先
有深度学习或大规模数据挖掘相关经验者优先
热爱技术，自我驱动，主动思考，有很好的技术敏感度、风险识别能力和全局意识 
有不断钻研和探索的精神，敢于挑战自我，有解决疑难问题的毅力和决心
责任心强，良好的沟通能力和团队协作精神

工作地址
北京 - 海淀区 - 上地 - 中关村软件园二区新浪总部大厦
查看地图
职位发布者:
微
微博招聘机器人
招聘
聊天意愿
暂无
回复率--  用时--
简历处理
超快
处理率100%  用时1天
活跃时段
下午
下午2点最活跃
-------------------------------------------------
际慧信息技术中心招聘
知名公司找大数据专家Hado...
20k-35k /杭州 / 经验5-10年 / 本科及以上 / 全职
专家
hadoop
spark
大数据
Java
2018-01-15  发布于拉勾网职位诱惑：
福利好,旅游,发展快,空间大
职位描述：
岗位职责：
1、 负责大数据平台的构建并主导技术调研的方向和路线；
2、 负责组建并带领团队成员开发和完善大数据基础平台和应用平台，编写核心代码，进行技术攻关；
3、 优化开发流程，控制开发进度，保证开发质量；
任职要求：
1、 计算机相关专业大学本科及以上学历，3年以上互联网行业大数据开发经验；
2、 精通Hadoop、Spark等大数据体系相关技术，对分布式系统原理，存储、队列、计算、集群管理中的一项或多项有深入的理解和认识；
3、 良好的沟通能力和逻辑思维能力，思维敏捷，可对业务需求进行抽象并据此进行架构设计；
4、 能够完全独立主导架构设计和数据库建模,至少熟悉一个关系型数据库（Oracle、Sql Server、MySql）以及相关的数据库调优技巧,同时了解运维相关的服务器、网络、存储等硬件知识；
工作地址
杭州 - 滨江区 - 长河 - 网商路
查看地图
职位发布者:
张琦
经理助理
聊天意愿
很弱
回复率--  用时22分钟
简历处理
暂无
处理率--  用时--天
活跃时段
早上
早9点最活跃
-------------------------------------------------
帜讯信息上海帜讯信息技术股份有限公司招聘
资深大数据工程师（Scala+H...
22k-40k /上海 / 经验5-10年 / 本科及以上 / 全职
软件开发
14:24  发布于拉勾网职位诱惑：
每年加薪/补充公积金/晋升通道/交通补贴
职位描述：
岗位职责:
职位描述：
1. 参与公司大数据产品规划,大数据处理分析平台的设计;
2. 负责数据分析、加工、清理、处理程序的开发;
3. 负责数据相关平台的搭建、维护和优化。
任职资格:
岗位要求：
1. 计算机相关专业本科学历以上；
2. 5+年以上相关大数据工作经验；
3. 熟悉Hadoop、Hbase、Hive、Spark集群搭建维护、优化及异常问题解决;
4. 能够发现系统性能瓶颈,并能对IO、网络通讯、任务调度调优;
5. 熟悉Java和Scala语言、熟悉常用设计模式、具有代码重构意识;
6. 使用Spark Streaming和Spark SQL进行数据处理, 并具有SPARK SQL优化经验;
7. 熟悉MySQL数据库性能优化方法, 了解常见NO-SQL数据库;
8. 有数据挖掘、数据分析、机器学习研发实践经验者优先。
工作地址
上海市 - 浦东新区 - 张江 - 浦东新区张江高科软件园博霞路50号402室
查看地图
职位发布者:
jiawei.dai
人力资源部
聊天意愿
暂无
回复率--  用时--
简历处理
快
处理率40%  用时1天
活跃时段
下午
下午5点最活跃
-------------------------------------------------
明略数据招聘
Hadoop（上海）
17k-25k /上海 / 经验3-5年 / 本科及以上 / 全职
大数据
1天前  发布于拉勾网职位诱惑：
六险一金，技术大咖等你来挑战
职位描述：
大数据研发工程师（senior）： 一名
工作职责：
1、负责大数据应用相关解决方案的设计，进行技术方案材料的撰写；
2、负责大数据应用相关产品的整体架构设计，进行大数据平台上数据挖掘产品的规划及研发；
3、完成各种面向业务目标的数据分析模型的定义和应用开发；
4、开发具有数据分析、数据挖掘能力的创新型产品； 
岗位要求：
1、计算机相关专业，本科及以上学历，3~4年以上Hadoop相关开发经验；
2、熟悉主流的云计算、大数据产品（hadoop、spark、flume等）和数据分析技术（机器学习)并具有相关项目经验；
3、精通算法设计/数据结构，精通JAVA或C/C++语言编程；
4、熟悉Linux/Unix平台上的开发环境；
5、思路敏捷清晰，良好的表达和理解能力，良好的学习能力，强烈的创新意识；
优先考虑：
1、具有百度、腾讯、阿里等知名互联网公司经验者优先
工作地址
- 龙之梦大厦
查看地图
职位发布者:
明略数据HR汪丽
大数据,数据挖掘
聊天意愿
很弱
回复率--  用时3分钟
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
明略数据项目部招聘
Hadoop
10k-20k /北京 / 经验3-5年 / 本科及以上 / 全职
大数据
1天前  发布于拉勾网职位诱惑：
待遇好,福利多,技术牛
职位描述：
1.本科以上学历
2.3年＋大数据开发经验。
3.熟悉Java语言，熟练使用SQL，熟练使用Linux，能熟练写Shell脚本，懂scala语言佳
4.熟悉Hadoop生态圈中的组件之一或者多种（flume, kafka, Hive, HBase, Spark, impala，storm，ES）【备注 Hive和Spark经验优先】
6.有志往大数据领域发展，学习欲强，学习能力强，主动性强，抗压能力强，团队协作意识强
工作地址
北京 - 朝阳区 - 立水桥 - 立水桥
查看地图
职位发布者:
明略数据HR汪丽
大数据,数据挖掘
聊天意愿
很弱
回复率--  用时3分钟
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
明略数据招聘
Hadoop
8k-12k /上海 / 经验1-3年 / 本科及以上 / 全职
大数据
1天前  发布于拉勾网职位诱惑：
六险一金，技术大咖等你来挑战
职位描述：
大数据研发工程师（senior）： 一名
工作职责：
1、负责大数据应用相关解决方案的设计，进行技术方案材料的撰写；
2、负责大数据应用相关产品的整体架构设计，进行大数据平台上数据挖掘产品的规划及研发；
3、完成各种面向业务目标的数据分析模型的定义和应用开发；
4、开发具有数据分析、数据挖掘能力的创新型产品； 
岗位要求：
1、计算机相关专业，本科及以上学历，2~3年以上Hadoop相关开发经验；
2、熟悉主流的云计算、大数据产品（hadoop、spark、flume等）和数据分析技术（机器学习)并具有相关项目经验；
3、精通算法设计/数据结构，精通JAVA或C/C++语言编程；
4、熟悉Linux/Unix平台上的开发环境；
5、思路敏捷清晰，良好的表达和理解能力，良好的学习能力，强烈的创新意识；
  工作地址
上海 - 浦东新区 - 张江 - 郭守敬路498号3号楼302
查看地图
职位发布者:
明略数据HR汪丽
大数据,数据挖掘
聊天意愿
很弱
回复率--  用时3分钟
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
明略数据招聘
Hadoop开发--平台组
15k-20k /北京 / 经验不限 / 本科及以上 / 全职
大数据
平台
1天前  发布于拉勾网职位诱惑：
五险一金
职位描述：
职位描述：
1. 参与大数据基础平台管理组件的设计与研发、测试等工作；
2. 负责相关模块的研发，保证系统性能、稳定和安全；
3. 参与Hadoop生态系统相关开源技术的使用、封装和增强等研发工作；
任职要求：
1.熟悉JAVA开发语言等相关技术和网络应用开发；
2.参与Hadoop生态中的zookeeper、hdfs、yarn、hbase、hive、impala、sqoop、spark、oozie、flume、kafka等开源组件的使用、封装和增强；
4.熟悉MySql、Postgresql至少一种数据库；
5.熟悉使用Linux；
6.熟悉Hadoop生态系统的优先考虑。
工作地址
北京 - 昌平区 - 东小口 - 东小口中煤大厦
查看地图
职位发布者:
明略数据HR汪丽
大数据,数据挖掘
聊天意愿
很弱
回复率--  用时3分钟
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
美团点评技术工程及基础数据平台招聘
【2018届校招补招：hadoop平...
14k-25k /北京 / 经验不限 / 本科及以上 / 全职
spark
hadoop
数据挖掘
机器学习
大数据
10:48  发布于拉勾网职位诱惑：
公司规模大,发展空间大
职位描述：
美团点评基础数据部的离线计算组
拥有国内顶级的hadoop集群规模与服务，主要负责Hadoop生态系统平台化的搭建，开发与维护服务，为美团点评所有的事业群，提供稳定的海量数据存储、计算、查询、数据分析平台，支撑起美团点评O2O和全渠道零售线上和线下大数据采集、整合、分析和应用。

团队同学技术水平很高，有多个hadoop开源项目的commiter与contributor; 主要突破事迹包括: 
1. 深度改造了hadoop底层架构, 支撑万节点集群常态跨机房运行
2. 维护的YARN版本性能做到了社区的100倍以上，并支持异构资源和环境的调度，同时支撑离线/实时/机器学习/深度学习/模型在线服务的混部
3. 有两名Apache Kylin PMC和一名Apache Kylin committer，向多个开源项目贡献超过100个patch，尤其向Apache Kylin社区贡献了独立HBase集群、精确去重计数、分布式构建与HA、构建性能优化等5项核心改进
4. 向Spark社区贡献了基于磁盘的Shuffle实现，Shuffle并发控制，推测执行算法优化等核心模块优化改造

一些公开资料:
美团大数据平台架构实践
Apache Kylin在美团点评的应用
美团点评数据平台融合实践
Spark在美团的实践

工作职责：
- Spark/Hive/MapReduce, Tensorflow/MXNet, Hdfs/HBase, Yarn, Kylin, Druid,Presto 等引擎性能改进、功能扩展、故障分析；
- 不断解决规模增长带来的技术和业务问题，构造高度稳定可用的大数据分布式系统, 支撑数据价值的持续交付.
- 构建与持续迭代符合公司数据开发新模式需要的计算平台能力. 如机器学习pipeline, 下一代BI分析能力.

要求：
1. 熟悉常用数据结构与算法，代码能力必须过关。
2. 熟练掌握Java/Python/C++，熟练应用其中两者优先。
3. 学习能力强，对新技术能快速上手。
4.对分布式计算平台有理解和一定的实践经验, 对于构建超大规模集群系统以及革新开源架构有浓厚的兴趣.

下面几项是加分项，有其中一项或者多项最佳：
1. 有上述分布式计算平台内核研究经验优先。
2. 熟悉常见的机器学习算法或者深度学习算法优先。
3. 有科研能力并有成果发表在国际顶级会议、期刊者优先。

该团队现面向2018届的有能力的小伙伴开展部门定向招聘（包括校招正式岗位和长期实习岗位）
工作地址
北京 - 朝阳区 - 望京 - 望京东路4号恒电大厦C座
查看地图
职位发布者:
杨慧
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午5点最活跃
-------------------------------------------------
平安银行零售大数据招聘
高级/资深Hadoop工程师
25k-40k /上海 / 经验3-5年 / 本科及以上 / 全职
hadoop
spark
hive
大数据
2天前  发布于拉勾网职位诱惑：
扁平管理 福利优厚
职位描述：
职责描述:
1.负责Hadoop集群相关的开发、调优、监控等工作
2.负责Cassandra、Spark、Hive项目开发、实施工作
3.负责数据平台的基础架构设计和优化工作
  职位要求:
1.3年以上大数据基础架构相关工作经验
2.深刻理解Hadoop、Hive、Hbase、Spark等开源软件的工作原理
3.熟练掌握Java开发，有开源软件源码阅读和fix经验者优先
4.技术Geek,对技术有很高的热情
5.有大规模Hadoop集群运维经验者优先
6.具有快速解决问题的能力和较强的学习能力
7.熟悉linux系统
8.附上github地址或blog地址有加分
工作地址
上海 - 浦东新区 - 陆家嘴 - 全华信息大厦
查看地图
职位发布者:
平
平安银行
职位发布者
聊天意愿
暂无
回复率--  用时--
简历处理
一般
处理率37%  用时3天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
明略数据技术部招聘
Hadoop大数据高级工程师（...
15k-25k /北京 / 经验不限 / 本科及以上 / 全职
数据
大数据
1天前  发布于拉勾网职位诱惑：
六险一金 超强技术团队
职位描述：
工作职责
1、基于Hadoop/Spark分布式集群的架构设计和开发。
2、解答用户提出的需求以及碰到问题时的解答。
任职资格
1、数学、统计学、人工智能、计算机相关专业，本科或以上学历。
2、至少熟练运用Java、Scala语言中的1种。
3、需要有Hadoop / Spark平台相关运维经验2年以上，有3年以上基于hadoop/Spark的实际项目开发经验。
4、熟练掌握linux常规命令与工具，至少熟练应用shell、Python脚本语言中的1种。
5、敏锐的洞察系统性能瓶颈，并能对io、网络通讯、任务调度中一个或多个方面的性能调优。
6、具有较强的学习能力、逻辑分析能力、问题排查能力、沟通能力、自我驱动动力、自我管理能力。
工作地址
北京 - 昌平区 - 东小口 - 东小口中煤大厦
查看地图
职位发布者:
明略数据HR汪丽
大数据,数据挖掘
聊天意愿
很弱
回复率--  用时3分钟
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
明略数据技术部招聘
Hadoop大数据高级工程师
15k-25k /北京 / 经验不限 / 本科及以上 / 全职
数据
大数据
管理岗
1天前  发布于拉勾网职位诱惑：
六险一金 超强技术团队
职位描述：
工作职责
1、基于Hadoop/Spark分布式集群的架构设计和开发。
2、解答用户提出的需求以及碰到问题时的解答。
任职资格
1、数学、统计学、人工智能、计算机相关专业，本科或以上学历。
2、至少熟练运用Java、Scala语言中的1种。
3、需要有Hadoop / Spark平台相关运维经验2年以上，有3年以上基于hadoop/Spark的实际项目开发经验。
4、熟练掌握linux常规命令与工具，至少熟练应用shell、Python脚本语言中的1种。
5、敏锐的洞察系统性能瓶颈，并能对io、网络通讯、任务调度中一个或多个方面的性能调优。
6、具有较强的学习能力、逻辑分析能力、问题排查能力、沟通能力、自我驱动动力、自我管理能力。
工作地址
北京市海淀区
查看完整地图
职位发布者:
明略数据HR汪丽
大数据,数据挖掘
聊天意愿
很弱
回复率--  用时3分钟
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
明略数据招聘
Hadoop--平台组
16k-25k /北京 / 经验1-3年 / 本科及以上 / 全职
大数据
平台
1天前  发布于拉勾网职位诱惑：
六险一金，技术大咖等你来挑战
职位描述：
职位描述：
  1. 参与大数据基础平台管理组件的设计与研发、测试等工作
  2. 负责相关模块的研发，保证系统性能、稳定和安全
  3. 参与Hadoop生态系统相关开源技术的使用、封装和增强等研发工作
  任职要求：
1.熟悉JAVA开发语言等相关技术和网络应用开发。
2.参与Hadoop生态中的zookeeper、hdfs、yarn、hbase、hive、impala、sqoop、spark、oozie、flume、kafka等开源组件的使用、封装和增强
4.熟悉MySql、Postgresql至少一种数据库；
5.熟悉使用Linux
6.熟悉Hadoop生态系统的优先考虑

工作地址
北京 - 朝阳区 - 立水桥 - 立水桥
查看地图
职位发布者:
明略数据HR汪丽
大数据,数据挖掘
聊天意愿
很弱
回复率--  用时3分钟
简历处理
暂无
处理率--  用时--天
活跃时段
下午
下午4点最活跃
-------------------------------------------------
